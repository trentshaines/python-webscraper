<!DOCTYPE html>
<html lang="en-US" class="no-js">
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="twitter:dnt" content="on">

		<script>document.documentElement.classList.remove('no-js');document.documentElement.classList.add('js');</script>
	<script>
		if ( -1 !== window.location.hash.indexOf( '#!' ) ) {
			window.location.href = window.location.origin + window.location.pathname + window.location.hash.replace( '#!', '' ) + '/' + window.location.search;
		}

					if ( -1 !== window.location.hash.indexOf( '#' + 'past-episodes' ) ) {
				window.location.href = window.location.origin + window.location.pathname + 'past-episodes' + '/' + window.location.search;
			}
					if ( -1 !== window.location.hash.indexOf( '#' + 'faq' ) ) {
				window.location.href = window.location.origin + window.location.pathname + 'faq' + '/' + window.location.search;
			}
		
		if ( -1 !== window.location.pathname.indexOf( '/overview' ) ) {
			window.location.href = window.location.origin + window.location.pathname.replace( '/overview', '' ) + window.location.search;
		}
	</script>
				<meta name="awa-product" content="MSR">
						<meta name="awa-stv" content="9.7.0">
						<meta name="awa-sitesection" content="">
						<meta name="awa-pageType" content="Event">
						<meta name="awa-market" content="en-us">
						<meta name="awa-env" content="Production">
						<meta name="awa‐asst" content="1140163">
						<meta name="awa-pgidx" content="1">
						<meta name="awa-pgtot" content="-1">
						<meta name="awa-pgtop" content="Artificial intelligence; Medical, health and genomics">
			<meta name='robots' content='index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	
	<!-- This site is optimized with the Yoast SEO plugin v25.3.1 - https://yoast.com/wordpress/plugins/seo/ -->
	<title>Microsoft Research Forum - Microsoft Research</title>
	<meta name="description" content="This series explores recent research advances, bold new ideas, and important discussions with the global research community." />
	<link rel="canonical" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/" />
	<meta property="og:locale" content="en_US" />
	<meta property="og:type" content="article" />
	<meta property="og:title" content="Microsoft Research Forum - Microsoft Research" />
	<meta property="og:description" content="This series explores recent research advances, bold new ideas, and important discussions with the global research community." />
	<meta property="og:url" content="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/" />
	<meta property="og:site_name" content="Microsoft Research" />
	<meta property="article:publisher" content="https://www.facebook.com/microsoftresearch/" />
	<meta property="article:modified_time" content="2025-09-11T18:16:29+00:00" />
	<meta property="og:image" content="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg" />
	<meta property="og:image:width" content="1400" />
	<meta property="og:image:height" content="788" />
	<meta property="og:image:type" content="image/jpeg" />
	<meta name="twitter:card" content="summary_large_image" />
	<meta name="twitter:site" content="@MSFTResearch" />
	<script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/","url":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/","name":"Microsoft Research Forum - Microsoft Research","isPartOf":{"@id":"https://www.microsoft.com/en-us/research/#website"},"primaryImageOfPage":{"@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/#primaryimage"},"image":{"@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/#primaryimage"},"thumbnailUrl":"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg","datePublished":"2025-05-27T19:35:37+00:00","dateModified":"2025-09-11T18:16:29+00:00","description":"This series explores recent research advances, bold new ideas, and important discussions with the global research community.","breadcrumb":{"@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://www.microsoft.com/en-us/research/event/microsoft-research-forum/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/#primaryimage","url":"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg","contentUrl":"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg","width":1400,"height":788,"caption":"Research Forum | abstract background with colorful hexagons"},{"@type":"BreadcrumbList","@id":"https://www.microsoft.com/en-us/research/event/microsoft-research-forum/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://www.microsoft.com/en-us/research/"},{"@type":"ListItem","position":2,"name":"Microsoft Research Forum"}]},{"@type":"WebSite","@id":"https://www.microsoft.com/en-us/research/#website","url":"https://www.microsoft.com/en-us/research/","name":"Microsoft Research","description":"","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.microsoft.com/en-us/research/?s={search_term_string}"},"query-input":{"@type":"PropertyValueSpecification","valueRequired":true,"valueName":"search_term_string"}}],"inLanguage":"en-US"}]}</script>
	<!-- / Yoast SEO plugin. -->


<link rel='dns-prefetch' href='//wcpstatic.microsoft.com' />
<link rel='dns-prefetch' href='//www.microsoft.com' />
<link rel='dns-prefetch' href='//js.monitor.azure.com' />
<link rel="alternate" type="application/rss+xml" title="Microsoft Research &raquo; Feed" href="https://www.microsoft.com/en-us/research/feed/" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/16.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/16.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/www.microsoft.com\/en-us\/research\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.8.2"}};
/*! This file is auto-generated */
!function(s,n){var o,i,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),a=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===a[t]})}function u(e,t){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);for(var n=e.getImageData(16,16,1,1),a=0;a<n.data.length;a++)if(0!==n.data[a])return!1;return!0}function f(e,t,n,a){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\udde8\ud83c\uddf6","\ud83c\udde8\u200b\ud83c\uddf6")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!a(e,"\ud83e\udedf")}return!1}function g(e,t,n,a){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):s.createElement("canvas"),o=r.getContext("2d",{willReadFrequently:!0}),i=(o.textBaseline="top",o.font="600 32px Arial",{});return e.forEach(function(e){i[e]=t(o,e,n,a)}),i}function t(e){var t=s.createElement("script");t.src=e,t.defer=!0,s.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",i=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){s.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+g.toString()+"("+[JSON.stringify(i),f.toString(),p.toString(),u.toString()].join(",")+"));",a=new Blob([e],{type:"text/javascript"}),r=new Worker(URL.createObjectURL(a),{name:"wpTestEmojiSupports"});return void(r.onmessage=function(e){c(n=e.data),r.terminate(),t(n)})}catch(e){}c(n=g(i,f,p,u))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/block-library/style.min.css?ver=6.8.2' type='text/css' media='all' />
<style id='elasticpress-related-posts-style-inline-css' type='text/css'>
.editor-styles-wrapper .wp-block-elasticpress-related-posts ul,.wp-block-elasticpress-related-posts ul{list-style-type:none;padding:0}.editor-styles-wrapper .wp-block-elasticpress-related-posts ul li a>div{display:inline}

</style>
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #171717;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--blue: #0072cc;--wp--preset--color--purple: #5c2d91;--wp--preset--color--magenta: #b4009e;--wp--preset--color--red: #e81123;--wp--preset--color--orange: #d83b01;--wp--preset--color--yellow: #ffb900;--wp--preset--color--green: #107c10;--wp--preset--color--teal: #008272;--wp--preset--color--dark-gray: #2f2f2f;--wp--preset--color--gray: #767676;--wp--preset--color--light-gray: #e3e3e3;--wp--preset--color--lighter-gray: #f2f2f2;--wp--preset--color--light-blue: #ecf8fe;--wp--preset--color--cyan-blue: #3aa0fa;--wp--preset--color--transparent: transparent;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}.wp-block-button .wp-block-button__link{--wp--preset--color--blue: #0072cc;--wp--preset--color--cyan-blue: #3aa0fa;--wp--preset--color--black: #171717;--wp--preset--color--white: #ffffff;}:root { --wp--style--global--content-size: 1600px;--wp--style--global--wide-size: 1600px; }:where(body) { margin: 0; }.wp-site-blocks > .alignleft { float: left; margin-right: 2em; }.wp-site-blocks > .alignright { float: right; margin-left: 2em; }.wp-site-blocks > .aligncenter { justify-content: center; margin-left: auto; margin-right: auto; }:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}.is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}body{padding-top: 0px;padding-right: 0px;padding-bottom: 0px;padding-left: 0px;}a:where(:not(.wp-element-button)){text-decoration: underline;}:root :where(.wp-element-button, .wp-block-button__link){background-color: #32373c;border-width: 0;color: #fff;font-family: inherit;font-size: inherit;line-height: inherit;padding: calc(0.667em + 2px) calc(1.333em + 2px);text-decoration: none;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-blue-color{color: var(--wp--preset--color--blue) !important;}.has-purple-color{color: var(--wp--preset--color--purple) !important;}.has-magenta-color{color: var(--wp--preset--color--magenta) !important;}.has-red-color{color: var(--wp--preset--color--red) !important;}.has-orange-color{color: var(--wp--preset--color--orange) !important;}.has-yellow-color{color: var(--wp--preset--color--yellow) !important;}.has-green-color{color: var(--wp--preset--color--green) !important;}.has-teal-color{color: var(--wp--preset--color--teal) !important;}.has-dark-gray-color{color: var(--wp--preset--color--dark-gray) !important;}.has-gray-color{color: var(--wp--preset--color--gray) !important;}.has-light-gray-color{color: var(--wp--preset--color--light-gray) !important;}.has-lighter-gray-color{color: var(--wp--preset--color--lighter-gray) !important;}.has-light-blue-color{color: var(--wp--preset--color--light-blue) !important;}.has-cyan-blue-color{color: var(--wp--preset--color--cyan-blue) !important;}.has-transparent-color{color: var(--wp--preset--color--transparent) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-blue-background-color{background-color: var(--wp--preset--color--blue) !important;}.has-purple-background-color{background-color: var(--wp--preset--color--purple) !important;}.has-magenta-background-color{background-color: var(--wp--preset--color--magenta) !important;}.has-red-background-color{background-color: var(--wp--preset--color--red) !important;}.has-orange-background-color{background-color: var(--wp--preset--color--orange) !important;}.has-yellow-background-color{background-color: var(--wp--preset--color--yellow) !important;}.has-green-background-color{background-color: var(--wp--preset--color--green) !important;}.has-teal-background-color{background-color: var(--wp--preset--color--teal) !important;}.has-dark-gray-background-color{background-color: var(--wp--preset--color--dark-gray) !important;}.has-gray-background-color{background-color: var(--wp--preset--color--gray) !important;}.has-light-gray-background-color{background-color: var(--wp--preset--color--light-gray) !important;}.has-lighter-gray-background-color{background-color: var(--wp--preset--color--lighter-gray) !important;}.has-light-blue-background-color{background-color: var(--wp--preset--color--light-blue) !important;}.has-cyan-blue-background-color{background-color: var(--wp--preset--color--cyan-blue) !important;}.has-transparent-background-color{background-color: var(--wp--preset--color--transparent) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-blue-border-color{border-color: var(--wp--preset--color--blue) !important;}.has-purple-border-color{border-color: var(--wp--preset--color--purple) !important;}.has-magenta-border-color{border-color: var(--wp--preset--color--magenta) !important;}.has-red-border-color{border-color: var(--wp--preset--color--red) !important;}.has-orange-border-color{border-color: var(--wp--preset--color--orange) !important;}.has-yellow-border-color{border-color: var(--wp--preset--color--yellow) !important;}.has-green-border-color{border-color: var(--wp--preset--color--green) !important;}.has-teal-border-color{border-color: var(--wp--preset--color--teal) !important;}.has-dark-gray-border-color{border-color: var(--wp--preset--color--dark-gray) !important;}.has-gray-border-color{border-color: var(--wp--preset--color--gray) !important;}.has-light-gray-border-color{border-color: var(--wp--preset--color--light-gray) !important;}.has-lighter-gray-border-color{border-color: var(--wp--preset--color--lighter-gray) !important;}.has-light-blue-border-color{border-color: var(--wp--preset--color--light-blue) !important;}.has-cyan-blue-border-color{border-color: var(--wp--preset--color--cyan-blue) !important;}.has-transparent-border-color{border-color: var(--wp--preset--color--transparent) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}.wp-block-button .wp-block-button__link.has-blue-color{color: var(--wp--preset--color--blue) !important;}.wp-block-button .wp-block-button__link.has-cyan-blue-color{color: var(--wp--preset--color--cyan-blue) !important;}.wp-block-button .wp-block-button__link.has-black-color{color: var(--wp--preset--color--black) !important;}.wp-block-button .wp-block-button__link.has-white-color{color: var(--wp--preset--color--white) !important;}.wp-block-button .wp-block-button__link.has-blue-background-color{background-color: var(--wp--preset--color--blue) !important;}.wp-block-button .wp-block-button__link.has-cyan-blue-background-color{background-color: var(--wp--preset--color--cyan-blue) !important;}.wp-block-button .wp-block-button__link.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.wp-block-button .wp-block-button__link.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.wp-block-button .wp-block-button__link.has-blue-border-color{border-color: var(--wp--preset--color--blue) !important;}.wp-block-button .wp-block-button__link.has-cyan-blue-border-color{border-color: var(--wp--preset--color--cyan-blue) !important;}.wp-block-button .wp-block-button__link.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.wp-block-button .wp-block-button__link.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='cpsh-shortcodes-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/column-shortcodes/assets/css/shortcodes.css?ver=1.0.1' type='text/css' media='all' />
<link rel='stylesheet' id='moray_blocks_shared_style-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/moray-blocks/dist/css/shared-style.css?ver=0.2.0' type='text/css' media='all' />
<link rel='stylesheet' id='moray_blocks_frontend_style-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/moray-blocks/dist/css/style.css?ver=0.2.0' type='text/css' media='all' />
<link rel='stylesheet' id='msr_block_library_plugin_shared-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/msr-blocks-library/dist/css/shared.css?ver=1756401366' type='text/css' media='all' />
<link rel='stylesheet' id='msr_block_library_plugin_frontend-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/msr-blocks-library/dist/css/frontend.css?ver=1756401366' type='text/css' media='all' />
<link rel='stylesheet' id='taxonomy-image-plugin-public-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/taxonomy-images/css/style.css?ver=0.9.6' type='text/css' media='screen' />
<link rel='stylesheet' id='microsoft-research-moray-css' href='https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/css/microsoft-research-moray.min.css?ver=7009c675ffd3915a29f8dc09388f79dc02addde3' type='text/css' media='all' />
<link rel='stylesheet' id='wp-components-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/components/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-preferences-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/preferences/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-editor-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/block-editor/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-reusable-blocks-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/reusable-blocks/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-patterns-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/patterns/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-editor-css' href='https://www.microsoft.com/en-us/research/wp-includes/css/dist/editor/style.min.css?ver=6.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='msr_blocks-style-css-css' href='https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/css/blocks-style.min.css?ver=7009c675ffd3915a29f8dc09388f79dc02addde3' type='text/css' media='all' />
<link rel='stylesheet' id='elasticpress-autosuggest-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/elasticpress/dist/css/autosuggest-styles.css?ver=d87f34a78edccbda21b1' type='text/css' media='all' />
<link rel='stylesheet' id='duet-date-picker-style-css' href='https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/vendor/duet-date-picker/duet/themes/default.css?ver=7009c675ffd3915a29f8dc09388f79dc02addde3' type='text/css' media='all' />
<link rel='stylesheet' id='elasticpress-facets-css' href='https://www.microsoft.com/en-us/research/wp-content/plugins/elasticpress/dist/css/facets-styles.css?ver=5797fb4036fc4007a87a' type='text/css' media='all' />
<script type="text/javascript" src="https://wcpstatic.microsoft.com/mscc/lib/v2/wcp-consent.js" id="wcp-consent-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/vendor/jquery/jquery-3.3.1.min.js?ver=3.3.1" id="jquery-core-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/vendor/jquery-migrate/jquery-migrate-3.0.0.js?ver=3.0.0" id="jquery-migrate-js"></script>
<script type="text/javascript" id="trp-gp-language-cookie-js-extra">
/* <![CDATA[ */
var trp_gp_language_cookie_data = {"lang_parameter":"lang"};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/tp-add-on-language-by-get-parameter/assets/js/trp-gp-language-cookie.js?ver=1.0.1" id="trp-gp-language-cookie-js"></script>
<script type="text/javascript" src="https://js.monitor.azure.com/scripts/c/ms.analytics-web-3.min.js" id="oneds-tracking-js"></script>
<link rel="https://api.w.org/" href="https://www.microsoft.com/en-us/research/wp-json/" /><link rel="alternate" title="JSON" type="application/json" href="https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event/1140163" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.microsoft.com/en-us/research/xmlrpc.php?rsd" />
<meta name="generator" content="WordPress 6.8.2" />
<link rel='shortlink' href='https://www.microsoft.com/en-us/research/?p=1140163' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="https://www.microsoft.com/en-us/research/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="https://www.microsoft.com/en-us/research/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F&#038;format=xml" />
<link rel="stylesheet" href="https://www.microsoft.com/onerfstatics/marketingsites-wcus-prod/west-european/shell/_scrf/css/themes=default.device=uplevel_web_pc/63-57d110/c9-be0100/a6-e969ef/43-9f2e7c/82-8b5456/a0-5d3913/3d-28500e/ae-f1ac0c?ver=2.0&amp;_cf=02242021_3231" type="text/css" media="all" /><!-- Stream WordPress user activity plugin v4.1.1 -->
<link type="text/plain" rel="author" href="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/humans.txt" /><meta name="research-area" content="Artificial intelligence; Medical, health and genomics"><link rel="prefetch" href="https://c.s-microsoft.com" /><link rel="prefetch" href="https://i.s-microsoft.com" /><link rel="prefetch" href="https://www.clarity.ms" /><link rel="prefetch" href="https://connect.facebook.net" /><link rel="alternate" hreflang="x-default" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/">
<link rel="alternate" hreflang="en-us" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/">

	<!-- Facebook Pixel Code -->
	<script>
		function facebookTracking() {
			!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?
				n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;
				n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
				t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
				document,'script','https://connect.facebook.net/en_US/fbevents.js');
			fbq('init', '435868603227390');
						fbq('track', 'PageView');
					}
	</script>
	<!-- End Facebook Pixel Code -->

	
	<!-- Clicktale Code -->
	<script>
		function clicktaleTracking() {
			var s = document.createElement( 'script' );
			var src = "//cdn.clicktale.com/js/www07/ptc/959721af-e707-44b6-9b6a-d14f3ec0f756.js";
			s.setAttribute( 'src', src );
			document.head.appendChild( s );
		}
	</script>
	<!-- End Clicktale Code -->

	
	<!-- Clarity Code -->
	<script type="text/javascript">
		function clarityTracking() {
			(function(c,l,a,r,i,t,y){
			c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
			t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
			y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
			})(window, document, "clarity", "script", "738awl9hsy");
		}
	</script>
	<!-- End Clarity Code -->

			<style type="text/css" id="wp-custom-css">
			/** Temporary fix to make right-aligned annotated links clickable **/
.annotations__list.card {
	z-index: 999999;
}
/** End temporary fix to make right-aligned annotated links clickable **/

.wp-block-social-link-label, 
.wp-block-social-link-anchor {
  margin-bottom: 0;
}

/** MSR-3986 - External Links on images **/
.wp-block-image > a.msr-external-link:after, .wp-block-media-text__media > a.msr-external-link:after {
  display: none;
}

/** End **/

/** MSR-4078 **/
.wp-social-link a {
		padding: 0 !important;
}

.wp-social-link {
	background: transparent !important;
}

/** End **/

/** MSR-4077 **/

.wp-block-pullquote {
	padding: 2rem 0;
}

/** End **/

/** MSRA Launch **/

li.custom-control:has(#field-associated_msr_research_lab-post-1012650-1012650) {
	display: none !important;
}

/** End **/
		</style>
		<script src="https://www.microsoft.com/onerfstatics/marketingsites-wcus-prod/shell/_scrf/js/themes=default/54-af9f9f/d4-fb1f57/e1-a50eee/e7-954872/d8-97d509/f0-251fe2/46-be1318/77-04a268/11-240c7b/63-077520/a4-34de62/77-380647/db-bc0148/dc-7e9864/6d-c07ea1/6f-dafe8c/f6-aa5278/e6-5f3533/6d-1e7ed0/b7-cadaa7/62-2741f0/ca-40b7b0/4e-ee3a55/3e-f5c39b/c3-6454d7/f9-7592d3/d0-e64f3e/92-10345d/79-499886/7e-cda2d3/58-ab4971/57-c14418/38-b93a9e/de-884374/1f-100dea/33-abe4df/2b-8e0ae6?ver=2.0&_cf=02242021_3231&iife=1"></script>	</head>

	<body class="wp-singular msr-event-template-default single single-msr-event postid-1140163 wp-embed-responsive wp-theme-microsoft-research-theme microsoft-uhf  msr-not-translated">

		<div id="ms-cookie-banner"></div>		
		

		<div id="banner" class="site-header" data-bi-aN="header" data-no-translation>
			
				<uhf_header>
					<div id="headerArea" class="uhf"  data-m='{"cN":"headerArea","cT":"Area_coreuiArea","id":"a1Body","sN":1,"aN":"Body"}'>
                <div id="headerRegion"      data-region-key="headerregion" data-m='{"cN":"headerRegion","cT":"Region_coreui-region","id":"r1a1","sN":1,"aN":"a1"}' >

    <div  id="headerUniversalHeader" data-m='{"cN":"headerUniversalHeader","cT":"Module_coreui-universalheader","id":"m1r1a1","sN":1,"aN":"r1a1"}'  data-module-id="Category|headerRegion|coreui-region|headerUniversalHeader|coreui-universalheader">
        

                        <div id="epb" class="x-hidden x-hidden-vp-mobile-st uhfc-universal-context context-uhf" data-m='{"cN":"epb_cont","cT":"Container","id":"c1m1r1a1","sN":1,"aN":"m1r1a1"}'>

	<div class="c-uhfh-alert f-information epb-container theme-light" role="dialog" aria-label="Promotional Banner" data-m='{"cT":"Container","id":"c1c1m1r1a1","sN":1,"aN":"c1m1r1a1"}' data-pb="[{&quot;Browser&quot;:&quot;anaheim&quot;,&quot;ExtensionType&quot;:&quot;windows10only&quot;,&quot;ExtensionUrl&quot;:&quot;https://copilot.microsoft.com/?prompt=Tell+me+how+Copilot+can+help+me+brainstorm+ideas+for&amp;form=MY02P2&amp;OCID=MY02P2&amp;ICID=DSM_Promo_Copilot&quot;,&quot;BackgroundColorDarkTheme&quot;:&quot;b-black&quot;,&quot;LogoUrlDarkTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RW1iGSh.png&quot;,&quot;ActionLinkBackgroundColorDarkTheme&quot;:&quot;btn-white&quot;,&quot;BackgroundColorLightTheme&quot;:&quot;b-white&quot;,&quot;LogoUrlLightTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RW1iGSh.png&quot;,&quot;ActionLinkBackgroundColorLightTheme&quot;:&quot;btn-light-blue&quot;,&quot;Title&quot;:&quot;Bring ideas to life with Copilot&quot;,&quot;Paragraph&quot;:&quot;Create images from text, find writing inspiration, and get help with your questions.&quot;,&quot;ActionLinkText&quot;:&quot;Ask Copilot&quot;,&quot;ActionLinkAriaLabel&quot;:&quot;Ask Copilot&quot;,&quot;DismissText&quot;:&quot;No, thanks&quot;,&quot;DismissAriaLabel&quot;:&quot;No, thanks&quot;,&quot;CookieExpiration&quot;:&quot;7&quot;,&quot;CurrentTheme&quot;:&quot;theme-light&quot;},{&quot;Browser&quot;:&quot;edge&quot;,&quot;ExtensionType&quot;:&quot;windows10only&quot;,&quot;ExtensionUrl&quot;:&quot;https://aka.ms/MicrosoftEdgeDownload&quot;,&quot;BackgroundColorDarkTheme&quot;:&quot;b-black&quot;,&quot;LogoUrlDarkTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RE4xdax.png&quot;,&quot;ActionLinkBackgroundColorDarkTheme&quot;:&quot;btn-white&quot;,&quot;BackgroundColorLightTheme&quot;:&quot;b-white&quot;,&quot;LogoUrlLightTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RE4xdax.png&quot;,&quot;ActionLinkBackgroundColorLightTheme&quot;:&quot;btn-light-blue&quot;,&quot;Title&quot;:&quot;Try the browser recommended by Microsoft&quot;,&quot;Paragraph&quot;:&quot;Get speed, security and privacy with Microsoft Edge&quot;,&quot;ActionLinkText&quot;:&quot;Download now&quot;,&quot;ActionLinkAriaLabel&quot;:&quot;Download now&quot;,&quot;DismissText&quot;:&quot;No thanks&quot;,&quot;DismissAriaLabel&quot;:&quot;No thanks&quot;,&quot;CookieExpiration&quot;:&quot;30&quot;,&quot;CurrentTheme&quot;:&quot;theme-light&quot;},{&quot;Browser&quot;:&quot;chrome&quot;,&quot;ExtensionType&quot;:&quot;windows10only&quot;,&quot;ExtensionUrl&quot;:&quot;https://copilot.microsoft.com/?prompt=Tell+me+how+Copilot+can+help+me+brainstorm+ideas+for&amp;form=MY02P2&amp;OCID=MY02P2&amp;ICID=DSM_Promo_Copilot&quot;,&quot;BackgroundColorDarkTheme&quot;:&quot;b-black&quot;,&quot;LogoUrlDarkTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RW1iGSh.png&quot;,&quot;ActionLinkBackgroundColorDarkTheme&quot;:&quot;btn-white&quot;,&quot;BackgroundColorLightTheme&quot;:&quot;b-white&quot;,&quot;LogoUrlLightTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RW1iGSh.png&quot;,&quot;ActionLinkBackgroundColorLightTheme&quot;:&quot;btn-light-blue&quot;,&quot;Title&quot;:&quot;Bring ideas to life with Copilot&quot;,&quot;Paragraph&quot;:&quot;Create images from text, find writing inspiration, and get help with your questions.&quot;,&quot;ActionLinkText&quot;:&quot;Ask Copilot&quot;,&quot;ActionLinkAriaLabel&quot;:&quot;Ask Copilot&quot;,&quot;DismissText&quot;:&quot;No, thanks&quot;,&quot;DismissAriaLabel&quot;:&quot;No, thanks&quot;,&quot;CookieExpiration&quot;:&quot;7&quot;,&quot;CurrentTheme&quot;:&quot;theme-light&quot;},{&quot;Browser&quot;:&quot;firefox&quot;,&quot;ExtensionType&quot;:&quot;rewards&quot;,&quot;ExtensionUrl&quot;:&quot;https://browserdefaults.microsoft.com/extn/redirect/?xid=106&amp;channel=uhf&amp;pc=U785&quot;,&quot;BackgroundColorDarkTheme&quot;:&quot;b-blue&quot;,&quot;LogoUrlDarkTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RE4mFZT.png&quot;,&quot;ActionLinkBackgroundColorDarkTheme&quot;:&quot;btn-white&quot;,&quot;BackgroundColorLightTheme&quot;:&quot;b-white&quot;,&quot;LogoUrlLightTheme&quot;:&quot;https://uhf.microsoft.com/images/banners/RE4mDoE.png&quot;,&quot;ActionLinkBackgroundColorLightTheme&quot;:&quot;btn-blue&quot;,&quot;Title&quot;:&quot;Maximize your points with the Microsoft Rewards extension&quot;,&quot;Paragraph&quot;:&quot;Quick access to your daily points and offers&quot;,&quot;ActionLinkText&quot;:&quot;Add it now&quot;,&quot;ActionLinkAriaLabel&quot;:&quot;Add it now&quot;,&quot;DismissText&quot;:&quot;No thanks&quot;,&quot;DismissAriaLabel&quot;:&quot;No thanks&quot;,&quot;CookieExpiration&quot;:&quot;30&quot;,&quot;CurrentTheme&quot;:&quot;theme-light&quot;}]" data-pb-g="true">
		<div>
			<div class="c-paragraph">
				<img alt="" data-src="" src="" class="f-img-lzy" />
				<span class="c-text-group pb-content">
					<span class="epb-launch pb-content-heading"></span>
					<span class="epb-text pb-content-text"></span>
				</span>
			</div>
			<span class="c-group">
				<button id="close-epb" class="c-action-trigger c-action-cancel c-glyph-cancel" data-m='{"cN":"PB-dismiss_nonnav","id":"nn1c1c1m1r1a1","sN":1,"aN":"c1c1m1r1a1"}'></button>
				<a id="epbTryNow" href="" target="_blank" class="epb-launch c-action-trigger c-action-open" data-m='{"cN":"PB-launch_nav","id":"n2c1c1m1r1a1","sN":2,"aN":"c1c1m1r1a1"}'></a>
			</span>
		</div>
	</div>





                            
                        </div>





        <a id="uhfSkipToMain" class="m-skip-to-main" href="javascript:void(0)" data-href="" tabindex="0" data-m='{"cN":"Skip to content_nonnav","id":"nn2c1m1r1a1","sN":2,"aN":"c1m1r1a1"}'>Skip to main content</a>


<header class="c-uhfh context-uhf no-js c-sgl-stck c-category-header " itemscope="itemscope" data-header-footprint="/MSRESEARCH/research-header-main, fromService: True"   data-magict="true"   itemtype="http://schema.org/Organization">
    <div class="theme-light js-global-head f-closed  global-head-cont" data-m='{"cN":"Universal Header_cont","cT":"Container","id":"c3c1m1r1a1","sN":3,"aN":"c1m1r1a1"}'>
        <div class="c-uhfh-gcontainer-st">
            <button type="button" class="c-action-trigger c-glyph glyph-global-nav-button" aria-label="All Microsoft expand to see list of Microsoft products and services" initialState-label="All Microsoft expand to see list of Microsoft products and services" toggleState-label="Close All Microsoft list" aria-expanded="false" data-m='{"cN":"Mobile menu button_nonnav","id":"nn1c3c1m1r1a1","sN":1,"aN":"c3c1m1r1a1"}'></button>
            <button type="button" class="c-action-trigger c-glyph glyph-arrow-htmllegacy c-close-search" aria-label="Close search" aria-expanded="false" data-m='{"cN":"Close Search_nonnav","id":"nn2c3c1m1r1a1","sN":2,"aN":"c3c1m1r1a1"}'></button>
                    <a id="uhfLogo" class="c-logo c-sgl-stk-uhfLogo" itemprop="url" href="https://www.microsoft.com" aria-label="Microsoft" data-m='{"cN":"GlobalNav_Logo_cont","cT":"Container","id":"c3c3c1m1r1a1","sN":3,"aN":"c3c1m1r1a1"}'>
                        <img alt="" itemprop="logo" class="c-image" src="https://uhf.microsoft.com/images/microsoft/RE1Mu3b.png" role="presentation" aria-hidden="true" />
                        <span itemprop="name" role="presentation" aria-hidden="true">Microsoft</span>
                    </a>
            <div class="f-mobile-title">
                <button type="button" class="c-action-trigger c-glyph glyph-chevron-left" aria-label="See more menu options" data-m='{"cN":"Mobile back button_nonnav","id":"nn4c3c1m1r1a1","sN":4,"aN":"c3c1m1r1a1"}'></button>
                <span data-global-title="Microsoft home" class="js-mobile-title">Research</span>
                <button type="button" class="c-action-trigger c-glyph glyph-chevron-right" aria-label="See more menu options" data-m='{"cN":"Mobile forward button_nonnav","id":"nn5c3c1m1r1a1","sN":5,"aN":"c3c1m1r1a1"}'></button>
            </div>
                    <div class="c-show-pipe x-hidden-vp-mobile-st">
                        <a id="uhfCatLogo" class="c-logo c-cat-logo" href="/en-us/research/" aria-label="Research" itemprop="url" data-m='{"cN":"CatNav_Research_nav","id":"n6c3c1m1r1a1","sN":6,"aN":"c3c1m1r1a1"}'>
                                <span>Research</span>
                        </a>
                    </div>
                <div class="cat-logo-button-cont x-hidden">
                        <button type="button" id="uhfCatLogoButton" class="c-cat-logo-button x-hidden" aria-expanded="false" aria-label="Research" data-m='{"cN":"Research_nonnav","id":"nn7c3c1m1r1a1","sN":7,"aN":"c3c1m1r1a1"}'>
                            Research
                        </button>
                </div>



                    <nav id="uhf-g-nav" aria-label="Contextual menu" class="c-uhfh-gnav" data-m='{"cN":"Category nav_cont","cT":"Container","id":"c8c3c1m1r1a1","sN":8,"aN":"c3c1m1r1a1"}'>
            <ul class="js-paddle-items">
                    <li class="single-link js-nav-menu x-hidden-none-mobile-vp uhf-menu-item">
                        <a class="c-uhf-nav-link" href="/en-us/research/" data-m='{"cN":"CatNav_Home_nav","id":"n1c8c3c1m1r1a1","sN":1,"aN":"c8c3c1m1r1a1"}' > Home </a>
                    </li>
                                        <li class="nested-menu uhf-menu-item">
                            <div class="c-uhf-menu js-nav-menu">
                                <button type="button" id="c-shellmenu_40"  aria-expanded="false" data-m='{"cN":"CatNav_OurResearch_nonnav","id":"nn2c8c3c1m1r1a1","sN":2,"aN":"c8c3c1m1r1a1"}'>Our research</button>

                                <ul class="f-multi-column f-multi-column-5" data-class-idn="f-multi-column f-multi-column-5" aria-hidden="true" data-m='{"cN":"OurResearch_cont","cT":"Container","id":"c3c8c3c1m1r1a1","sN":3,"aN":"c8c3c1m1r1a1"}'>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"Resources_cont","cT":"Container","id":"c1c3c8c3c1m1r1a1","sN":1,"aN":"c3c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_41-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Resources_nonnav","id":"nn1c1c3c8c3c1m1r1a1","sN":1,"aN":"c1c3c8c3c1m1r1a1"}'>Resources</span>
    <button id="uhf-navbtn-shellmenu_41-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Resources_nonnav","id":"nn2c1c3c8c3c1m1r1a1","sN":2,"aN":"c1c3c8c3c1m1r1a1"}'>Resources</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_41-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"Publications_cont","cT":"Container","id":"c3c1c3c8c3c1m1r1a1","sN":3,"aN":"c1c3c8c3c1m1r1a1"}'>
            <a id="Publications" class="js-subm-uhf-nav-link" href="/en-us/research/publications/" data-m='{"cN":"CatNav_Publications_nav","id":"n1c3c1c3c8c3c1m1r1a1","sN":1,"aN":"c3c1c3c8c3c1m1r1a1"}'>Publications</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Code \u0026 data_cont","cT":"Container","id":"c4c1c3c8c3c1m1r1a1","sN":4,"aN":"c1c3c8c3c1m1r1a1"}'>
            <a id="CodeDatasets" class="js-subm-uhf-nav-link" href="/en-us/research/tools/" data-m='{"cN":"CatNav_Code \u0026 data_nav","id":"n1c4c1c3c8c3c1m1r1a1","sN":1,"aN":"c4c1c3c8c3c1m1r1a1"}'>Code &amp; data</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"People-resources_cont","cT":"Container","id":"c5c1c3c8c3c1m1r1a1","sN":5,"aN":"c1c3c8c3c1m1r1a1"}'>
            <a id="People" class="js-subm-uhf-nav-link" href="/en-us/research/people/" data-m='{"cN":"CatNav_People-resources_nav","id":"n1c5c1c3c8c3c1m1r1a1","sN":1,"aN":"c5c1c3c8c3c1m1r1a1"}'>People</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"MicrosoftResearchBlog-resources_cont","cT":"Container","id":"c6c1c3c8c3c1m1r1a1","sN":6,"aN":"c1c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_45" class="js-subm-uhf-nav-link" href="/en-us/research/blog/" data-m='{"cN":"CatNav_MicrosoftResearchBlog-resources_nav","id":"n1c6c1c3c8c3c1m1r1a1","sN":1,"aN":"c6c1c3c8c3c1m1r1a1"}'>Microsoft Research blog</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"Intelligence_cont","cT":"Container","id":"c2c3c8c3c1m1r1a1","sN":2,"aN":"c3c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_46-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Intelligence_nonnav","id":"nn1c2c3c8c3c1m1r1a1","sN":1,"aN":"c2c3c8c3c1m1r1a1"}'>Research areas: Intelligence</span>
    <button id="uhf-navbtn-shellmenu_46-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Intelligence_nonnav","id":"nn2c2c3c8c3c1m1r1a1","sN":2,"aN":"c2c3c8c3c1m1r1a1"}'>Research areas: Intelligence</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_46-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"ArtificialIntelligence_cont","cT":"Container","id":"c3c2c3c8c3c1m1r1a1","sN":3,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_47" class="js-subm-uhf-nav-link" href="/en-us/research/focus-area/ai-and-microsoft-research/" data-m='{"cN":"CatNav_ArtificialIntelligence_nav","id":"n1c3c2c3c8c3c1m1r1a1","sN":1,"aN":"c3c2c3c8c3c1m1r1a1"}'>Artificial intelligence</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"audioacoustics_cont","cT":"Container","id":"c4c2c3c8c3c1m1r1a1","sN":4,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_48" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/audio-acoustics/" data-m='{"cN":"CatNav_audioacoustics_nav","id":"n1c4c2c3c8c3c1m1r1a1","sN":1,"aN":"c4c2c3c8c3c1m1r1a1"}'>Audio &amp; acoustics</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Computervision_cont","cT":"Container","id":"c5c2c3c8c3c1m1r1a1","sN":5,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_49" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/computer-vision/" data-m='{"cN":"CatNav_Computervision_nav","id":"n1c5c2c3c8c3c1m1r1a1","sN":1,"aN":"c5c2c3c8c3c1m1r1a1"}'>Computer vision</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Graphicsmultimedia_cont","cT":"Container","id":"c6c2c3c8c3c1m1r1a1","sN":6,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_50" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/graphics-and-multimedia/" data-m='{"cN":"CatNav_Graphicsmultimedia_nav","id":"n1c6c2c3c8c3c1m1r1a1","sN":1,"aN":"c6c2c3c8c3c1m1r1a1"}'>Graphics &amp; multimedia</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Humancomputerinteraction_cont","cT":"Container","id":"c7c2c3c8c3c1m1r1a1","sN":7,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_51" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/human-computer-interaction/" data-m='{"cN":"CatNav_Humancomputerinteraction_nav","id":"n1c7c2c3c8c3c1m1r1a1","sN":1,"aN":"c7c2c3c8c3c1m1r1a1"}'>Human-computer interaction</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Humanlanguagetechnologies_cont","cT":"Container","id":"c8c2c3c8c3c1m1r1a1","sN":8,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_52" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/human-language-technologies/" data-m='{"cN":"CatNav_Humanlanguagetechnologies_nav","id":"n1c8c2c3c8c3c1m1r1a1","sN":1,"aN":"c8c2c3c8c3c1m1r1a1"}'>Human language technologies</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Searchinformationretrieval_cont","cT":"Container","id":"c9c2c3c8c3c1m1r1a1","sN":9,"aN":"c2c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_53" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/search-information-retrieval/" data-m='{"cN":"CatNav_Searchinformationretrieval_nav","id":"n1c9c2c3c8c3c1m1r1a1","sN":1,"aN":"c9c2c3c8c3c1m1r1a1"}'>Search &amp; information retrieval</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"Systems_cont","cT":"Container","id":"c3c3c8c3c1m1r1a1","sN":3,"aN":"c3c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_54-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Systems_nonnav","id":"nn1c3c3c8c3c1m1r1a1","sN":1,"aN":"c3c3c8c3c1m1r1a1"}'>Research areas: Systems</span>
    <button id="uhf-navbtn-shellmenu_54-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Systems_nonnav","id":"nn2c3c3c8c3c1m1r1a1","sN":2,"aN":"c3c3c8c3c1m1r1a1"}'>Research areas: Systems</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_54-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"Datamanagementanalysisvisualization_cont","cT":"Container","id":"c3c3c3c8c3c1m1r1a1","sN":3,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_55" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/data-platform-analytics/" data-m='{"cN":"CatNav_Datamanagementanalysisvisualization_nav","id":"n1c3c3c3c8c3c1m1r1a1","sN":1,"aN":"c3c3c3c8c3c1m1r1a1"}'>Data platforms and analytics</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Hardwaredevices_cont","cT":"Container","id":"c4c3c3c8c3c1m1r1a1","sN":4,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_56" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/hardware-devices/" data-m='{"cN":"CatNav_Hardwaredevices_nav","id":"n1c4c3c3c8c3c1m1r1a1","sN":1,"aN":"c4c3c3c8c3c1m1r1a1"}'>Hardware &amp; devices</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Programminglanguagessoftwareengineering_cont","cT":"Container","id":"c5c3c3c8c3c1m1r1a1","sN":5,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_57" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/programming-languages-software-engineering/" data-m='{"cN":"CatNav_Programminglanguagessoftwareengineering_nav","id":"n1c5c3c3c8c3c1m1r1a1","sN":1,"aN":"c5c3c3c8c3c1m1r1a1"}'>Programming languages &amp; software engineering</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"QuantumComputing_cont","cT":"Container","id":"c6c3c3c8c3c1m1r1a1","sN":6,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="Quantum computing" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/quantum/" data-m='{"cN":"CatNav_QuantumComputing_nav","id":"n1c6c3c3c8c3c1m1r1a1","sN":1,"aN":"c6c3c3c8c3c1m1r1a1"}'>Quantum computing</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Securityprivacycryptography_cont","cT":"Container","id":"c7c3c3c8c3c1m1r1a1","sN":7,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_59" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/security-privacy-cryptography/" data-m='{"cN":"CatNav_Securityprivacycryptography_nav","id":"n1c7c3c3c8c3c1m1r1a1","sN":1,"aN":"c7c3c3c8c3c1m1r1a1"}'>Security, privacy &amp; cryptography</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Computersystemsnetworking_cont","cT":"Container","id":"c8c3c3c8c3c1m1r1a1","sN":8,"aN":"c3c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_60" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/systems-and-networking/" data-m='{"cN":"CatNav_Computersystemsnetworking_nav","id":"n1c8c3c3c8c3c1m1r1a1","sN":1,"aN":"c8c3c3c8c3c1m1r1a1"}'>Systems &amp; networking</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"Theory_cont","cT":"Container","id":"c4c3c8c3c1m1r1a1","sN":4,"aN":"c3c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_61-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Theory_nonnav","id":"nn1c4c3c8c3c1m1r1a1","sN":1,"aN":"c4c3c8c3c1m1r1a1"}'>Research areas: Theory</span>
    <button id="uhf-navbtn-shellmenu_61-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Theory_nonnav","id":"nn2c4c3c8c3c1m1r1a1","sN":2,"aN":"c4c3c8c3c1m1r1a1"}'>Research areas: Theory</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_61-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"Algorithms_cont","cT":"Container","id":"c3c4c3c8c3c1m1r1a1","sN":3,"aN":"c4c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_62" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/algorithms/" data-m='{"cN":"CatNav_Algorithms_nav","id":"n1c3c4c3c8c3c1m1r1a1","sN":1,"aN":"c3c4c3c8c3c1m1r1a1"}'>Algorithms</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Mathematics_cont","cT":"Container","id":"c4c4c3c8c3c1m1r1a1","sN":4,"aN":"c4c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_63" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/computational-sciences-mathematics/" data-m='{"cN":"CatNav_Mathematics_nav","id":"n1c4c4c3c8c3c1m1r1a1","sN":1,"aN":"c4c4c3c8c3c1m1r1a1"}'>Mathematics</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"Other Sciences_cont","cT":"Container","id":"c5c3c8c3c1m1r1a1","sN":5,"aN":"c3c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_64-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Other Sciences_nonnav","id":"nn1c5c3c8c3c1m1r1a1","sN":1,"aN":"c5c3c8c3c1m1r1a1"}'>Research areas: Other Sciences</span>
    <button id="uhf-navbtn-shellmenu_64-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_Other Sciences_nonnav","id":"nn2c5c3c8c3c1m1r1a1","sN":2,"aN":"c5c3c8c3c1m1r1a1"}'>Research areas: Other Sciences</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_64-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"Ecologyenvironment_cont","cT":"Container","id":"c3c5c3c8c3c1m1r1a1","sN":3,"aN":"c5c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_65" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/ecology-environment/" data-m='{"cN":"CatNav_Ecologyenvironment_nav","id":"n1c3c5c3c8c3c1m1r1a1","sN":1,"aN":"c3c5c3c8c3c1m1r1a1"}'>Ecology &amp; environment</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Economics_cont","cT":"Container","id":"c4c5c3c8c3c1m1r1a1","sN":4,"aN":"c5c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_66" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/economics/" data-m='{"cN":"CatNav_Economics_nav","id":"n1c4c5c3c8c3c1m1r1a1","sN":1,"aN":"c4c5c3c8c3c1m1r1a1"}'>Economics</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Medicalhealthgenomics_cont","cT":"Container","id":"c5c5c3c8c3c1m1r1a1","sN":5,"aN":"c5c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_67" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/medical-health-genomics/" data-m='{"cN":"CatNav_Medicalhealthgenomics_nav","id":"n1c5c5c3c8c3c1m1r1a1","sN":1,"aN":"c5c5c3c8c3c1m1r1a1"}'>Medical, health &amp; genomics</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Socialsciences_cont","cT":"Container","id":"c6c5c3c8c3c1m1r1a1","sN":6,"aN":"c5c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_68" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/social-sciences/" data-m='{"cN":"CatNav_Socialsciences_nav","id":"n1c6c5c3c8c3c1m1r1a1","sN":1,"aN":"c6c5c3c8c3c1m1r1a1"}'>Social sciences</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Technologyemergingmarkets_cont","cT":"Container","id":"c7c5c3c8c3c1m1r1a1","sN":7,"aN":"c5c3c8c3c1m1r1a1"}'>
            <a id="shellmenu_69" class="js-subm-uhf-nav-link" href="/en-us/research/research-area/technology-for-emerging-markets/" data-m='{"cN":"CatNav_Technologyemergingmarkets_nav","id":"n1c7c5c3c8c3c1m1r1a1","sN":1,"aN":"c7c5c3c8c3c1m1r1a1"}'>Technology for emerging markets</a>
            
        </li>
    </ul>
    
</li>
                                                    
                                </ul>
                            </div>
                        </li>                        <li class="nested-menu uhf-menu-item">
                            <div class="c-uhf-menu js-nav-menu">
                                <button type="button" id="c-shellmenu_70"  aria-expanded="false" data-m='{"cN":"CatNav_ProgramsEvents_nonnav","id":"nn4c8c3c1m1r1a1","sN":4,"aN":"c8c3c1m1r1a1"}'>Programs &amp; events</button>

                                <ul class="" data-class-idn="" aria-hidden="true" data-m='{"cN":"ProgramsEvents_cont","cT":"Container","id":"c5c8c3c1m1r1a1","sN":5,"aN":"c8c3c1m1r1a1"}'>
        <li class="js-nav-menu single-link" data-m='{"cN":"Academic programs_cont","cT":"Container","id":"c1c5c8c3c1m1r1a1","sN":1,"aN":"c5c8c3c1m1r1a1"}'>
            <a id="c-shellmenu_71" class="js-subm-uhf-nav-link" href="/en-us/research/academic-programs/" data-m='{"cN":"CatNav_Academic programs_nav","id":"n1c1c5c8c3c1m1r1a1","sN":1,"aN":"c1c5c8c3c1m1r1a1"}'>Academic programs</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Events \u0026 academic conferences_cont","cT":"Container","id":"c2c5c8c3c1m1r1a1","sN":2,"aN":"c5c8c3c1m1r1a1"}'>
            <a id="Events &amp; academic conferences" class="js-subm-uhf-nav-link" href="/en-us/research/events-conferences/" data-m='{"cN":"CatNav_Events \u0026 academic conferences_nav","id":"n1c2c5c8c3c1m1r1a1","sN":1,"aN":"c2c5c8c3c1m1r1a1"}'>Events &amp; academic conferences</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Microsoft Research Forum_cont","cT":"Container","id":"c3c5c8c3c1m1r1a1","sN":3,"aN":"c5c8c3c1m1r1a1"}'>
            <a id="c-shellmenu_73" class="js-subm-uhf-nav-link" href="https://researchforum.microsoft.com" data-m='{"cN":"CatNav_Microsoft Research Forum_nav","id":"n1c3c5c8c3c1m1r1a1","sN":1,"aN":"c3c5c8c3c1m1r1a1"}'>Microsoft Research Forum</a>
            
        </li>
                                                    
                                </ul>
                            </div>
                        </li>                        <li class="nested-menu uhf-menu-item">
                            <div class="c-uhf-menu js-nav-menu">
                                <button type="button" id="Connect learn"  aria-expanded="false" data-m='{"cN":"CatNav_Connect \u0026 learn_nonnav","id":"nn6c8c3c1m1r1a1","sN":6,"aN":"c8c3c1m1r1a1"}'>Connect &amp; learn</button>

                                <ul class="" data-class-idn="" aria-hidden="true" data-m='{"cN":"Connect \u0026 learn_cont","cT":"Container","id":"c7c8c3c1m1r1a1","sN":7,"aN":"c8c3c1m1r1a1"}'>
        <li class="js-nav-menu single-link" data-m='{"cN":"BehindtheTech_cont","cT":"Container","id":"c1c7c8c3c1m1r1a1","sN":1,"aN":"c7c8c3c1m1r1a1"}'>
            <a id="c-shellmenu_75" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/behind-the-tech " data-m='{"cN":"CatNav_BehindtheTech_nav","id":"n1c1c7c8c3c1m1r1a1","sN":1,"aN":"c1c7c8c3c1m1r1a1"}'>Behind the Tech podcast</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"MicrosoftResearchblog-blog_cont","cT":"Container","id":"c2c7c8c3c1m1r1a1","sN":2,"aN":"c7c8c3c1m1r1a1"}'>
            <a id="c-shellmenu_76" class="js-subm-uhf-nav-link" href="/en-us/research/blog" data-m='{"cN":"CatNav_MicrosoftResearchblog-blog_nav","id":"n1c2c7c8c3c1m1r1a1","sN":1,"aN":"c2c7c8c3c1m1r1a1"}'>Microsoft Research blog</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Microsoft Research Forum_cont","cT":"Container","id":"c3c7c8c3c1m1r1a1","sN":3,"aN":"c7c8c3c1m1r1a1"}'>
            <a id="Microsoft Research Forum" class="js-subm-uhf-nav-link" href="https://researchforum.microsoft.com" data-m='{"cN":"CatNav_Microsoft Research Forum_nav","id":"n1c3c7c8c3c1m1r1a1","sN":1,"aN":"c3c7c8c3c1m1r1a1"}'>Microsoft Research Forum</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"MicrosoftResearchpodcast_cont","cT":"Container","id":"c4c7c8c3c1m1r1a1","sN":4,"aN":"c7c8c3c1m1r1a1"}'>
            <a id="c-shellmenu_78" class="js-subm-uhf-nav-link" href="/en-us/research/podcast/" data-m='{"cN":"CatNav_MicrosoftResearchpodcast_nav","id":"n1c4c7c8c3c1m1r1a1","sN":1,"aN":"c4c7c8c3c1m1r1a1"}'>Microsoft Research podcast</a>
            
        </li>
                                                    
                                </ul>
                            </div>
                        </li>                        <li class="nested-menu uhf-menu-item">
                            <div class="c-uhf-menu js-nav-menu">
                                <button type="button" id="About"  aria-expanded="false" data-m='{"cN":"CatNav_About_nonnav","id":"nn8c8c3c1m1r1a1","sN":8,"aN":"c8c3c1m1r1a1"}'>About</button>

                                <ul class="f-multi-column f-multi-column-3" data-class-idn="f-multi-column f-multi-column-3" aria-hidden="true" data-m='{"cN":"About_cont","cT":"Container","id":"c9c8c3c1m1r1a1","sN":9,"aN":"c8c3c1m1r1a1"}'>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"People_cont","cT":"Container","id":"c1c9c8c3c1m1r1a1","sN":1,"aN":"c9c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_80-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_People_nonnav","id":"nn1c1c9c8c3c1m1r1a1","sN":1,"aN":"c1c9c8c3c1m1r1a1"}'>People &amp; news</span>
    <button id="uhf-navbtn-shellmenu_80-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_People_nonnav","id":"nn2c1c9c8c3c1m1r1a1","sN":2,"aN":"c1c9c8c3c1m1r1a1"}'>People &amp; news</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_80-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"/en-us/research/about-microsoft-research/_cont","cT":"Container","id":"c3c1c9c8c3c1m1r1a1","sN":3,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="About Microsoft Research" class="js-subm-uhf-nav-link" href="/en-us/research/about-microsoft-research/" data-m='{"cN":"CatNav_/en-us/research/about-microsoft-research/_nav","id":"n1c3c1c9c8c3c1m1r1a1","sN":1,"aN":"c3c1c9c8c3c1m1r1a1"}'>About Microsoft Research</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"CareersInternships_cont","cT":"Container","id":"c4c1c9c8c3c1m1r1a1","sN":4,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="CareersInternships" class="js-subm-uhf-nav-link" href="/en-us/research/careers/" data-m='{"cN":"CatNav_CareersInternships_nav","id":"n1c4c1c9c8c3c1m1r1a1","sN":1,"aN":"c4c1c9c8c3c1m1r1a1"}'>Careers &amp; internships</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"People-about_cont","cT":"Container","id":"c5c1c9c8c3c1m1r1a1","sN":5,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_83" class="js-subm-uhf-nav-link" href="/en-us/research/people/" data-m='{"cN":"CatNav_People-about_nav","id":"n1c5c1c9c8c3c1m1r1a1","sN":1,"aN":"c5c1c9c8c3c1m1r1a1"}'>People</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Emeritus program_cont","cT":"Container","id":"c6c1c9c8c3c1m1r1a1","sN":6,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="EmeritusProgram" class="js-subm-uhf-nav-link" href="/en-us/research/microsoft-research-emeritus-program/" data-m='{"cN":"CatNav_Emeritus program_nav","id":"n1c6c1c9c8c3c1m1r1a1","sN":1,"aN":"c6c1c9c8c3c1m1r1a1"}'>Emeritus program</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"News \u0026 awards_cont","cT":"Container","id":"c7c1c9c8c3c1m1r1a1","sN":7,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="NewsAwards" class="js-subm-uhf-nav-link" href="/en-us/research/news-and-awards/" data-m='{"cN":"CatNav_News \u0026 awards_nav","id":"n1c7c1c9c8c3c1m1r1a1","sN":1,"aN":"c7c1c9c8c3c1m1r1a1"}'>News &amp; awards</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Newsletter-about_cont","cT":"Container","id":"c8c1c9c8c3c1m1r1a1","sN":8,"aN":"c1c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_86" class="js-subm-uhf-nav-link" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html?wt.mc_id=S-webpage_msr-homepage" data-m='{"cN":"CatNav_Newsletter-about_nav","id":"n1c8c1c9c8c3c1m1r1a1","sN":1,"aN":"c8c1c9c8c3c1m1r1a1"}'>Microsoft Research newsletter</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cN":"MicrosoftResearchLabs_cont","cT":"Container","id":"c2c9c8c3c1m1r1a1","sN":2,"aN":"c9c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_87-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_MicrosoftResearchLabs_nonnav","id":"nn1c2c9c8c3c1m1r1a1","sN":1,"aN":"c2c9c8c3c1m1r1a1"}'>Microsoft Research Labs</span>
    <button id="uhf-navbtn-shellmenu_87-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"cN":"CatNav_MicrosoftResearchLabs_nonnav","id":"nn2c2c9c8c3c1m1r1a1","sN":2,"aN":"c2c9c8c3c1m1r1a1"}'>Microsoft Research Labs</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_87-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"Africa_cont","cT":"Container","id":"c3c2c9c8c3c1m1r1a1","sN":3,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="Africa" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-lab-africa-nairobi/" data-m='{"cN":"CatNav_Africa_nav","id":"n1c3c2c9c8c3c1m1r1a1","sN":1,"aN":"c3c2c9c8c3c1m1r1a1"}'>Africa</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"AI for Science_cont","cT":"Container","id":"c4c2c9c8c3c1m1r1a1","sN":4,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_89" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-ai-for-science/" data-m='{"cN":"CatNav_AI for Science_nav","id":"n1c4c2c9c8c3c1m1r1a1","sN":1,"aN":"c4c2c9c8c3c1m1r1a1"}'>AI for Science</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"AI Frontiers_cont","cT":"Container","id":"c5c2c9c8c3c1m1r1a1","sN":5,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="AI Frontiers" class="js-subm-uhf-nav-link" href="/en-us/research/lab/ai-frontiers/" data-m='{"cN":"CatNav_AI Frontiers_nav","id":"n1c5c2c9c8c3c1m1r1a1","sN":1,"aN":"c5c2c9c8c3c1m1r1a1"}'>AI Frontiers</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"AsiaPacific_cont","cT":"Container","id":"c6c2c9c8c3c1m1r1a1","sN":6,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_91" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-asia/" data-m='{"cN":"CatNav_AsiaPacific_nav","id":"n1c6c2c9c8c3c1m1r1a1","sN":1,"aN":"c6c2c9c8c3c1m1r1a1"}'>Asia-Pacific</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"CambridgeLab_cont","cT":"Container","id":"c7c2c9c8c3c1m1r1a1","sN":7,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_92" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-cambridge/" data-m='{"cN":"CatNav_CambridgeLab_nav","id":"n1c7c2c9c8c3c1m1r1a1","sN":1,"aN":"c7c2c9c8c3c1m1r1a1"}'>Cambridge</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Health Futures_cont","cT":"Container","id":"c8c2c9c8c3c1m1r1a1","sN":8,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_93" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-health-futures/" data-m='{"cN":"CatNav_Health Futures_nav","id":"n1c8c2c9c8c3c1m1r1a1","sN":1,"aN":"c8c2c9c8c3c1m1r1a1"}'>Health Futures</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"IndiaLab_cont","cT":"Container","id":"c9c2c9c8c3c1m1r1a1","sN":9,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_94" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-india/" data-m='{"cN":"CatNav_IndiaLab_nav","id":"n1c9c2c9c8c3c1m1r1a1","sN":1,"aN":"c9c2c9c8c3c1m1r1a1"}'>India</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"MontrealLab_cont","cT":"Container","id":"c10c2c9c8c3c1m1r1a1","sN":10,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_95" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-montreal/" data-m='{"cN":"CatNav_MontrealLab_nav","id":"n1c10c2c9c8c3c1m1r1a1","sN":1,"aN":"c10c2c9c8c3c1m1r1a1"}'>Montreal</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"NewEnglandLab_cont","cT":"Container","id":"c11c2c9c8c3c1m1r1a1","sN":11,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_96" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-new-england/" data-m='{"cN":"CatNav_NewEnglandLab_nav","id":"n1c11c2c9c8c3c1m1r1a1","sN":1,"aN":"c11c2c9c8c3c1m1r1a1"}'>New England</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"NewYorkCityLab_cont","cT":"Container","id":"c12c2c9c8c3c1m1r1a1","sN":12,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_97" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-new-york/" data-m='{"cN":"CatNav_NewYorkCityLab_nav","id":"n1c12c2c9c8c3c1m1r1a1","sN":1,"aN":"c12c2c9c8c3c1m1r1a1"}'>New York City</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"RedmondLab_cont","cT":"Container","id":"c13c2c9c8c3c1m1r1a1","sN":13,"aN":"c2c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_98" class="js-subm-uhf-nav-link" href="/en-us/research/lab/microsoft-research-redmond/" data-m='{"cN":"CatNav_RedmondLab_nav","id":"n1c13c2c9c8c3c1m1r1a1","sN":1,"aN":"c13c2c9c8c3c1m1r1a1"}'>Redmond</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cT":"Container","id":"c3c9c8c3c1m1r1a1","sN":3,"aN":"c9c8c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_99-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn1c3c9c8c3c1m1r1a1","sN":1,"aN":"c3c9c8c3c1m1r1a1"}'>Other labs</span>
    <button id="uhf-navbtn-shellmenu_99-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn2c3c9c8c3c1m1r1a1","sN":2,"aN":"c3c9c8c3c1m1r1a1"}'>Other labs</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_99-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"AppliedSciencesLab_cont","cT":"Container","id":"c3c3c9c8c3c1m1r1a1","sN":3,"aN":"c3c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_100" class="js-subm-uhf-nav-link" href="/en-us/research/lab/applied-sciences-group/" data-m='{"cN":"CatNav_AppliedSciencesLab_nav","id":"n1c3c3c9c8c3c1m1r1a1","sN":1,"aN":"c3c3c9c8c3c1m1r1a1"}'>Applied Sciences</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Mixed Reality \u0026 AI - Cambridge_cont","cT":"Container","id":"c4c3c9c8c3c1m1r1a1","sN":4,"aN":"c3c9c8c3c1m1r1a1"}'>
            <a id="shellmenu_101" class="js-subm-uhf-nav-link" href="/en-us/research/lab/mixed-reality-ai-lab-cambridge/" data-m='{"cN":"CatNav_Mixed Reality \u0026 AI - Cambridge_nav","id":"n1c4c3c9c8c3c1m1r1a1","sN":1,"aN":"c4c3c9c8c3c1m1r1a1"}'>Mixed Reality &amp; AI - Cambridge</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Mixed Reality \u0026 AI - Zurich_cont","cT":"Container","id":"c5c3c9c8c3c1m1r1a1","sN":5,"aN":"c3c9c8c3c1m1r1a1"}'>
            <a id="Mixed-reality" class="js-subm-uhf-nav-link" href="/en-us/research/lab/mixed-reality-ai-zurich/" data-m='{"cN":"CatNav_Mixed Reality \u0026 AI - Zurich_nav","id":"n1c5c3c9c8c3c1m1r1a1","sN":1,"aN":"c5c3c9c8c3c1m1r1a1"}'>Mixed Reality &amp; AI - Zurich</a>
            
        </li>
    </ul>
    
</li>
                                                    
                                </ul>
                            </div>
                        </li>

                <li id="overflow-menu" class="overflow-menu x-hidden uhf-menu-item">
                        <div class="c-uhf-menu js-nav-menu">
        <button data-m='{"pid":"More","id":"nn10c8c3c1m1r1a1","sN":10,"aN":"c8c3c1m1r1a1"}' type="button" aria-label="More" aria-expanded="false">More</button>
        <ul id="overflow-menu-list" aria-hidden="true" class="overflow-menu-list">
        </ul>
    </div>

                </li>
                                    <li class="single-link js-nav-menu" id="c-uhf-nav-cta">
                        <a id="NewsletterButton" class="c-uhf-nav-link" href="https://researchforum.microsoft.com" data-m='{"cN":"CatNav_cta_Register: Research Forum_nav","id":"n11c8c3c1m1r1a1","sN":11,"aN":"c8c3c1m1r1a1"}'>Register: Research Forum</a>
                    </li>
            </ul>
            
        </nav>


            <div class="c-uhfh-actions" data-m='{"cN":"Header actions_cont","cT":"Container","id":"c9c3c1m1r1a1","sN":9,"aN":"c3c1m1r1a1"}'>
                <div class="wf-menu">        <nav id="uhf-c-nav" aria-label="All Microsoft menu" data-m='{"cN":"GlobalNav_cont","cT":"Container","id":"c1c9c3c1m1r1a1","sN":1,"aN":"c9c3c1m1r1a1"}'>
            <ul class="js-paddle-items">
                <li>
                    <div class="c-uhf-menu js-nav-menu">
                        <button type="button" class="c-button-logo all-ms-nav" aria-expanded="false" data-m='{"cN":"GlobalNav_More_nonnav","id":"nn1c1c9c3c1m1r1a1","sN":1,"aN":"c1c9c3c1m1r1a1"}'> <span>All Microsoft</span></button>
                        <ul class="f-multi-column f-multi-column-4" aria-hidden="true" data-m='{"cN":"More_cont","cT":"Container","id":"c2c1c9c3c1m1r1a1","sN":2,"aN":"c1c9c3c1m1r1a1"}'>
                                    <li class="c-w0-contr">
            <h2 class="c-uhf-sronly">Global</h2>
            <ul class="c-w0">
        <li class="js-nav-menu single-link" data-m='{"cN":"Microsoft Security_cont","cT":"Container","id":"c1c2c1c9c3c1m1r1a1","sN":1,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_0" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/security" data-m='{"cN":"W0Nav_Microsoft Security_nav","id":"n1c1c2c1c9c3c1m1r1a1","sN":1,"aN":"c1c2c1c9c3c1m1r1a1"}'>Microsoft Security</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Azure_cont","cT":"Container","id":"c2c2c1c9c3c1m1r1a1","sN":2,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_1" class="js-subm-uhf-nav-link" href="https://azure.microsoft.com/en-us/" data-m='{"cN":"W0Nav_Azure_nav","id":"n1c2c2c1c9c3c1m1r1a1","sN":1,"aN":"c2c2c1c9c3c1m1r1a1"}'>Azure</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Dynamics 365_cont","cT":"Container","id":"c3c2c1c9c3c1m1r1a1","sN":3,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_2" class="js-subm-uhf-nav-link" href="https://dynamics.microsoft.com/en-us/" data-m='{"cN":"W0Nav_Dynamics 365_nav","id":"n1c3c2c1c9c3c1m1r1a1","sN":1,"aN":"c3c2c1c9c3c1m1r1a1"}'>Dynamics 365</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Microsoft 365_cont","cT":"Container","id":"c4c2c1c9c3c1m1r1a1","sN":4,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_3" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/microsoft-365/business/" data-m='{"cN":"W0Nav_Microsoft 365_nav","id":"n1c4c2c1c9c3c1m1r1a1","sN":1,"aN":"c4c2c1c9c3c1m1r1a1"}'>Microsoft 365</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Microsoft Teams_cont","cT":"Container","id":"c5c2c1c9c3c1m1r1a1","sN":5,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_4" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/microsoft-teams/group-chat-software" data-m='{"cN":"W0Nav_Microsoft Teams_nav","id":"n1c5c2c1c9c3c1m1r1a1","sN":1,"aN":"c5c2c1c9c3c1m1r1a1"}'>Microsoft Teams</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"Windows 365_cont","cT":"Container","id":"c6c2c1c9c3c1m1r1a1","sN":6,"aN":"c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_5" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/windows-365" data-m='{"cN":"W0Nav_Windows 365_nav","id":"n1c6c2c1c9c3c1m1r1a1","sN":1,"aN":"c6c2c1c9c3c1m1r1a1"}'>Windows 365</a>
            
        </li>
            </ul>
        </li>

<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cT":"Container","id":"c7c2c1c9c3c1m1r1a1","sN":7,"aN":"c2c1c9c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_7-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn1c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c7c2c1c9c3c1m1r1a1"}'>Tech &amp; innovation</span>
    <button id="uhf-navbtn-shellmenu_7-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn2c7c2c1c9c3c1m1r1a1","sN":2,"aN":"c7c2c1c9c3c1m1r1a1"}'>Tech &amp; innovation</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_7-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_MicrosoftCloud_cont","cT":"Container","id":"c3c7c2c1c9c3c1m1r1a1","sN":3,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_8" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/microsoft-cloud" data-m='{"cN":"GlobalNav_More_TechInnovation_MicrosoftCloud_nav","id":"n1c3c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c3c7c2c1c9c3c1m1r1a1"}'>Microsoft Cloud</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation__AI_cont","cT":"Container","id":"c4c7c2c1c9c3c1m1r1a1","sN":4,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_9" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/ai" data-m='{"cN":"GlobalNav_More_TechInnovation__AI_nav","id":"n1c4c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c4c7c2c1c9c3c1m1r1a1"}'>AI</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_AzureSpace_cont","cT":"Container","id":"c5c7c2c1c9c3c1m1r1a1","sN":5,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_10" class="js-subm-uhf-nav-link" href="https://azure.microsoft.com/en-us/solutions/space/" data-m='{"cN":"GlobalNav_More_TechInnovation_AzureSpace_nav","id":"n1c5c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c5c7c2c1c9c3c1m1r1a1"}'>Azure Space</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_MixedReality_cont","cT":"Container","id":"c6c7c2c1c9c3c1m1r1a1","sN":6,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_11" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/mixed-reality/windows-mixed-reality" data-m='{"cN":"GlobalNav_More_TechInnovation_MixedReality_nav","id":"n1c6c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c6c7c2c1c9c3c1m1r1a1"}'>Mixed reality</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_MicrosoftHololens_cont","cT":"Container","id":"c7c7c2c1c9c3c1m1r1a1","sN":7,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_12" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/hololens" data-m='{"cN":"GlobalNav_More_TechInnovation_MicrosoftHololens_nav","id":"n1c7c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c7c7c2c1c9c3c1m1r1a1"}'>Microsoft HoloLens</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_Microsoft Viva_cont","cT":"Container","id":"c8c7c2c1c9c3c1m1r1a1","sN":8,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_13" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/microsoft-viva" data-m='{"cN":"GlobalNav_More_TechInnovation_Microsoft Viva_nav","id":"n1c8c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c8c7c2c1c9c3c1m1r1a1"}'>Microsoft Viva</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_QuantumComputing_cont","cT":"Container","id":"c9c7c2c1c9c3c1m1r1a1","sN":9,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_14" class="js-subm-uhf-nav-link" href="https://azure.microsoft.com/en-us/solutions/quantum-computing/" data-m='{"cN":"GlobalNav_More_TechInnovation_QuantumComputing_nav","id":"n1c9c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c9c7c2c1c9c3c1m1r1a1"}'>Quantum computing</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_TechInnovation_Sustainability_cont","cT":"Container","id":"c10c7c2c1c9c3c1m1r1a1","sN":10,"aN":"c7c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_15" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/sustainability/" data-m='{"cN":"GlobalNav_More_TechInnovation_Sustainability_nav","id":"n1c10c7c2c1c9c3c1m1r1a1","sN":1,"aN":"c10c7c2c1c9c3c1m1r1a1"}'>Sustainability</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cT":"Container","id":"c8c2c1c9c3c1m1r1a1","sN":8,"aN":"c2c1c9c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_16-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn1c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c8c2c1c9c3c1m1r1a1"}'>Industries</span>
    <button id="uhf-navbtn-shellmenu_16-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn2c8c2c1c9c3c1m1r1a1","sN":2,"aN":"c8c2c1c9c3c1m1r1a1"}'>Industries</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_16-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Education_cont","cT":"Container","id":"c3c8c2c1c9c3c1m1r1a1","sN":3,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_17" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/education" data-m='{"cN":"GlobalNav_More_Industries_Education_nav","id":"n1c3c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c3c8c2c1c9c3c1m1r1a1"}'>Education</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Automotive_cont","cT":"Container","id":"c4c8c2c1c9c3c1m1r1a1","sN":4,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_18" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/automotive" data-m='{"cN":"GlobalNav_More_Industries_Automotive_nav","id":"n1c4c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c4c8c2c1c9c3c1m1r1a1"}'>Automotive</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Financialservices_cont","cT":"Container","id":"c5c8c2c1c9c3c1m1r1a1","sN":5,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_19" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/financial-services/banking" data-m='{"cN":"GlobalNav_More_Industries_Financialservices_nav","id":"n1c5c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c5c8c2c1c9c3c1m1r1a1"}'>Financial services</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Government_cont","cT":"Container","id":"c6c8c2c1c9c3c1m1r1a1","sN":6,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_20" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/government" data-m='{"cN":"GlobalNav_More_Industries_Government_nav","id":"n1c6c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c6c8c2c1c9c3c1m1r1a1"}'>Government</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Health_cont","cT":"Container","id":"c7c8c2c1c9c3c1m1r1a1","sN":7,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_21" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/health/microsoft-cloud-for-healthcare" data-m='{"cN":"GlobalNav_More_Industries_Health_nav","id":"n1c7c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c7c8c2c1c9c3c1m1r1a1"}'>Healthcare</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Manufacturing_cont","cT":"Container","id":"c8c8c2c1c9c3c1m1r1a1","sN":8,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_22" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/manufacturing/microsoft-cloud-for-manufacturing" data-m='{"cN":"GlobalNav_More_Industries_Manufacturing_nav","id":"n1c8c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c8c8c2c1c9c3c1m1r1a1"}'>Manufacturing</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Retail_cont","cT":"Container","id":"c9c8c2c1c9c3c1m1r1a1","sN":9,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_23" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry/consumer-goods" data-m='{"cN":"GlobalNav_More_Industries_Retail_nav","id":"n1c9c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c9c8c2c1c9c3c1m1r1a1"}'>Retail</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Industries_Allindustries_cont","cT":"Container","id":"c10c8c2c1c9c3c1m1r1a1","sN":10,"aN":"c8c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_24" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/industry" data-m='{"cN":"GlobalNav_More_Industries_Allindustries_nav","id":"n1c10c8c2c1c9c3c1m1r1a1","sN":1,"aN":"c10c8c2c1c9c3c1m1r1a1"}'>All industries</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cT":"Container","id":"c9c2c1c9c3c1m1r1a1","sN":9,"aN":"c2c1c9c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_25-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn1c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c9c2c1c9c3c1m1r1a1"}'>Partners</span>
    <button id="uhf-navbtn-shellmenu_25-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn2c9c2c1c9c3c1m1r1a1","sN":2,"aN":"c9c2c1c9c3c1m1r1a1"}'>Partners</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_25-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Partner_FindPartner_cont","cT":"Container","id":"c3c9c2c1c9c3c1m1r1a1","sN":3,"aN":"c9c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_26" class="js-subm-uhf-nav-link" href="https://partner.microsoft.com/en-US/" data-m='{"cN":"GlobalNav_More_Partner_FindPartner_nav","id":"n1c3c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c3c9c2c1c9c3c1m1r1a1"}'>Find a partner</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Partner_BecomePartner_cont","cT":"Container","id":"c4c9c2c1c9c3c1m1r1a1","sN":4,"aN":"c9c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_27" class="js-subm-uhf-nav-link" href="https://partner.microsoft.com/en-US/membership/cloud-solution-provider" data-m='{"cN":"GlobalNav_More_Partner_BecomePartner_nav","id":"n1c4c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c4c9c2c1c9c3c1m1r1a1"}'>Become a partner</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Partner_PartnerNetwork_cont","cT":"Container","id":"c5c9c2c1c9c3c1m1r1a1","sN":5,"aN":"c9c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_28" class="js-subm-uhf-nav-link" href="https://partner.microsoft.com/en-us/membership" data-m='{"cN":"GlobalNav_More_Partner_PartnerNetwork_nav","id":"n1c5c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c5c9c2c1c9c3c1m1r1a1"}'>Partner Network</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Partner_AzureMarketplace_cont","cT":"Container","id":"c6c9c2c1c9c3c1m1r1a1","sN":6,"aN":"c9c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_29" class="js-subm-uhf-nav-link" href="https://azuremarketplace.microsoft.com/en-us/" data-m='{"cN":"GlobalNav_More_Partner_AzureMarketplace_nav","id":"n1c6c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c6c9c2c1c9c3c1m1r1a1"}'>Azure Marketplace</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Partner_AppSource_cont","cT":"Container","id":"c7c9c2c1c9c3c1m1r1a1","sN":7,"aN":"c9c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_30" class="js-subm-uhf-nav-link" href="https://appsource.microsoft.com/en-us/" data-m='{"cN":"GlobalNav_More_Partner_AppSource_nav","id":"n1c7c9c2c1c9c3c1m1r1a1","sN":1,"aN":"c7c9c2c1c9c3c1m1r1a1"}'>AppSource</a>
            
        </li>
    </ul>
    
</li>
<li class="f-sub-menu js-nav-menu nested-menu" data-m='{"cT":"Container","id":"c10c2c1c9c3c1m1r1a1","sN":10,"aN":"c2c1c9c3c1m1r1a1"}'>

    <span id="uhf-navspn-shellmenu_31-span" style="display:none"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn1c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c10c2c1c9c3c1m1r1a1"}'>Resources</span>
    <button id="uhf-navbtn-shellmenu_31-button" type="button"   f-multi-parent="true" aria-expanded="false" data-m='{"id":"nn2c10c2c1c9c3c1m1r1a1","sN":2,"aN":"c10c2c1c9c3c1m1r1a1"}'>Resources</button>
    <ul aria-hidden="true" aria-labelledby="uhf-navspn-shellmenu_31-span">
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_Blog_cont","cT":"Container","id":"c3c10c2c1c9c3c1m1r1a1","sN":3,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_32" class="js-subm-uhf-nav-link" href="https://blogs.microsoft.com/" data-m='{"cN":"GlobalNav_More_Resources_Blog_nav","id":"n1c3c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c3c10c2c1c9c3c1m1r1a1"}'>Blog</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_MicrosoftAdvertising_cont","cT":"Container","id":"c4c10c2c1c9c3c1m1r1a1","sN":4,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_33" class="js-subm-uhf-nav-link" href="https://about.ads.microsoft.com/en-us?s_cid=dig-src_uhfcomm" data-m='{"cN":"GlobalNav_More_Resources_MicrosoftAdvertising_nav","id":"n1c4c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c4c10c2c1c9c3c1m1r1a1"}'>Microsoft Advertising</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_DeveloperCenter_cont","cT":"Container","id":"c5c10c2c1c9c3c1m1r1a1","sN":5,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_34" class="js-subm-uhf-nav-link" href="https://developer.microsoft.com/en-us/" data-m='{"cN":"GlobalNav_More_Resources_DeveloperCenter_nav","id":"n1c5c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c5c10c2c1c9c3c1m1r1a1"}'>Developer Center</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_Documentation_cont","cT":"Container","id":"c6c10c2c1c9c3c1m1r1a1","sN":6,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_35" class="js-subm-uhf-nav-link" href="https://learn.microsoft.com/docs/" data-m='{"cN":"GlobalNav_More_Resources_Documentation_nav","id":"n1c6c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c6c10c2c1c9c3c1m1r1a1"}'>Documentation</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_Events_cont","cT":"Container","id":"c7c10c2c1c9c3c1m1r1a1","sN":7,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_36" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/events" data-m='{"cN":"GlobalNav_More_Resources_Events_nav","id":"n1c7c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c7c10c2c1c9c3c1m1r1a1"}'>Events</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_Licensing_cont","cT":"Container","id":"c8c10c2c1c9c3c1m1r1a1","sN":8,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_37" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/licensing/" data-m='{"cN":"GlobalNav_More_Resources_Licensing_nav","id":"n1c8c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c8c10c2c1c9c3c1m1r1a1"}'>Licensing</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_MicrosoftLearn_cont","cT":"Container","id":"c9c10c2c1c9c3c1m1r1a1","sN":9,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_38" class="js-subm-uhf-nav-link" href="https://learn.microsoft.com/" data-m='{"cN":"GlobalNav_More_Resources_MicrosoftLearn_nav","id":"n1c9c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c9c10c2c1c9c3c1m1r1a1"}'>Microsoft Learn</a>
            
        </li>
        <li class="js-nav-menu single-link" data-m='{"cN":"More_Resources_MicrosoftResearch_cont","cT":"Container","id":"c10c10c2c1c9c3c1m1r1a1","sN":10,"aN":"c10c2c1c9c3c1m1r1a1"}'>
            <a id="shellmenu_39" class="js-subm-uhf-nav-link" href="https://www.microsoft.com/en-us/research/" data-m='{"cN":"GlobalNav_More_Resources_MicrosoftResearch_nav","id":"n1c10c10c2c1c9c3c1m1r1a1","sN":1,"aN":"c10c10c2c1c9c3c1m1r1a1"}'>Microsoft Research</a>
            
        </li>
    </ul>
    
</li>
                                                            <li class="f-multi-column-info">
                                    <a data-m='{"id":"n11c2c1c9c3c1m1r1a1","sN":11,"aN":"c2c1c9c3c1m1r1a1"}' href="https://www.microsoft.com/en-us/sitemap" aria-label="" class="c-glyph">View Sitemap</a>
                                </li>
                            
                        </ul>
                    </div>
                </li>
            </ul>
        </nav>
</div>
                            <form class="c-search" autocomplete="off" id="searchForm" name="searchForm" role="search" action="/en-us/research/search/" method="GET" data-seAutoSuggest='{"isAutosuggestDisabled":true,"queryParams":{"market":"en-us","clientId":"7F27B536-CF6B-4C65-8638-A0F8CBDFCA65","sources":"Microsoft-Terms,Iris-Products,DCatAll-Products","filter":"+ClientType:StoreWeb","counts":"5,1,5"},"familyNames":{"Apps":"App","Books":"Book","Bundles":"Bundle","Devices":"Device","Fees":"Fee","Games":"Game","MusicAlbums":"Album","MusicTracks":"Song","MusicVideos":"Video","MusicArtists":"Artist","OperatingSystem":"Operating System","Software":"Software","Movies":"Movie","TV":"TV","CSV":"Gift Card","VideoActor":"Actor"}}' data-seautosuggestapi="https://www.microsoft.com/msstoreapiprod/api/autosuggest" data-m='{"cN":"GlobalNav_Search_cont","cT":"Container","id":"c3c1c9c3c1m1r1a1","sN":3,"aN":"c1c9c3c1m1r1a1"}' aria-expanded="false">
                                <input  id="cli_shellHeaderSearchInput" aria-label="Search Expanded" aria-expanded="false" aria-controls="universal-header-search-auto-suggest-transparent" aria-owns="universal-header-search-auto-suggest-ul" type="search" name="q" placeholder="Search Microsoft Research" data-m='{"cN":"SearchBox_nav","id":"n1c3c1c9c3c1m1r1a1","sN":1,"aN":"c3c1c9c3c1m1r1a1"}' data-toggle="tooltip" data-placement="right" title="Search Microsoft Research" />
                                    <button id="search" aria-label="Search Microsoft Research" class="c-glyph" data-m='{"cN":"Search_nav","id":"n2c3c1c9c3c1m1r1a1","sN":2,"aN":"c3c1c9c3c1m1r1a1"}' data-bi-mto="true" aria-expanded="false" disabled="disabled">
                                        <span role="presentation">Search</span>
                                        <span role="tooltip" class="c-uhf-tooltip c-uhf-search-tooltip">Search Microsoft Research</span>
                                    </button>
                                <div class="m-auto-suggest" id="universal-header-search-auto-suggest-transparent" role="group">
                                    <ul class="c-menu" id="universal-header-search-auto-suggest-ul" aria-label="Search Suggestions" aria-hidden="true" data-bi-dnt="true" data-bi-mto="true" data-js-auto-suggest-position="default" role="listbox" data-tel="jsll" data-m='{"cN":"search suggestions_cont","cT":"Container","id":"c3c3c1c9c3c1m1r1a1","sN":3,"aN":"c3c1c9c3c1m1r1a1"}'></ul>
                                    <ul class="c-menu f-auto-suggest-no-results" aria-hidden="true" data-js-auto-suggest-postion="default" data-js-auto-suggest-position="default" role="listbox">
                                        <li class="c-menu-item"> <span tabindex="-1">No results</span></li>
                                    </ul>
                                </div>
                                
                            </form>
                        <button data-m='{"cN":"cancel-search","pid":"Cancel Search","id":"nn4c1c9c3c1m1r1a1","sN":4,"aN":"c1c9c3c1m1r1a1"}' id="cancel-search" class="cancel-search" aria-label="Cancel Search">
                            <span>Cancel</span>
                        </button>
                
            </div>
        </div>
        
        
    </div>
    
</header>




    </div>
        </div>

    </div>				</uhf_header>

					</div>

		
	<main class="event" data-bi-aN="body" awa-sitesection="event single" id="main" role="main">
			
<div class="wp-block-cover is-light has-white-color has-text-color has-link-color wp-elements-4cf2924f716642350f12f0005580e4dd" style="min-height:25vw;aspect-ratio:unset;"><img fetchpriority="high" decoding="async" width="1024" height="384" class="wp-block-cover__image-background wp-image-1147621 size-large" alt="Research Forum | Episode 5 - abstract background with colorful hexagons" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-1024x384.jpg" data-object-fit="cover" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-1024x384.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-300x113.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-768x288.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-1536x576.jpg 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-1600x600.jpg 1600w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final-240x90.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Research-Forum_header_1920x720-final.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" /><span aria-hidden="true" class="wp-block-cover__background has-purple-background-color has-background-dim-0 has-background-dim"></span><div class="wp-block-cover__inner-container is-layout-constrained wp-container-core-cover-is-layout-d9fd7b74 wp-block-cover-is-layout-constrained">
<p></p>



<h1 class="wp-block-heading has-black-color has-text-color has-link-color wp-elements-f254dc4be67571fc8d14c3bae3d299c8" id="microsoft-research-forum">Microsoft Research Forum</h1>



<p class="has-black-color has-text-color has-link-color wp-elements-d2f5b57c698943b521515c0f3b590be0">Location: Virtual</p>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://register.researchforum.microsoft.com/" target="_blank" rel="noreferrer noopener">Register for the series</a></div>
</div>
</div></div>


<div class="wp-block-msr-content-tabs container mt-3 mb-0" data-bi-aN="content">
	<section class="row" data-bi-tN="content-tabs">

		<nav class="nav-container col-12 px-4 px-lg-0" aria-label="Subpage navigation">
			<ul class="nav my-4">
						<li class="nav-item active">
					<a
						id="tab-overview-tab"
													aria-label="Active page: Overview"
												class="nav-link"
												href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/"
						data-bi-cN="Overview"
						data-bi-type="tab"
						data-bi-tN="content-tab"
					>
						Overview					</a>
				</li>
							<li class="nav-item ">
					<a
						id="tab-past-episodes-tab"
												class="nav-link"
												href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/past-episodes/"
						data-bi-cN="Past episodes"
						data-bi-type="tab"
						data-bi-tN="content-tab"
					>
						Past episodes					</a>
				</li>
						</ul>
		</nav>
		<div class="col-12 px-4 px-lg-0">
									<div
							class="tab-pane fade pl-0 col-12 active show"
							id="overview"
							data-bi-aN="Overview"
						>
							
<div style="padding-bottom:32px; padding-top:32px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__wrapper">
			<h2 class="wp-block-heading has-text-align-center h3" id="microsoft-research-forum-is-a-virtual-series-highlighting-purposeful-research-and-its-real-world-impact-from-fundamental-exploration-to-advancing-ai-responsibly-scaling-innovation-through-products-and-open-source-and-driving-positive-change-for-society">Microsoft Research Forum is a virtual series highlighting purposeful research and its real-world impact, from fundamental exploration to advancing AI responsibly, scaling innovation through products and open source, and driving positive change for society.</h2>



<div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div>		</div>
	</div>

	</div>

<div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__wrapper col-lg-11 col-xl-9 px-0 m-auto">
			<h2 class="wp-block-heading has-text-align-center" id="season-2-episode-1">Season 2 | Episode 1</h2>



<p class="has-text-align-center"><strong>Wednesday, September 24, 2025 | 8:00 AM &#8211; 9:00 AM Pacific Time</strong></p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-16018d1d wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--1"><a data-bi-type="button" class="wp-block-button__link has-black-color has-text-color has-link-color wp-element-button" href="https://register.researchforum.microsoft.com/" target="_blank" rel="noreferrer noopener">Register now</a></div>
</div>		</div>
	</div>

	<img decoding="async" width="1600" height="600" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1.jpg" class="wp-block-msr-immersive-section__background-image" alt="Forum | purple background with black pencil drawings" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1.jpg 1600w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1-300x113.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1-1024x384.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1-768x288.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1-1536x576.jpg 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-Web-Banner-1600x600-1-240x90.jpg 240w" sizes="(max-width: 1600px) 100vw, 1600px" /></div>

<div style="padding-bottom:32px; padding-top:32px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__wrapper">
			<h2 class="wp-block-heading has-text-align-center is-style-default" id="ai-in-organizational-settings">Agenda</h2>



<div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMojan-Javaheripi-150x150.png" alt="Mojan Javaheripi" class="wp-image-1148745" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMojan-Javaheripi-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMojan-Javaheripi-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMojan-Javaheripi-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMojan-Javaheripi.png 360w" sizes="(max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/mojavaheripi/">Mojan Javaheripi</a><br>Member of Technical Staff<br><em>Microsoft Research AI Frontiers</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p><sub>TALK | IMPACT AT SCALE</sub></p>



<p><strong>Pushing boundaries of complex reasoning in small language models</strong></p>



<p>This talk explores Phi-4-Reasoning and Phi-4-Reasoning-Plus—two 14B models designed to push the boundaries of complex reasoning in small language models. By introducing a dedicated “thinking block” into the model response and applying supervised fine-tuning and reinforcement learning on carefully curated, reasoning-intensive STEM datasets, we achieved significant advances in the models’ problem-solving capabilities.</p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsKwangjin-Ahn-150x150.png" alt="Kwangjun Ahn" class="wp-image-1148743" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsKwangjin-Ahn-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsKwangjin-Ahn-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsKwangjin-Ahn-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsKwangjin-Ahn.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/kwangjunahn/">Kwangjun Ahn</a><br>Senior Researcher<br><em>Microsoft Research AI Frontiers</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p><sub>TALK | MISSION ON AI</sub></p>



<p><strong>Dion: The distributed orthonormal update revolution is here</strong></p>



<p>We introduce Dion, an orthonormal-update optimizer in the style of Muon that adds a tunable rank axis—orthonormalizing only the top-r subspace via amortized power iteration—to retain Muon’s fast convergence while significantly reducing compute and communication, and scaling efficiently with FSDP/TP for very large models.</p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsPaolo-Costa-150x150.png" alt="Paolo Costa" class="wp-image-1148746" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsPaolo-Costa-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsPaolo-Costa-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsPaolo-Costa-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsPaolo-Costa.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/pcosta/">Paolo Costa</a><br>Partner Research Manager<br><em>Microsoft Research Cambridge</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p><sub>TALK | NEW ADVANCEMENT OUT OF THE LAB</sub></p>



<p><strong>Disrupting the AI Infrastructure with MicroLEDs</strong></p>



<p>The performance of modern AI systems is increasingly constrained by limitations in memory and network resources, driven by fundamental scaling challenges in current communication technologies. Copper links are power-efficient and reliable but have very limited reach (< 2 m). Optical links offer longer reach but at the expense of high-power consumption and lower reliability. A collaborative effort across MSR, Azure Networking, Azure Hardware, and M365 has been investigating the use of microLEDs to develop a novel technology that can break this trade-off by providing high-distance connectivity with low power consumption, low cost, and high reliability, opening up exciting opportunities for radical new AI cluster designs.</p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsFrank-Noe-150x150.png" alt="Frank Noé" class="wp-image-1148742" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsFrank-Noe-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsFrank-Noe-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsFrank-Noe-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsFrank-Noe.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/franknoe/">Frank Noé</a><br>Partner Research Manager<br><em>Microsoft Research AI for Science</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p><sub>TALK | AI FOR ALL</sub></p>



<p><strong>Scalable emulation of protein equilibrium ensembles with BioEmu</strong></p>



<p>The next frontier in molecular biology is predicting how biomolecules change shape to drive biological function, a key step for drug discovery. MSR AI for Science’s Biomolecular Emulator (BioEmu) recently reached a major milestone, emulating protein structure changes and stabilities with near-experimental accuracy while running up to 100,000x faster than traditional simulations.</p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%"></div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsAlexandra-Olteanu-150x150.png" alt="Alexandra Olteanu" class="wp-image-1148747" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsAlexandra-Olteanu-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsAlexandra-Olteanu-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsAlexandra-Olteanu-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsAlexandra-Olteanu.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/aloltea/">Alexandra Olteanu</a><br>Principal Researcher<br><em><em>Microsoft Research Montréal</em></em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsSu-Lin-Blodgett-150x150.png" alt="Su Lin Blodgett" class="wp-image-1148741" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsSu-Lin-Blodgett-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsSu-Lin-Blodgett-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsSu-Lin-Blodgett-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsSu-Lin-Blodgett.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/sublodge/">Su Lin Blodgett</a><br>Senior Researcher<br><em>Microsoft Research Montréal</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p><sub>TALK | RESEARCH EXPLORATION</sub></p>



<p><strong>Dehumanizing machines: Making sense of AI systems that seem human</strong></p>



<p>GenAI systems are the focus of growing scrutiny in part because they are increasingly anthropomorphic—i.e., they are designed or perceived to be human-like. Guiding practitioners in appropriately and deliberately designing anthropomorphic AI systems requires equipping them with clarity regarding what about these systems&#8217; design and behavior makes them anthropomorphic, and which design decisions and system behaviors are desirable and effective.</p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%"></div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:15%">
<figure class="wp-block-image aligncenter size-thumbnail is-style-rounded"><img loading="lazy" decoding="async" width="150" height="150" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMaya-Murad-150x150.png" alt="Maya Murad" class="wp-image-1148744" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMaya-Murad-150x150.png 150w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMaya-Murad-300x300.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMaya-Murad-180x180.png 180w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/RF-S2E1-HeadshotsMaya-Murad.png 360w" sizes="auto, (max-width: 150px) 100vw, 150px" /><figcaption class="wp-element-caption"><a href="https://www.microsoft.com/en-us/research/people/mayamurad/">Maya Murad</a><br>Senior Technical Program Manager<br><em>Microsoft Research AI Frontiers</em></figcaption></figure>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:50%">
<p></p>



<p><strong>Host remarks</strong></p>



<p></p>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow" style="flex-basis:10%">
<p></p>
</div>
</div>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-16018d1d wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-fill"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/past-episodes/">All Research Forum sessions</a></div>
</div>		</div>
	</div>

	</div>

<div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__wrapper">
			<h2 class="wp-block-heading has-text-align-center" id="explore-more-about-microsoft-research">Explore more about Microsoft Research</h2>


<div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left has-cards" data-bi-aN="Cards">
	<div class="msr-cards__inner">
		
					<div class="mt-4">
				<ul class="my-0 list-unstyled row row-cols-1 row-cols-sm-2 row-cols-lg-4">
	<li class="my-0 msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

					<div class="embed-responsive embed-responsive-16by9">
				<img loading="lazy" decoding="async" width="380" height="214" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-640x360.png" class="card-img embed-responsive-item img-object-cover" alt="Ask Microsoft research copilot experience" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-640x360.png 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-300x169.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-1024x576.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-768x432.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-1066x600.png 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-655x368.png 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-343x193.png 343w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-240x135.png 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-960x540.png 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo-1280x720.png 1280w, https://www.microsoft.com/en-us/research/wp-content/uploads/2024/01/MSR-Chat-Promo.png 1400w" sizes="auto, (max-width: 380px) 100vw, 380px" />			</div>
		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a href="https://msrchat.azurewebsites.net/?ocid=msr_researchforum_homepage_copilot" data-bi-cN="Interact with Microsoft Research Chat" target="_blank" rel="noopener noreferrer" class="text-decoration-none text-black"><span>Interact with Microsoft Research Chat</span>&nbsp;<span class="glyph-in-link glyph-append glyph-append-open-in-new-tab" aria-hidden="true"></span></a>				</h3>
			

			<div class="card__description card__citation small">
									<p>Discover more about research at Microsoft through our AI-powered experience.</p>				
							</div>
		</div>
	</div>
</li>
<li class="my-0 msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

					<div class="embed-responsive embed-responsive-16by9">
				<img loading="lazy" decoding="async" width="380" height="214" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-640x360.jpg" class="card-img embed-responsive-item img-object-cover" alt="three people talking in a relaxed setting" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Careers_16-9.jpg 1200w" sizes="auto, (max-width: 380px) 100vw, 380px" />			</div>
		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a href="https://www.microsoft.com/en-us/research/careers/" data-bi-cN="Explore careers in research" class="text-decoration-none text-black"><span>Explore careers in research</span>&nbsp;<span class="glyph-in-link glyph-append glyph-append-chevron-right" aria-hidden="true"></span></a>				</h3>
			

			<div class="card__description card__citation small">
									<p>Join a brilliant team of researchers and engineers working to solve technology’s most exciting challenges.</p>				
							</div>
		</div>
	</div>
</li>
<li class="my-0 msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

					<div class="embed-responsive embed-responsive-16by9">
				<img loading="lazy" decoding="async" width="380" height="214" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-640x360.png" class="card-img embed-responsive-item img-object-cover" alt="background pattern with blue and purple layers" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-640x360.png 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-300x169.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-1024x576.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-768x432.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-1066x600.png 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-655x368.png 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-240x135.png 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9-960x540.png 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-MSR-Blog_16-9.png 1200w" sizes="auto, (max-width: 380px) 100vw, 380px" />			</div>
		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a href="https://www.microsoft.com/en-us/research/blog/" data-bi-cN="Microsoft Research Blog" class="text-decoration-none text-black"><span>Microsoft Research Blog</span>&nbsp;<span class="glyph-in-link glyph-append glyph-append-chevron-right" aria-hidden="true"></span></a>				</h3>
			

			<div class="card__description card__citation small">
									<p>The latest news and insights from Microsoft Research, covering topics such as AI, data science, machine learning, human-computer interaction, and more.</p>				
							</div>
		</div>
	</div>
</li>
<li class="my-0 msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0">

					<div class="embed-responsive embed-responsive-16by9">
				<img loading="lazy" decoding="async" width="380" height="214" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-640x360.png" class="card-img embed-responsive-item img-object-cover" alt="background pattern with transparent yellow and blue layers" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-640x360.png 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-300x169.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-1024x576.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-768x432.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-1066x600.png 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-655x368.png 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-240x135.png 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9-960x540.png 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/Forum-explore-Azure-AI-Foundry_16-9.png 1200w" sizes="auto, (max-width: 380px) 100vw, 380px" />			</div>
		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a href="https://ai.azure.com/" data-bi-cN="Microsoft Azure AI Foundry" target="_blank" rel="noopener noreferrer" class="text-decoration-none text-black"><span>Microsoft Azure AI Foundry</span>&nbsp;<span class="glyph-in-link glyph-append glyph-append-open-in-new-tab" aria-hidden="true"></span></a>				</h3>
			

			<div class="card__description card__citation small">
									<p>Explore and experiment with the latest research innovations at Azure AI Foundry</p>				
							</div>
		</div>
	</div>
</li>
</ul>
			</div>
		
			</div>
</div>		</div>
	</div>

	<img loading="lazy" decoding="async" width="1600" height="600" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2.png" class="wp-block-msr-immersive-section__background-image" alt="background pattern" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2.png 1600w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2-300x113.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2-1024x384.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2-768x288.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2-1536x576.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/forum-background_1600x600_2-240x90.png 240w" sizes="auto, (max-width: 1600px) 100vw, 1600px" /></div>

<div style="padding-bottom:32px; padding-top:32px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__wrapper col-lg-11 col-xl-9 px-0 m-auto">
			<h2 class="wp-block-heading has-text-align-center has-white-color has-text-color has-link-color wp-elements-07f22b3da697602d0fa22f1a7ecde984" id="microsoft-research-forum">Microsoft Research Forum</h2>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-16018d1d wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://register.researchforum.microsoft.com/" target="_blank" rel="noreferrer noopener">Register for the series</a></div>



<div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/faq/">Series FAQ</a></div>
</div>		</div>
	</div>

	<img loading="lazy" decoding="async" width="1600" height="600" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720.jpg" class="wp-block-msr-immersive-section__background-image" alt="dark blue watercolor background" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720.jpg 1920w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-300x113.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-1024x384.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-768x288.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-1536x576.jpg 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-1600x600.jpg 1600w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/MRF_MCR_LowerPromoBanner_1920x720-240x90.jpg 240w" sizes="auto, (max-width: 1600px) 100vw, 1600px" /></div>
						</div>
								</div>
	</section>


</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</main>

<div ms.pgarea="social" data-moray>
	<section class="msr-social msr-social--footer py-3" role="region" aria-label="Social media links"
			 data-bi-aN="SocialMediaLinks">
		<div class="ms-grid container">
			<div class="row">
				<div class="col-12 col-md-6 msr-social-col msr-social-col--follow">
					<div class="d-flex flex-row flex-wrap align-items-center">
						<p class="mr-2 mb-0" id="msr-follow-us-footer">
							Follow us:						</p>
						<ul class="list-unstyled d-inline-flex flex-row-auto gap-2 align-items-center mb-0" aria-labelledby="msr-follow-us-footer">
							<li class="mr-0 mb-0 p-1">
								<a
									href="
									https://x.com/intent/follow?original_referrer=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F&#038;screen_name=MSFTResearch									"
									data-bi-slot="0"
									data-bi-cN="Follow on X"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Follow on X</span>
									<svg width="22" height="19" viewBox="0 0 1200 1227" fill="none" xmlns="http://www.w3.org/2000/svg">
										<path d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z" fill="currentColor"/>
									</svg>
								</a>
							</li>

							<li class="mr-0 mb-0 p-1">
								<a
									href="https://www.facebook.com/microsoftresearch/"
									data-bi-slot="1"
									data-bi-cN="Like on Facebook"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Like on Facebook</span>
									<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" width="22" viewbox="0 0 32 32">
										<path style="fill: currentColor;" d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"
											  class="block"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a
									href="https://www.linkedin.com/showcase/microsoftresearch/"
									data-bi-slot="5"
									data-bi-cN="Follow on LinkedIn"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Follow on LinkedIn</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" preserveAspectRatio="xMidYMid meet"  aria-hidden="true" width="24" viewbox="0 0 32 32">
										<path style="fill: currentColor;" d="M12 12h5.535v2.837h.079c.77-1.381 2.655-2.837 5.464-2.837C28.92 12 30 15.637 30 20.367V30h-5.769v-8.54c0-2.037-.042-4.657-3.001-4.657-3.005 0-3.463 2.218-3.463 4.509V30H12V12zM2 12h6v18H2V12zM8 7a3 3 0 1 1-6 0 3 3 0 0 1 6 0z"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a
									href="https://www.youtube.com/user/MicrosoftResearch"
									data-bi-slot="2"
									data-bi-cN="Subscribe on Youtube"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Subscribe on Youtube</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" aria-hidden="true" width="22" viewBox="0 0 32 32">
										<path style="fill: currentColor;" d="M31.681 9.6s-.313-2.206-1.275-3.175C29.187 5.15 27.825 5.144 27.2 5.069c-4.475-.325-11.194-.325-11.194-.325h-.012s-6.719 0-11.194.325c-.625.075-1.987.081-3.206 1.356C.631 7.394.325 9.6.325 9.6s-.319 2.588-.319 5.181v2.425c0 2.587.319 5.181.319 5.181s.313 2.206 1.269 3.175c1.219 1.275 2.819 1.231 3.531 1.369 2.563.244 10.881.319 10.881.319s6.725-.012 11.2-.331c.625-.075 1.988-.081 3.206-1.356.962-.969 1.275-3.175 1.275-3.175s.319-2.587.319-5.181v-2.425c-.006-2.588-.325-5.181-.325-5.181zM12.694 20.15v-8.994l8.644 4.513-8.644 4.481z"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a
									href="https://www.instagram.com/msft_research/"
									data-bi-slot="3"
									data-bi-cN="Follow on Instagram"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Follow on Instagram</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" aria-hidden="true" width="22" viewBox="0 0 32 32">
										<path style="fill: currentColor;" d="M30 0H2C.895 0 0 .894 0 2v28c0 1.105.894 2 2 2h28a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2zM12 16s.316-4 4-4 4 4 4 4 .115 4-4 4-4-4-4-4zm16 12H4V14h4.283C8.117 14.643 8 15.305 8 16a8 8 0 0 0 16 0c0-.695-.117-1.357-.283-2H28v14zm0-18h-6V4h6v6z"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a
									href="https://www.microsoft.com/en-us/research/feed/"
									data-bi-slot="4"
									data-bi-cN="Subscribe to our RSS feed"
									data-bi-type="social-link"
									data-bi-tN="social-follow"
									data-bi-bhvr="126"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Subscribe to our RSS feed</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" aria-hidden="true" width="22" viewBox="0 0 32 32">
										<path style="fill: currentColor;" d="M4.259 23.467A4.265 4.265 0 0 0 0 27.719a4.25 4.25 0 0 0 4.259 4.244 4.25 4.25 0 0 0 4.265-4.244 4.265 4.265 0 0 0-4.265-4.252zM.005 10.873v6.133c3.993 0 7.749 1.562 10.577 4.391A14.897 14.897 0 0 1 14.966 32h6.16c0-11.651-9.478-21.127-21.121-21.127zM.012 0v6.136C14.255 6.136 25.848 17.74 25.848 32H32C32 14.36 17.648 0 .012 0z"/>
									</svg>
								</a>
							</li>
						</ul>
					</div>
				</div><!--/.col-->

				<div class="col-12 col-md-6 msr-social-col msr-social-col--share mt-3 mt-md-0">
					<div class="d-flex flex-row flex-wrap align-items-center">
						<p class="mr-3 mb-0" id="msr-share-footer">
							Share this page:						</p>
						<ul class="list-unstyled d-flex gap-2 align-items-center mb-0" aria-labelledby="msr-share-footer">

							<li class="mr-0 mb-0 p-1">
								
								<a
									href="
									https://x.com/intent/tweet?text=Microsoft%20Research%20Forum&#038;url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F									"
									data-bi-slot="5"
									data-bi-cN="Share on X"
									data-bi-type="social-link"
									data-bi-tN="social-share"
									data-bi-bhvr="120"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Share on X</span>
									<svg width="22" height="19" viewBox="0 0 1200 1227" fill="none" xmlns="http://www.w3.org/2000/svg">
										<path d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z" fill="currentColor"/>
									</svg>
								</a>
							</li>

							<li class="mr-0 mb-0 p-1">
								<a
									href="
									https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F									"
									data-bi-slot="6"
									data-bi-cN="Share on Facebook"
									data-bi-type="social-link"
									data-bi-tN="social-share"
									data-bi-bhvr="120"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block">
									<span class="sr-only">Share on Facebook</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" aria-hidden="true" width="22" viewbox="0 0 32 32">
										<path style="fill: currentColor;" d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"
											  class="block"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a
									href="
									https://www.linkedin.com/shareArticle?mini=true&#038;url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F&#038;title=Microsoft%20Research%20Forum&#038;summary=Microsoft%20Research%20Forum&#038;source=Microsoft%20Research									"
									data-bi-slot="7"
									data-bi-cN="Share on LinkedIn"
									data-bi-type="social-link"
									data-bi-tN="social-share"
									data-bi-bhvr="120"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Share on LinkedIn</span>
									<svg xmlns="http://www.w3.org/2000/svg" class=" preserveAspectRatio="xMidYMid meet"  aria-hidden="true" width="24" viewbox="0 0 32 32">
										<path style="fill: currentColor;" d="M12 12h5.535v2.837h.079c.77-1.381 2.655-2.837 5.464-2.837C28.92 12 30 15.637 30 20.367V30h-5.769v-8.54c0-2.037-.042-4.657-3.001-4.657-3.005 0-3.463 2.218-3.463 4.509V30H12V12zM2 12h6v18H2V12zM8 7a3 3 0 1 1-6 0 3 3 0 0 1 6 0z"/>
									</svg>
								</a>
							</li>

							<li class="mb-0 p-1">
								<a href="
									http://www.reddit.com/submit?title=Microsoft%20Research%20Forum&#038;url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fevent%2Fmicrosoft-research-forum%2F									"
									data-bi-slot="8"
									data-bi-cN="Share on Reddit"
									data-bi-type="social-link"
									data-bi-tN="social-share"
									data-bi-bhvr="120"
									target="_blank"
									rel="noopener noreferrer"
									class="d-block"
								>
									<span class="sr-only">Share on Reddit</span>
									<svg xmlns="http://www.w3.org/2000/svg" class="block" aria-hidden="true" width="22" viewBox="0 0 32 32">
										<path style="fill: currentColor;" d="M8 20a2 2 0 1 1 3.999-.001A2 2 0 0 1 8 20zm12 0a2 2 0 1 1 3.999-.001A2 2 0 0 1 20 20zm.097 4.274a1.188 1.188 0 0 1 1.47 1.866C20.133 27.27 17.948 28 16 28s-4.133-.73-5.567-1.86a1.188 1.188 0 0 1 1.47-1.866c.826.651 2.46 1.351 4.097 1.351s3.271-.7 4.097-1.351zM32 16a4 4 0 0 0-7.495-1.943c-2.056-1.125-4.561-1.851-7.29-2.019l2.387-5.36 4.569 1.319a3 3 0 1 0 .188-2.417l-5.091-1.47a1.187 1.187 0 0 0-1.414.658l-3.243 7.282c-2.661.187-5.102.907-7.114 2.007a4 4 0 1 0-5.109 5.603 7.334 7.334 0 0 0-.387 2.341c0 5.523 6.268 10 14 10s14-4.477 14-10a7.3 7.3 0 0 0-.387-2.34 4 4 0 0 0 2.387-3.66zM27 5.875a1.125 1.125 0 1 1 0 2.25 1.125 1.125 0 0 1 0-2.25zM2 16c0-1.103.897-2 2-2 .797 0 1.487.469 1.808 1.145-1.045.793-1.911 1.707-2.552 2.711A2.003 2.003 0 0 1 2 16zm14 13.625c-6.42 0-11.625-3.414-11.625-7.625S9.58 14.375 16 14.375 27.625 17.789 27.625 22 22.42 29.625 16 29.625zm12.744-11.769c-.641-1.003-1.507-1.918-2.552-2.711A2.003 2.003 0 0 1 28 14c1.103 0 2 .897 2 2 0 .84-.52 1.56-1.256 1.856z"/>
									</svg>
								</a>
							</li>
						</ul>
					</div>

				</div><!--/.col-->
			</div><!--/.ms-row-->
		</div><!--/.ms-grid-->
	</section><!--/.ms-social-->
</div>
		<div id="playerModal" class="mfp-hide">
			<div id="player"></div>
		</div>

		<div id="mq"></div>

		
		<span data-no-translation>
			<div id="footerArea" class="uhf"  data-m='{"cN":"footerArea","cT":"Area_coreuiArea","id":"a2Body","sN":2,"aN":"Body"}'>
                <div id="footerRegion"      data-region-key="footerregion" data-m='{"cN":"footerRegion","cT":"Region_coreui-region","id":"r1a2","sN":1,"aN":"a2"}' >

    <div  id="footerUniversalFooter" data-m='{"cN":"footerUniversalFooter","cT":"Module_coreui-universalfooter","id":"m1r1a2","sN":1,"aN":"r1a2"}'  data-module-id="Category|footerRegion|coreui-region|footerUniversalFooter|coreui-universalfooter">
        



<footer id="uhf-footer" class="c-uhff context-uhf"  data-uhf-mscc-rq="false" data-footer-footprint="/MSRESEARCH/global-default-footer, fromService: True" data-m='{"cN":"Uhf footer_cont","cT":"Container","id":"c1m1r1a2","sN":1,"aN":"m1r1a2"}'>
        <nav class="c-uhff-nav" aria-label="Footer Resource links" data-m='{"cN":"Footer nav_cont","cT":"Container","id":"c1c1m1r1a2","sN":1,"aN":"c1m1r1a2"}'>
            
                <div class="c-uhff-nav-row">
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn1_cont","cT":"Container","id":"c1c1c1m1r1a2","sN":1,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">What&#39;s new</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Surface Pro What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/surface/devices/surface-pro" data-m='{"cN":"Footer_WhatsNew_NewSurfacePro_nav","id":"n1c1c1c1m1r1a2","sN":1,"aN":"c1c1c1m1r1a2"}'>Surface Pro</a>
                            </li>
                            <li>
                                <a aria-label="Surface Laptop What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/surface/devices/surface-laptop" data-m='{"cN":"Footer_WhatsNew_SurfaceLaptop_nav","id":"n2c1c1c1m1r1a2","sN":2,"aN":"c1c1c1m1r1a2"}'>Surface Laptop</a>
                            </li>
                            <li>
                                <a aria-label="Surface Laptop Studio 2 What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/en-us/d/Surface-Laptop-Studio-2/8rqr54krf1dz" data-m='{"cN":"Footer_WhatsNew_SurfaceLaptopStudio2_nav","id":"n3c1c1c1m1r1a2","sN":3,"aN":"c1c1c1m1r1a2"}'>Surface Laptop Studio 2</a>
                            </li>
                            <li>
                                <a aria-label="Copilot for organizations What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-copilot/organizations?icid=DSM_Footer_CopilotOrganizations" data-m='{"cN":"Footer_WhatsNew_CopilotMicrosoft_nav","id":"n4c1c1c1m1r1a2","sN":4,"aN":"c1c1c1m1r1a2"}'>Copilot for organizations</a>
                            </li>
                            <li>
                                <a aria-label="Copilot for personal use What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-copilot/for-individuals?icid=DSM_Footer_CopilotPersonal" data-m='{"cN":"Footer_WhatsNew_CopilotMicrosoft_nav","id":"n5c1c1c1m1r1a2","sN":5,"aN":"c1c1c1m1r1a2"}'>Copilot for personal use</a>
                            </li>
                            <li>
                                <a aria-label="AI in Windows What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/en-us/windows/copilot-ai-features" data-m='{"cN":"Whatsnew_AIinWindows_nav","id":"n6c1c1c1m1r1a2","sN":6,"aN":"c1c1c1m1r1a2"}'>AI in Windows</a>
                            </li>
                            <li>
                                <a aria-label="Explore Microsoft products What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-products-and-apps" data-m='{"cN":"Footer_WhatsNew_ExploreMicrosoftProducts_nav","id":"n7c1c1c1m1r1a2","sN":7,"aN":"c1c1c1m1r1a2"}'>Explore Microsoft products</a>
                            </li>
                            <li>
                                <a aria-label="Windows 11 apps What&#39;s new" class="c-uhff-link" href="https://www.microsoft.com/windows/windows-11-apps" data-m='{"cN":"Footer_WhatsNew_Windows_11_apps_nav","id":"n8c1c1c1m1r1a2","sN":8,"aN":"c1c1c1m1r1a2"}'>Windows 11 apps</a>
                            </li>

                        </ul>
                        
                    </div>
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn2_cont","cT":"Container","id":"c2c1c1m1r1a2","sN":2,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">Microsoft Store</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Account profile Microsoft Store" class="c-uhff-link" href="https://account.microsoft.com/" data-m='{"cN":"Footer_StoreandSupport_AccountProfile_nav","id":"n1c2c1c1m1r1a2","sN":1,"aN":"c2c1c1m1r1a2"}'>Account profile</a>
                            </li>
                            <li>
                                <a aria-label="Download Center Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/download" data-m='{"cN":"Footer_StoreandSupport_DownloadCenter_nav","id":"n2c2c1c1m1r1a2","sN":2,"aN":"c2c1c1m1r1a2"}'>Download Center</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Store support Microsoft Store" class="c-uhff-link" href="https://go.microsoft.com/fwlink/?linkid=2139749" data-m='{"cN":"Footer_StoreandSupport_SalesAndSupport_nav","id":"n3c2c1c1m1r1a2","sN":3,"aN":"c2c1c1m1r1a2"}'>Microsoft Store support</a>
                            </li>
                            <li>
                                <a aria-label="Returns Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/returns" data-m='{"cN":"Footer_StoreandSupport_Returns_nav","id":"n4c2c1c1m1r1a2","sN":4,"aN":"c2c1c1m1r1a2"}'>Returns</a>
                            </li>
                            <li>
                                <a aria-label="Order tracking Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/order-tracking" data-m='{"cN":"Footer_StoreandSupport_OrderTracking_nav","id":"n5c2c1c1m1r1a2","sN":5,"aN":"c2c1c1m1r1a2"}'>Order tracking</a>
                            </li>
                            <li>
                                <a aria-label="Certified Refurbished Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/certified-refurbished-products" data-m='{"cN":"Footer_StoreandSupport_StoreLocations_nav","id":"n6c2c1c1m1r1a2","sN":6,"aN":"c2c1c1m1r1a2"}'>Certified Refurbished</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Store Promise Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/why-microsoft-store?icid=footer_why-msft-store_7102020" data-m='{"cN":"Footer_StoreandSupport_MicrosoftPromise_nav","id":"n7c2c1c1m1r1a2","sN":7,"aN":"c2c1c1m1r1a2"}'>Microsoft Store Promise</a>
                            </li>
                            <li>
                                <a aria-label="Flexible Payments Microsoft Store" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/payment-financing-options?icid=footer_financing_vcc" data-m='{"cN":"Footer_StoreandSupport_Financing_nav","id":"n8c2c1c1m1r1a2","sN":8,"aN":"c2c1c1m1r1a2"}'>Flexible Payments</a>
                            </li>

                        </ul>
                        
                    </div>
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn3_cont","cT":"Container","id":"c3c1c1m1r1a2","sN":3,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">Education</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Microsoft in education Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/education" data-m='{"cN":"Footer_Education_MicrosoftInEducation_nav","id":"n1c3c1c1m1r1a2","sN":1,"aN":"c3c1c1m1r1a2"}'>Microsoft in education</a>
                            </li>
                            <li>
                                <a aria-label="Devices for education Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/education/devices/overview" data-m='{"cN":"Footer_Education_DevicesforEducation_nav","id":"n2c3c1c1m1r1a2","sN":2,"aN":"c3c1c1m1r1a2"}'>Devices for education</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Teams for Education Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/education/products/teams" data-m='{"cN":"Footer_Education_MicrosoftTeamsforEducation_nav","id":"n3c3c1c1m1r1a2","sN":3,"aN":"c3c1c1m1r1a2"}'>Microsoft Teams for Education</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft 365 Education Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/education/products/microsoft-365" data-m='{"cN":"Footer_Education_Microsoft365Education_nav","id":"n4c3c1c1m1r1a2","sN":4,"aN":"c3c1c1m1r1a2"}'>Microsoft 365 Education</a>
                            </li>
                            <li>
                                <a aria-label="How to buy for your school Education" class="c-uhff-link" href="https://www.microsoft.com/education/how-to-buy" data-m='{"cN":"Footer_Howtobuyforyourschool_nav","id":"n5c3c1c1m1r1a2","sN":5,"aN":"c3c1c1m1r1a2"}'>How to buy for your school</a>
                            </li>
                            <li>
                                <a aria-label="Educator training and development Education" class="c-uhff-link" href="https://education.microsoft.com/" data-m='{"cN":"Footer_Education_EducatorTrainingDevelopment_nav","id":"n6c3c1c1m1r1a2","sN":6,"aN":"c3c1c1m1r1a2"}'>Educator training and development</a>
                            </li>
                            <li>
                                <a aria-label="Deals for students and parents Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/education" data-m='{"cN":"Footer_Education_DealsForStudentsandParents_nav","id":"n7c3c1c1m1r1a2","sN":7,"aN":"c3c1c1m1r1a2"}'>Deals for students and parents</a>
                            </li>
                            <li>
                                <a aria-label="AI for education Education" class="c-uhff-link" href="https://www.microsoft.com/en-us/education/ai-in-education" data-m='{"cN":"Footer_Education_Azureforstudents_nav","id":"n8c3c1c1m1r1a2","sN":8,"aN":"c3c1c1m1r1a2"}'>AI for education</a>
                            </li>

                        </ul>
                        
                    </div>
                </div>
                <div class="c-uhff-nav-row">
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn4_cont","cT":"Container","id":"c4c1c1m1r1a2","sN":4,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">Business</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Microsoft Cloud Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-cloud" data-m='{"cN":"Footer_Business_Microsoft_Cloud_nav","id":"n1c4c1c1m1r1a2","sN":1,"aN":"c4c1c1m1r1a2"}'>Microsoft Cloud</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Security Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/security" data-m='{"cN":"Footer_Business_Microsoft Security_nav","id":"n2c4c1c1m1r1a2","sN":2,"aN":"c4c1c1m1r1a2"}'>Microsoft Security</a>
                            </li>
                            <li>
                                <a aria-label="Dynamics 365 Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/dynamics-365" data-m='{"cN":"Footer_Business_MicrosoftDynamics365_nav","id":"n3c4c1c1m1r1a2","sN":3,"aN":"c4c1c1m1r1a2"}'>Dynamics 365</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft 365 Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-365/business" data-m='{"cN":"Footer_Business_M365_nav","id":"n4c4c1c1m1r1a2","sN":4,"aN":"c4c1c1m1r1a2"}'>Microsoft 365</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Power Platform Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/power-platform" data-m='{"cN":"Footer_DeveloperAndIT_Power Platform_nav","id":"n5c4c1c1m1r1a2","sN":5,"aN":"c4c1c1m1r1a2"}'>Microsoft Power Platform</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Teams Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-teams/group-chat-software" data-m='{"cN":"Footer_Business_Microsoft365_nav","id":"n6c4c1c1m1r1a2","sN":6,"aN":"c4c1c1m1r1a2"}'>Microsoft Teams</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft 365 Copilot Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/microsoft-365/copilot/copilot-for-work" data-m='{"cN":"Footer_CopilotMicrosoft365_nav","id":"n7c4c1c1m1r1a2","sN":7,"aN":"c4c1c1m1r1a2"}'>Microsoft 365 Copilot</a>
                            </li>
                            <li>
                                <a aria-label="Small Business Business" class="c-uhff-link" href="https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore" data-m='{"cN":"Footer_Business-SmallBusiness_nav","id":"n8c4c1c1m1r1a2","sN":8,"aN":"c4c1c1m1r1a2"}'>Small Business</a>
                            </li>

                        </ul>
                        
                    </div>
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn5_cont","cT":"Container","id":"c5c1c1m1r1a2","sN":5,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">Developer &amp; IT</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Azure Developer &amp; IT" class="c-uhff-link" href="https://azure.microsoft.com/en-us/" data-m='{"cN":"Footer_DeveloperAndIT_MicrosoftAzure_nav","id":"n1c5c1c1m1r1a2","sN":1,"aN":"c5c1c1m1r1a2"}'>Azure</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Developer Developer &amp; IT" class="c-uhff-link" href="https://developer.microsoft.com/en-us/" data-m='{"cN":"Footer_DeveloperAndIT_MicrosoftDeveloper_nav","id":"n2c5c1c1m1r1a2","sN":2,"aN":"c5c1c1m1r1a2"}'>Microsoft Developer</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Learn Developer &amp; IT" class="c-uhff-link" href="https://learn.microsoft.com/" data-m='{"cN":"Footer_DeveloperAndIT_MicrosoftLearn_nav","id":"n3c5c1c1m1r1a2","sN":3,"aN":"c5c1c1m1r1a2"}'>Microsoft Learn</a>
                            </li>
                            <li>
                                <a aria-label="Support for AI marketplace apps Developer &amp; IT" class="c-uhff-link" href="https://www.microsoft.com/isv/isv-success?ocid=cmm3atxvn98" data-m='{"cN":"Footer_DeveloperAndIT_ExploreISVSuccess_nav","id":"n4c5c1c1m1r1a2","sN":4,"aN":"c5c1c1m1r1a2"}'>Support for AI marketplace apps</a>
                            </li>
                            <li>
                                <a aria-label="Microsoft Tech Community Developer &amp; IT" class="c-uhff-link" href="https://techcommunity.microsoft.com/" data-m='{"cN":"Footer_DeveloperAndIT_MicrosoftTechCommunity_nav","id":"n5c5c1c1m1r1a2","sN":5,"aN":"c5c1c1m1r1a2"}'>Microsoft Tech Community</a>
                            </li>
                            <li>
                                <a aria-label="Azure Marketplace Developer &amp; IT" class="c-uhff-link" href="https://azuremarketplace.microsoft.com/" data-m='{"cN":"Footer_DeveloperAndIT_AzureMarketplace_nav","id":"n6c5c1c1m1r1a2","sN":6,"aN":"c5c1c1m1r1a2"}'>Azure Marketplace</a>
                            </li>
                            <li>
                                <a aria-label="AppSource Developer &amp; IT" class="c-uhff-link" href="https://appsource.microsoft.com/en-us/" data-m='{"cN":"Footer_DeveloperAndIT_AppSource_nav","id":"n7c5c1c1m1r1a2","sN":7,"aN":"c5c1c1m1r1a2"}'>AppSource</a>
                            </li>
                            <li>
                                <a aria-label="Visual Studio Developer &amp; IT" class="c-uhff-link" href="https://visualstudio.microsoft.com/" data-m='{"cN":"Footer_DeveloperAndIT_MicrosoftVisualStudio_nav","id":"n8c5c1c1m1r1a2","sN":8,"aN":"c5c1c1m1r1a2"}'>Visual Studio</a>
                            </li>

                        </ul>
                        
                    </div>
                    <div class="c-uhff-nav-group" data-m='{"cN":"footerNavColumn6_cont","cT":"Container","id":"c6c1c1m1r1a2","sN":6,"aN":"c1c1m1r1a2"}'>
                        <div class="c-heading-4" role="heading" aria-level="2">Company</div>
                        <ul class="c-list f-bare">
                            <li>
                                <a aria-label="Careers Company" class="c-uhff-link" href="https://careers.microsoft.com/" data-m='{"cN":"Footer_Company_Careers_nav","id":"n1c6c1c1m1r1a2","sN":1,"aN":"c6c1c1m1r1a2"}'>Careers</a>
                            </li>
                            <li>
                                <a aria-label="About Microsoft Company" class="c-uhff-link" href="https://www.microsoft.com/about" data-m='{"cN":"Footer_Company_AboutMicrosoft_nav","id":"n2c6c1c1m1r1a2","sN":2,"aN":"c6c1c1m1r1a2"}'>About Microsoft</a>
                            </li>
                            <li>
                                <a aria-label="Company news Company" class="c-uhff-link" href="https://news.microsoft.com/" data-m='{"cN":"Footer_Company_CompanyNews_nav","id":"n3c6c1c1m1r1a2","sN":3,"aN":"c6c1c1m1r1a2"}'>Company news</a>
                            </li>
                            <li>
                                <a aria-label="Privacy at Microsoft Company" class="c-uhff-link" href="https://privacy.microsoft.com/en-us" data-m='{"cN":"Footer_Company_PrivacyAtMicrosoft_nav","id":"n4c6c1c1m1r1a2","sN":4,"aN":"c6c1c1m1r1a2"}'>Privacy at Microsoft</a>
                            </li>
                            <li>
                                <a aria-label="Investors Company" class="c-uhff-link" href="https://www.microsoft.com/investor/default.aspx" data-m='{"cN":"Footer_Company_Investors_nav","id":"n5c6c1c1m1r1a2","sN":5,"aN":"c6c1c1m1r1a2"}'>Investors</a>
                            </li>
                            <li>
                                <a aria-label="Diversity and inclusion Company" class="c-uhff-link" href="https://www.microsoft.com/en-us/diversity/" data-m='{"cN":"Footer_Company_DiversityAndInclusion_nav","id":"n6c6c1c1m1r1a2","sN":6,"aN":"c6c1c1m1r1a2"}'>Diversity and inclusion</a>
                            </li>
                            <li>
                                <a aria-label="Accessibility Company" class="c-uhff-link" href="https://www.microsoft.com/en-us/accessibility" data-m='{"cN":"Footer_Company_Accessibility_nav","id":"n7c6c1c1m1r1a2","sN":7,"aN":"c6c1c1m1r1a2"}'>Accessibility</a>
                            </li>
                            <li>
                                <a aria-label="Sustainability Company" class="c-uhff-link" href="https://www.microsoft.com/en-us/sustainability/" data-m='{"cN":"Footer_Company_Sustainability_nav","id":"n8c6c1c1m1r1a2","sN":8,"aN":"c6c1c1m1r1a2"}'>Sustainability</a>
                            </li>

                        </ul>
                        
                    </div>
                </div>
        </nav>
    <div class="c-uhff-base">
        
            <a data-m='{"id":"n7c1c1m1r1a2","sN":7,"aN":"c1c1m1r1a2"}' href="https://aka.ms/yourcaliforniaprivacychoices" class='c-uhff-link c-uhff-ccpa'>
        <svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 14" xml:space="preserve" height="16" width="43">
            <title>Your Privacy Choices Opt-Out Icon</title>
            <path d="M7.4 12.8h6.8l3.1-11.6H7.4C4.2 1.2 1.6 3.8 1.6 7s2.6 5.8 5.8 5.8z" style="fill-rule:evenodd;clip-rule:evenodd;fill:#fff"/>
            <path d="M22.6 0H7.4c-3.9 0-7 3.1-7 7s3.1 7 7 7h15.2c3.9 0 7-3.1 7-7s-3.2-7-7-7zm-21 7c0-3.2 2.6-5.8 5.8-5.8h9.9l-3.1 11.6H7.4c-3.2 0-5.8-2.6-5.8-5.8z" style="fill-rule:evenodd;clip-rule:evenodd;fill:#06f"/>
            <path d="M24.6 4c.2.2.2.6 0 .8L22.5 7l2.2 2.2c.2.2.2.6 0 .8-.2.2-.6.2-.8 0l-2.2-2.2-2.2 2.2c-.2.2-.6.2-.8 0-.2-.2-.2-.6 0-.8L20.8 7l-2.2-2.2c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0l2.2 2.2L23.8 4c.2-.2.6-.2.8 0z" style="fill:#fff"/>
            <path d="M12.7 4.1c.2.2.3.6.1.8L8.6 9.8c-.1.1-.2.2-.3.2-.2.1-.5.1-.7-.1L5.4 7.7c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0L8 8.6l3.8-4.5c.2-.2.6-.2.9 0z" style="fill:#06f"/>
        </svg>
        <span>Your Privacy Choices</span>
    </a>

        <noscript>
                <a data-m='{"id":"n8c1c1m1r1a2","sN":8,"aN":"c1c1m1r1a2"}' href="https://aka.ms/yourcaliforniaprivacychoices" class='c-uhff-link c-uhff-ccpa'>
        <svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 14" xml:space="preserve" height="16" width="43">
            <title>Your Privacy Choices Opt-Out Icon</title>
            <path d="M7.4 12.8h6.8l3.1-11.6H7.4C4.2 1.2 1.6 3.8 1.6 7s2.6 5.8 5.8 5.8z" style="fill-rule:evenodd;clip-rule:evenodd;fill:#fff"/>
            <path d="M22.6 0H7.4c-3.9 0-7 3.1-7 7s3.1 7 7 7h15.2c3.9 0 7-3.1 7-7s-3.2-7-7-7zm-21 7c0-3.2 2.6-5.8 5.8-5.8h9.9l-3.1 11.6H7.4c-3.2 0-5.8-2.6-5.8-5.8z" style="fill-rule:evenodd;clip-rule:evenodd;fill:#06f"/>
            <path d="M24.6 4c.2.2.2.6 0 .8L22.5 7l2.2 2.2c.2.2.2.6 0 .8-.2.2-.6.2-.8 0l-2.2-2.2-2.2 2.2c-.2.2-.6.2-.8 0-.2-.2-.2-.6 0-.8L20.8 7l-2.2-2.2c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0l2.2 2.2L23.8 4c.2-.2.6-.2.8 0z" style="fill:#fff"/>
            <path d="M12.7 4.1c.2.2.3.6.1.8L8.6 9.8c-.1.1-.2.2-.3.2-.2.1-.5.1-.7-.1L5.4 7.7c-.2-.2-.2-.6 0-.8.2-.2.6-.2.8 0L8 8.6l3.8-4.5c.2-.2.6-.2.9 0z" style="fill:#06f"/>
        </svg>
        <span>Your Privacy Choices</span>
    </a>

        </noscript>
            <a data-m='{"id":"n9c1c1m1r1a2","sN":9,"aN":"c1c1m1r1a2"}' href="https://go.microsoft.com/fwlink/?linkid=2259814" class="c-uhff-link c-uhff-consumer">
        <span>Consumer Health Privacy</span>
    </a>

        <nav aria-label="Microsoft corporate links">
            <ul class="c-list f-bare" data-m='{"cN":"Corp links_cont","cT":"Container","id":"c10c1c1m1r1a2","sN":10,"aN":"c1c1m1r1a2"}'>
                                <li  id="c-uhff-footer_sitemap">
                    <a class="c-uhff-link" href="https://www.microsoft.com/en-us/sitemap1.aspx" data-mscc-ic="false" data-m='{"cN":"Footer_Sitemap_nav","id":"n1c10c1c1m1r1a2","sN":1,"aN":"c10c1c1m1r1a2"}'>Sitemap</a>
                </li>
                <li  id="c-uhff-footer_contactus">
                    <a class="c-uhff-link" href="https://support.microsoft.com/contactus" data-mscc-ic="false" data-m='{"cN":"Footer_ContactUs_nav","id":"n2c10c1c1m1r1a2","sN":2,"aN":"c10c1c1m1r1a2"}'>Contact Microsoft</a>
                </li>
                <li  id="c-uhff-footer_privacyandcookies">
                    <a class="c-uhff-link" href="https://go.microsoft.com/fwlink/?LinkId=521839" data-mscc-ic="false" data-m='{"cN":"Footer_PrivacyandCookies_nav","id":"n3c10c1c1m1r1a2","sN":3,"aN":"c10c1c1m1r1a2"}'>Privacy </a>
                </li>
                <li class=" x-hidden" id="c-uhff-footer_managecookies">
                    <a class="c-uhff-link" href="#" data-mscc-ic="false" data-m='{"cN":"Footer_ManageCookies_nav","id":"n4c10c1c1m1r1a2","sN":4,"aN":"c10c1c1m1r1a2"}'>Manage cookies</a>
                </li>
                <li  id="c-uhff-footer_termsofuse">
                    <a class="c-uhff-link" href="https://go.microsoft.com/fwlink/?LinkID=206977" data-mscc-ic="false" data-m='{"cN":"Footer_TermsOfUse_nav","id":"n5c10c1c1m1r1a2","sN":5,"aN":"c10c1c1m1r1a2"}'>Terms of use</a>
                </li>
                <li  id="c-uhff-footer_trademarks">
                    <a class="c-uhff-link" href="https://go.microsoft.com/fwlink/?linkid=2196228" data-mscc-ic="false" data-m='{"cN":"Footer_Trademarks_nav","id":"n6c10c1c1m1r1a2","sN":6,"aN":"c10c1c1m1r1a2"}'>Trademarks</a>
                </li>
                <li  id="c-uhff-footer_safetyandeco">
                    <a class="c-uhff-link" href="https://go.microsoft.com/fwlink/?linkid=2196227" data-mscc-ic="false" data-m='{"cN":"Footer_SafetyAndEco_nav","id":"n7c10c1c1m1r1a2","sN":7,"aN":"c10c1c1m1r1a2"}'>Safety &amp; eco</a>
                </li>
                <li  id="c-uhff-recycling">
                    <a class="c-uhff-link" href="https://www.microsoft.com/en-us/legal/compliance/recycling" data-mscc-ic="false" data-m='{"cN":"Recycling_nav","id":"n8c10c1c1m1r1a2","sN":8,"aN":"c10c1c1m1r1a2"}'>Recycling</a>
                </li>
                <li  id="c-uhff-footer_aboutourads">
                    <a class="c-uhff-link" href="https://choice.microsoft.com" data-mscc-ic="false" data-m='{"cN":"Footer_AboutourAds_nav","id":"n9c10c1c1m1r1a2","sN":9,"aN":"c10c1c1m1r1a2"}'>About our ads</a>
                </li>

                <li>&#169; Microsoft 2025</li>
                
            </ul>
        </nav>
        
    </div>
    
</footer>

<script id="uhf-footer-ccpa">
    const globalPrivacyControlEnabled = navigator.globalPrivacyControl;

    const GPC_DataSharingOptIn = (globalPrivacyControlEnabled) ? false : checkThirdPartyAdsOptOutCookie();

    if(window.onGPCLoaded) {
        window.onGPCLoaded();
    }
    
    function checkThirdPartyAdsOptOutCookie() {
        try {
            const ThirdPartyAdsOptOutCookieName = '3PAdsOptOut';
            var cookieValue = getCookie(ThirdPartyAdsOptOutCookieName);
            return cookieValue != 1;
        } catch {
            return true;
        }
    }

    function getCookie(cookieName) {
        var cookieValue = document.cookie.match('(^|;)\\s*' + cookieName + '\\s*=\\s*([^;]+)');
        return (cookieValue) ? cookieValue[2] : '';
    }
</script>







    </div>
        </div>

    </div>		</span>

		
		<script type="text/javascript">
			var varAutoFirePV = 1;
			var varClickTracking = 0;
			var varCustomerTracking = 1;
			var Route = "route_id";
			var Ctrl = "control_id";
		</script>

		<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/en-us\/research\/*"},{"not":{"href_matches":["\/en-us\/research\/wp-*.php","\/en-us\/research\/wp-admin\/*","\/en-us\/research\/wp-content\/uploads\/*","\/en-us\/research\/wp-content\/*","\/en-us\/research\/wp-content\/plugins\/*","\/en-us\/research\/wp-content\/themes\/microsoft-research-theme\/*","\/en-us\/research\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
	<script>
		function onConsentChanged( categoryPreferences ) {
			Metrics_3P_Scripts();

			// If any categories are disabled, clear all cookies
			if ( ! siteConsent.getConsentFor( WcpConsent.consentCategories.Analytics ) ) {
				Metrics_Clear_Cookies( 'Analytics' );
			}

			if ( ! siteConsent.getConsentFor( WcpConsent.consentCategories.Advertising ) ) {
				Metrics_Clear_Cookies( 'Advertising' );
			}

			if ( ! siteConsent.getConsentFor( WcpConsent.consentCategories.SocialMedia ) ) {
				Metrics_Clear_Cookies( 'SocialMedia' );
			}
		}

		function Metrics_Clear_Cookies( category ) {
			var all_cookies = document.cookie.split(";");

			// array of cookie names to clear
			const cookie_names = [
				'_clck',
				'_clsk',
				'_fbp',
				'_uetvid',
				'mbox',
				'AnalyticsSyncHistory',
				'bcookie',
				'bscookie',
				'li_sugr',
				'lidc',
				'li_gc',
				'UserMatchHistory',
			];

			for ( var i = 0; i < all_cookies.length; i++ ) {
				var cookie_name = all_cookies[i].split("=")[0].trim();
				if ( cookie_names.includes( cookie_name ) ) {
					document.cookie = cookie_name + '=;expires=Thu, 01 Jan 1970 00:00:01 GMT;';
				}
			}
		}

		function Metrics_3P_Scripts(){

			// if GPC_DataSharingOptIn is set and true set Metrics_3POptIn
			var Metrics_3P_OptIn = false;
			if ( typeof GPC_DataSharingOptIn !== 'undefined' && GPC_DataSharingOptIn ) {
				Metrics_3P_OptIn = true;
			} else {
				Metrics_3P_OptIn = false;
				Metrics_Clear_Cookies();
			}

			if ( siteConsent.getConsentFor( WcpConsent.consentCategories.Analytics ) && Metrics_3P_OptIn ) {
									if ( typeof clicktaleTracking === "function" ) {
						clicktaleTracking(); 
					}
				
				if ( siteConsent.getConsentFor( WcpConsent.consentCategories.Advertising ) ) {
											if ( typeof clarityTracking === "function" ) {
							clarityTracking(); 
						}
					
					if ( siteConsent.getConsentFor( WcpConsent.consentCategories.SocialMedia ) ) {
													if ( typeof facebookTracking === "function" ) {
								facebookTracking(); 
							}
													if ( typeof linkedinTracking === "function" ) {
								linkedinTracking(); 
							}
											}
				}

				if ( siteConsent.getConsentFor( WcpConsent.consentCategories.SocialMedia ) ) {
									}
			}

			if ( siteConsent.getConsentFor( WcpConsent.consentCategories.Advertising ) && Metrics_3P_OptIn ) {
				
				if ( siteConsent.getConsentFor( WcpConsent.consentCategories.SocialMedia ) ) {
									}
			}

			if ( siteConsent.getConsentFor( WcpConsent.consentCategories.SocialMedia ) && Metrics_3P_OptIn ) {
							}
		}

					window.WcpConsent && WcpConsent.init( "en-US", "ms-cookie-banner", function (err, _siteConsent) {

				if ( ! err ) {
					siteConsent = _siteConsent;  //siteConsent is used to get the current consent

					var consentRequiredElementExists = document.getElementById( "c-uhff-footer_managecookies" ) && siteConsent.isConsentRequired;

					if ( consentRequiredElementExists ) {
						document.getElementById( "c-uhff-footer_managecookies" ).classList.remove("x-hidden");
						document.getElementById( "c-uhff-footer_managecookies" ).onclick = function() {
							siteConsent.manageConsent();
						};
					}

					Metrics_3P_Scripts();

				} else {
					console.log( "Error initializing WcpConsent: " + err );
				}
			}, onConsentChanged );
				</script>
	
	<!-- LinkedIn Code -->
	<script type="text/javascript">
		_linkedin_partner_id = "7850";
		window._linkedin_data_partner_ids = window._linkedin_data_partner_ids || [];
		window._linkedin_data_partner_ids.push(_linkedin_partner_id);
	</script>
	<script type="text/javascript">
		(function(){var s = document.getElementsByTagName("script")[0];
		var b = document.createElement("script");
		b.type = "text/javascript";b.async = true;
		b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
		s.parentNode.insertBefore(b, s);})();
	</script>
	<noscript>
		<img height="1" width="1" style="display:none;" alt="" src="https://px.ads.linkedin.com/collect/?pid=7850&fmt=gif" />
	</noscript>
	<!-- End LinkedIn Code -->

	<style id='block-style-variation-styles-inline-css' type='text/css'>
:root :where(.wp-block-button.is-style-outline--1 .wp-block-button__link){background: transparent none;border-color: currentColor;border-width: 2px;border-style: solid;color: currentColor;padding-top: 0.667em;padding-right: 1.33em;padding-bottom: 0.667em;padding-left: 1.33em;}
</style>
<style id='core-block-supports-inline-css' type='text/css'>
.wp-elements-4cf2924f716642350f12f0005580e4dd a:where(:not(.wp-element-button)){color:var(--wp--preset--color--white);}.wp-elements-f254dc4be67571fc8d14c3bae3d299c8 a:where(:not(.wp-element-button)){color:var(--wp--preset--color--black);}.wp-elements-d2f5b57c698943b521515c0f3b590be0 a:where(:not(.wp-element-button)){color:var(--wp--preset--color--black);}.wp-container-core-cover-is-layout-d9fd7b74 > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width:1388px;margin-left:auto !important;margin-right:auto !important;}.wp-container-core-cover-is-layout-d9fd7b74 > .alignwide{max-width:1388px;}.wp-container-core-cover-is-layout-d9fd7b74 .alignfull{max-width:none;}.wp-container-core-buttons-is-layout-16018d1d{justify-content:center;}.wp-container-core-columns-is-layout-9d6595d7{flex-wrap:nowrap;}.wp-elements-07f22b3da697602d0fa22f1a7ecde984 a:where(:not(.wp-element-button)){color:var(--wp--preset--color--white);}
</style>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/moray-blocks/dist/js/shared.js?ver=0.2.0" id="moray_blocks_shared_script-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/moray-blocks/dist/js/frontend.js?ver=0.2.0" id="moray_blocks_frontend_script-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/mwf/bundle.min.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="mwf-moray-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/msr-blocks-library/dist/js/shared.js?ver=0.2.0" id="msr_block_library_plugin_shared-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/msr-blocks-library/dist/js/frontend.js?ver=ed590bdf264223835ab6" id="msr_block_library_plugin_frontend-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/plugins.min.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="msr-plugins-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/dom-ready.min.js?ver=f77871ff7694fffea381" id="wp-dom-ready-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/hooks.min.js?ver=4d63a3d491d11ffd8ac6" id="wp-hooks-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/i18n.min.js?ver=5e580eb46a90c2b997e6" id="wp-i18n-js"></script>
<script type="text/javascript" id="wp-i18n-js-after">
/* <![CDATA[ */
wp.i18n.setLocaleData( { 'text direction\u0004ltr': [ 'ltr' ] } );
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/a11y.min.js?ver=3156534cc54473497e14" id="wp-a11y-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/vendor/wp-polyfill.min.js?ver=3.15.0" id="wp-polyfill-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/url.min.js?ver=c2964167dfe2477c14ea" id="wp-url-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-includes/js/dist/api-fetch.min.js?ver=3623a576c78df404ff20" id="wp-api-fetch-js"></script>
<script type="text/javascript" id="wp-api-fetch-js-after">
/* <![CDATA[ */
wp.apiFetch.use( wp.apiFetch.createRootURLMiddleware( "https://www.microsoft.com/en-us/research/wp-json/" ) );
wp.apiFetch.nonceMiddleware = wp.apiFetch.createNonceMiddleware( "c272a741e2" );
wp.apiFetch.use( wp.apiFetch.nonceMiddleware );
wp.apiFetch.use( wp.apiFetch.mediaUploadMiddleware );
wp.apiFetch.nonceEndpoint = "https://www.microsoft.com/en-us/research/wp-admin/admin-ajax.php?action=rest-nonce";
/* ]]> */
</script>
<script type="text/javascript" id="ms-research-js-extra">
/* <![CDATA[ */
var MSR_i18n = {"currentPageText":"Current Page","pageText":"Page","currentSelections":"Current Selections","currentRemove":"Remove filter for: ","facetSearchUpdate":"Filtering results\u2026","facetSearchDone":"Result filtering completed.","facetErrors":{"dateRange":"Your end date is before your start date. Please check your date range.","dateFormat":"Sorry, we can\u2019t figure out the date range. Try using YYYY-MM-DD formats.","loading":"There was a problem getting the results. You might be offline, or something went wrong in the system. ","autocomplete":"This term has no results and it isn\u2019t in our system."},"expanded":"Expanded","collapsed":"Collapsed","onDemand":{"noResults":"Sorry, there are no items to show with your filters."}};
var MSR_content_refs = {"msr-podcast":"240054"};
var MSRData = {"blogNavigation":{"wrapper":"post-archive-grid","templateId":"post-archive-card","basePaginationUrl":"https:\/\/www.microsoft.com\/en-us\/research\/blog\/page\/","endpointUrl":"https:\/\/www.microsoft.com\/en-us\/research\/wp-json\/wp\/v2\/posts\/","search":null,"eventTypeTaxonomy":"msr-event-type"}};
var epAutosuggest = {"endpoint":"https:\/\/www.microsoft.com\/en-us\/research\/wp-json\/microsoft-research\/v1\/autosuggest","action":"navigate","locale":"en_US"};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/microsoft-research.min.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="ms-research-js"></script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/vendor/duet-date-picker/duet/duet.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="duet-date-picker-script-js"></script>
<script type="text/javascript" id="ms-oembed-gif-script-js-extra">
/* <![CDATA[ */
var msgifs = {"play":"Play animated gif","pause":"Pause animated gif"};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/gifplayer.min.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="ms-oembed-gif-script-js"></script>
<script type="text/javascript" id="1DS-init-script-js-after">
/* <![CDATA[ */
	<!-- JSLL tracking -->
		// 1DS initialization

		const analytics = new oneDS.ApplicationInsights();
		var config = {
			instrumentationKey: "9ec747153cf446f7b4e129dc7eaa8227-f83e8b36-9a56-4437-8103-9010c8e1e72a-6756",
			propertyConfiguration: {
				gpcDataSharingOptIn: ( typeof GPC_DataSharingOptIn !== "undefined" ) ? GPC_DataSharingOptIn : true,
				callback: {
					userConsentDetails: ( typeof siteConsent !== "undefined" ) ? siteConsent.getConsent : WcpConsent.siteConsent
				},
			},
			webAnalyticsConfiguration:{
				coreData: {"pageName":"Microsoft Research Forum","pageType":"Event"},
				urlCollectQuery: true,
				urlCollectHash: true,
				autoCapture: {
					scroll: true,
					pageView: true,
					onLoad: true,
					onUnload: true,
					click: true,
					scroll: true,
					resize: true,
					jsError: true
				}
			}
		};
		// Initialize OneDS SDK
		analytics.initialize( config, [] );
	
/* ]]> */
</script>
<script type="text/javascript" id="microsoft-uhf-js-extra">
/* <![CDATA[ */
var microsoftUhfSettings = {"homePath":"\/en-us\/research\/","loginUrl":"http:\/\/www.microsoft.com\/en-us\/research\/wp-login.php","logoutUrl":"","scripts":[],"inline":["linkedin","youtube","youTubeVideo"]};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/plugins/microsoft-uhf/assets/microsoft-uhf.js?ver=0.6.1" id="microsoft-uhf-js"></script>
<script type="text/javascript" id="faceted-search-js-extra">
/* <![CDATA[ */
var MSRSearch = {"debugging":"","endpoint":"https:\/\/www.microsoft.com\/en-us\/research\/wp-json\/microsoft-research\/v1\/faceted-search","locale":"","origin":"https:\/\/www.microsoft.com\/en-us\/research\/","initialLoadResults":{"users":[],"posts":[{"data":{"ID":1132236,"post_author":38004,"post_date":"2025-02-25 13:02:52","post_date_gmt":"2025-02-25 21:02:52","post_content":"<!-- wp:paragraph -->\n<p><em><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/aseemr\/\">Aseem Rastogi<\/a>&nbsp;and <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/pdeligia\/\">Pantazis Deligiannis<\/a><\/em> <em>at&nbsp;<\/em><strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Aseem Rastogi, Principal Researcher, and Pantazis Deligiannis, Principal Research Engineer from Microsoft Research FoSSE (Future of Scalable Software Engineering) discuss the technical results from ICSE'2025 on using Large Language Models (LLMs) for safe low-level programming. The results demonstrate LLMs inferring machine-checkable memory safety invariants in legacy C code, and how LLMs assist in fixing compilation errors in Rust codebases.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/llm-assistance-for-memory-safety\/\">LLM assistance for memory safety<\/a><br>April 2025<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/rustassistant-using-llms-to-fix-compilation-errors-in-rust-code\/\">RustAssistant: Using LLMs to fix compilation errors in Rust code<\/a><br>April 2025<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>LLMs for safe low-level programming<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>FRIEDERIKE NIEDTNER<\/strong>, Principal Technical Research Program Manager, Microsoft Research AI Frontiers: The following talk combines two projects that both harness the LLM's capabilities to understand and produce code. Both aim to help developers tackle the difficulties of safe low-level programming. One to ensure memory safety in legacy C code; the other presents RustAssistant, a tool for developers to automatically fix compilation errors in Rust.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>&nbsp;<strong>ASEEM RASTOGI:<\/strong> Hi, my name is Aseem Rastogi, and I'm a researcher in the Future of Scalable Software Engineering organization in Microsoft Research. I'm going to talk to you about our paper, \u201cLLM Assistance for Memory Safety.\u201d This paper will be presented at the 47th International Conference on Software Engineering in May later this year.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The lack of memory safety in low-level languages like C and C++ is one of the leading causes of software security vulnerabilities. For instance, a study by Microsoft estimated that 70% of the security bugs that Microsoft fixes and assigns a CVE every year are due to memory safety issues. Researchers have proposed safe dialects of C, for example, Checked C, that\u2014with the help of additional source-level annotations\u2014provide memory safety guarantees with low performance overheads. However, the cost of adding these annotations and the code restructuring required to enable them becomes a bottleneck in the adoption of these tools. In general, application of formal verification to real software faces the same challenge.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In our paper, we explore the use of pretrained large language models to help with the task of code restructuring and inferring source annotations required to adopt Checked C. Let's consider an example that takes an array of integers as input and sums the first <em>n<\/em> elements. To reason about the memory safety of this function, Checked C requires an annotation on <em>p<\/em>. One such annotation is as shown here. This tells the compiler that <em>p<\/em> is an array with at least <em>n<\/em> elements, which is enough to ensure the safety of memory accesses in this function. It also helps impose an explicit obligation on the callers of this function that they must pass an appropriately sized array to it.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Our goal is to infer such annotations with the help of LLMs. For this problem, LLMs seem like a perfect match. It is hard to encode reasoning about real-world code and complex code patterns in symbolic tools. LLMs, on the other hand, have demonstrated tremendous code comprehension and reasoning capabilities similar to what programmers have, even for real-world code. Second, LLM hallucinations might lead to incorrect annotations, but they cannot compromise memory safety. Once the annotations are added to the code, the Checked C compiler guarantees memory safety even when the annotations are incorrect. This way, we get best of both worlds!&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, working with LLMs for whole program transformations in large codebases represents another challenge. We need to break the task into smaller subtasks that can fit into LLM prompts while adding relevant symbolic context to each prompt. Put another way, in order for LLMs to be able to reason like programmers, we need to provide them context that a programmer would otherwise consider. Our paper presents a framework for doing just that with the help of program dependence graphs working in tandem with LLMs. We implement our ideas in a tool called MSA and evaluate it on real-world codebases ranging up to 20,000 lines of code. We observe that MSA can infer 86% of the annotations that state-of-the-art symbolic tools cannot. Although our paper focuses on memory safety, our methodology is more general and can be used to effectively leverage LLMs for scaling the use of formal verification to real software\u2014most importantly, doing so without compromising on the soundness guarantees. We are really excited about this research direction.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Up next, my colleague Pantazis will tell you about how we are leveraging LLMs to make it easier for the programmers to adopt Rust. Thank you.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>PANTAZIS DELIGIANNIS:<\/strong> Hello, everyone. I'm Pantazis, and today I will be presenting our work on leveraging the power of large language models for safe low-level programing. Specifically, I will focus on our recent paper about RustAssistant, which is a tool that uses LLMs to automatically fix compilation errors in code written in Rust. This work was done together with other individuals that are listed on the screen and will appear in the International Conference on Software Engineering later this spring.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>OK, let's dive in! Why do we care about safe low-level programing with Rust? So the Rust programing language, with its memory and concurrency safety guarantees, has established itself as a viable choice for building low-level software systems over the traditional, unsafe alternatives like C and C++. These guarantees come from a strong ownership-based type system, which enforces memory and concurrency safety at compile time. However, Rust poses a steep learning curve for developers, especially when they encounter compilation errors related to advanced language features such as ownership, lifetime, or traits. At the same time, Rust is becoming increasingly more popular every year, so as more and more developers adopt Rust for writing critical software systems, it is essential to tackle the difficulty in writing code in Rust.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In Microsoft Research, we created a tool called RustAssistant that leverages the power of state-of-the-art LLMs to help developers by automatically suggesting fixes for Rust compilation errors. Our tool uses a careful combination of prompting techniques as well as iteration between a large language model and the Rust compiler to deliver high-accuracy fixes. RustAssistant is able to achieve an impressive peak accuracy of roughly 74% on real-world compilation errors in popular open-source Rust repositories on GitHub.&nbsp;&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>OK, let's now see how RustAssistant works step by step. Let's begin with the first step: building the code and parsing the build errors. Such errors can range from simple syntax mistakes to very complicated issues involving traits, lifetimes, or ownership rules in Rust code spread across multiple files. So when a developer writes Rust code that doesn't compile, the Rust compiler generates detailed error messages that include the error code, the location of the error, as well as documentation and examples related to this error code.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>To illustrate this process, let's look at this very simple example on the screen. In this case, the developer is trying to compare a custom VerbosityLevel enumeration in their code using the greater-or-equal operator. However, the Rust compiler throws an error, stating that this binary operation cannot be applied to VerbosityLevel. The compiler suggests that the reason behind this error is because VerbosityLevel does not implement a trait that is required for performing such comparisons in Rust. This detailed error message is precisely what RustAssistant captures at this step, preparing it for the next stage of processing.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>At the next step, RustAssistant takes this detailed error information that is generated in the previous step and focuses on extracting the specific parts of the code that are directly relevant to this error. Looking at the example on the screen, the code snippets related to the enumeration and its use in the <em>log_error<\/em> function are automatically extracted by our tool. This includes not only the problematic line of code but also other code snippets that provide necessary context for understanding and resolving the error. The tool also captures the error details, such as the error code and the accompanying compiler suggestion about the missing trait for performing the comparison. These extracted code snippets and error details are then packaged into a prompt for the LLM. This ensures that the LLM receives only the essential information required to suggest an accurate fix without being overwhelmed by irrelevant parts of the codebase. This careful localization step is crucial for both efficiency and accuracy, especially when dealing with very large codebases.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now let's move to the last step. Here, RustAssistant sends the carefully localized prompt, which includes the error details and the relevant code snippets, to the large language model API. The LLM generates a proposed fix, formatted as a code diff\u2014in other words, does not include the entire code snippet for efficiency but only the new, edited, or deleted code lines. For example, in the case of our build error, the LLM suggests adding the missing traits to the enumeration, as shown here on the screen. This fix ensures that the comparison using the greater-or-equal operator will now work as intended. Next, RustAssistant parses this suggested fix and applies the changes to the appropriate file in the codebase. Once the fixes are applied, our tool runs again the Rust compiler to verify if the build error has been resolved. If the code compiles, then great news! The process is now complete, and we can do further validations like running any unit tests.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, if new errors appear or if the fix doesn't fully resolve the issue, RustAssistant sends the updated context back to the LLM, iterating until the code compiles error free. And this iterative process allows our tool to handle complex, multi-step fixes while ensuring correctness and alignment with the developer's intent. Of course, the example that I showed here is a very simple one, but you can imagine the tool being able to fix much more complicated build errors.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>To summarize, I presented a quick walkthrough of how RustAssistant can be used to help developers automatically fix build errors in their Rust codebases. In our paper, we evaluated RustAssistant on the top hundred Rust repositories on GitHub and showed that it can achieve an impressive peak accuracy of roughly 74% on real-world compilation errors. We invite you to read our ICSE paper as it not only discusses the evaluation results in detail but also dives into interesting technical details, such as how we designed our prompts as well as various techniques that we developed for scaling RustAssistant on very large codebases without losing accuracy.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thank you for listening.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How are LLMs transforming programming practices, enhancing safety and efficiency?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20are%20LLMs%20transforming%20programming%20practices,%20enhancing%20safety%20and%20efficiency?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Using LLMs for safe low-level programming","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"using-llms-for-safe-low-level-programming-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-23 11:31:33","post_modified_gmt":"2025-06-23 18:31:33","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/using-llms-for-safe-low-level-programming-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"},{"term_id":13560,"slug":"programming-languages-software-engineering","name":"Programming languages and software engineering","parent":0,"term_taxonomy_id":13560,"term_order":0,"facet":"{\"term_id\":13560,\"slug\":\"programming-languages-software-engineering\",\"name\":\"Programming languages and software engineering\",\"parent\":0,\"term_taxonomy_id\":13560,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269931,"slug":"extending-human-capabilities","name":"Extending Human Capabilities","parent":0,"term_taxonomy_id":269976,"term_order":0,"facet":"{\"term_id\":269931,\"slug\":\"extending-human-capabilities\",\"name\":\"Extending Human Capabilities\",\"parent\":0,\"term_taxonomy_id\":269976,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/kYGLH-WYPdI-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t10:23\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/kYGLH-WYPdI-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/using-llms-for-safe-low-level-programming-microsoft-research-forum\/\" data-bi-cN=\"Using LLMs for safe low-level programming\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Using LLMs for safe low-level programming\" icon_class=\"c-heading__icon\"><span>Using LLMs for safe low-level programming<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/aseemr\/\">Aseem Rastogi<\/a>, <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/pdeligia\/\">Pantazis Deligiannis<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1132227,"post_author":38004,"post_date":"2025-02-25 12:56:59","post_date_gmt":"2025-02-25 20:56:59","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/gaganbansal\/\">Gagan Bansal<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Gagan Bansal, Senior Researcher, Microsoft Research AI Frontiers introduces a transformative update to the AutoGen framework that builds on user feedback and redefines modularity, stability, and flexibility to empower the next generation of agentic AI research and applications.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/blog\/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness\/?msockid=0accc4a56d5664cd355dd0d66ccf65e8\">AutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness<\/a><br>Microsoft Research Blog | January 2025<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/github.com\/microsoft\/autogen\" target=\"_blank\" rel=\"noreferrer noopener\">AutoGen<\/a><br>Code on GitHub<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/microsoft.github.io\/autogen\/dev\/user-guide\/agentchat-user-guide\/migration-guide.html\">Migration Guide for v0.2 to v0.4<\/a><br>AutoGen project<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>AutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>FRIEDERIKE NIEDTNER, Principal Technical Research Program Manager, Microsoft Research AI Frontiers: <\/strong>The following talk invites us to follow the journey of <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/project\/autogen\/\">AutoGen<\/a> from a leading open-source framework for multi-agent applications to a complete redesign that lays the foundation for the future of agentic AI research and applications with the release of <a href=\"https:\/\/github.com\/microsoft\/autogen\">AutoGen 0.4<\/a>. The framework's new layered architecture provides flexibility and scalability and includes an ecosystem of extensions and applications, some created by the same team, such as Magentic-One, a team of generalist agents, and Studio, a low-code developer tool. AutoGen 0.4 is also a story about collaboration between MSR, partners within Microsoft, and a vibrant open-source community.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>GAGAN BASAL<\/strong>: Hi, I am Gagan Bansal and I am a researcher at Microsoft Research AI&nbsp;Frontiers. And today I'll talk about some exciting technical updates to AutoGen, a leading open-source framework for agentic AI. And although I am presenting, this is joint work with many incredible colleagues and interns at Microsoft over the last year.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>AutoGen is a leading open-source framework for multi-agent applications that we released in fall 2023. It enables developers and researchers to create intelligent applications using large language models, tool use, and multi-agent collaboration patterns. With AutoGen, our goal has been to lead the innovation in agentic AI research. When we first launched AutoGen in Fall 2023, it quickly became the leading open-source framework for agentic AI, and it continues to empower developers and researchers in many, many domains, including business process automation, marketing, finance, security, and others.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Since AutoGen's launch, we've not just been maintaining it. We've been listening closely to feedback from developers and researchers, and in this rapidly evolving landscape of AI progress, their expectations were high. Users told us that they needed greater modularity and the ability to reuse agents seamlessly. They also asked for better support for debugging and scaling their agentic solutions. And finally, there were many apps to enhance the code quality and maturity of the platform.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Pursuing these needs required us to question our assumptions and even possibly reimagine the platform. So, in early 2024, we used these learnings to experiment with alternate architectures, and we ended up adopting an actor model for multi-agent orchestration. The actor model is a well-known programming model for concurrent programing and high use systems. Here, actors are the computational building blocks that can exchange messages and also perform work. In Fall 2024, we announced a preview of this version and this new year, we're thrilled to announce a full release. In summary, AutoGen v0.4 is our response to address our users\u2019 feedback in this evolving landscape of AI research. AutoGen is now not just a framework, but it's a whole ecosystem for agentic AI. It provides you with a framework that lets you build sophisticated agents and multi-agent applications, and it also provides you with developer tools and many well-defined applications.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Let me first tell you about the AutoGen framework. At the heart of this release is a layered architecture that is designed for flexibility and scalability. At the base is AutoGen Core. This layer implements the actor model for agents. Building on core is AutoGen AgentChat. This layer provides a simple and easy to use API that is perfect for rapid prototyping. And building on Core and AgentChat is Extensions.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>This layer provides advanced clients, agents and teams, and integrations with third party software. This layered architecture is nice because whether you are an advanced developer or a researcher prototyping new ideas, AutoGen provides you with the tools you need for your project\u2019s stage of development. The Core implements an actor model for agentic AI. At the highest level, this implementation provides two key features.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The first is asynchronous message exchange between agents. It does so by providing a runtime, and then it also provides event-driven agents that perform computations in response to these messages. There are several implications of this design, and one of them is that it decouples how the messages are delivered between the agents from how the agents handle them. This naturally improves the modularity and scalability of agentic workflows built with AutoGen, especially for deployment.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The Core\u2019s event-driven architecture provides several other benefits. For example, it provides affordances to observe and control agent behavior, which is crucial for responsible development of agentic technology. It also enables running multiple agents on different processes and even implementing them using different languages. Finally, it enables developers to implement a large class of multi-agent patterns, including static and dynamic workflows.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>When we released AutoGen, one of the first things that the developers absolutely loved about it was its simplicity and the many pre-built agents and teams that it provided, such as the user proxy agent and the assistant agent, and the group chat between multiple agents. With the AutoGen AgentChat layer, we are maintaining these features and adding tons of more essential features such as streaming support, serialization, state management and memory for agents, and finally full-time support for a better development experience.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Please check out the link below for the migration guide. Finally, the Extension layers provide advanced runtimes, tools, clients, and ecosystem integrations that continuously expand the framework's capabilities. In addition to the framework, this new release also provides upgrades to essential developer tools and applications built using AutoGen. And here I'll briefly mention two of them. In late 2023, we also released AutoGen Studio, which is a low code tool for authoring multi-agent applications.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And we are excited to announce that with version 0.4, Studio has received massive upgrades. It now supports a drag and drop, multi-agent builder. It supports real time updates as agents solve tasks, flow visualizations and execution controls, so that the users remain in control, and component galleries so that the community can discover and build on each other's work. We've always believed that the framework should enable state-of-the-art applications for solving complex tasks with agents, which is why we've been building applications with the framework ourselves and using that to guide the framework's development.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Last year, we released <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks\/\">Magentic-One<\/a>, a state-of-the-art multi-agent team for solving file- and web-related tasks built using AutoGen. And now its developer API, and general capabilities, such as sophisticated orchestrators and specialized agents such as the web server and the file server, are now available in the AutoGen ecosystem. For us, this new ecosystem is only the beginning and sets the stage for future innovation in agentic AI.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Over the past two years, our team has made early progress in AI agents and we continue to deeply think about the changing landscape of current AI research and continue to invest in taking steps to help lead the innovation on agents. And by the way, we're also working closely with our colleagues at Semantic Kernel, to provide an enterprise ready multi-agent runtime for AutoGen.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thank you for attending Microsoft Research Forum. Please check out these links to learn more about AutoGen.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How has the new update to the AutoGen framework enhanced its capabilities for agentic AI applications?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20has%20the%20new%20update%20to%20the%20AutoGen%20framework%20enhanced%20its%20capabilities%20for%20agentic%20AI%20applications?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"AutoGen v0.4: Reimagining the foundation of agentic AI for scale and more","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-and-more-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-06 15:14:03","post_modified_gmt":"2025-06-06 22:14:03","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-and-more-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269929,"slug":"driving-model-innovation","name":"Driving Model Innovation","parent":0,"term_taxonomy_id":269974,"term_order":0,"facet":"{\"term_id\":269929,\"slug\":\"driving-model-innovation\",\"name\":\"Driving Model Innovation\",\"parent\":0,\"term_taxonomy_id\":269974,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/LM6JcqLeF0U-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t08:07\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/LM6JcqLeF0U-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-and-more-microsoft-research-forum\/\" data-bi-cN=\"AutoGen v0.4: Reimagining the foundation of agentic AI for scale and more\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled AutoGen v0.4: Reimagining the foundation of agentic AI for scale and more\" icon_class=\"c-heading__icon\"><span>AutoGen v0.4: Reimagining the foundation of agentic AI for scale and more<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/gaganbansal\/\">Gagan Bansal<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1132218,"post_author":38004,"post_date":"2025-02-25 12:40:10","post_date_gmt":"2025-02-25 20:40:10","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/jcl\/\">John Langford<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>John Langford, Partner Research Manager, Microsoft Research AI Frontiers showcases a new transformer architecture that generates compact belief states for goal-conditioned planning, enhancing planning algorithms' efficiency and effectiveness.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/learning-to-achieve-goals-with-belief-state-transformers\/\">Learning to achieve goals with belief state transformers<\/a><br>October 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Belief state transformers<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>FRIEDERIKE NIEDTNER, Principal Technical Research Program Manager, Microsoft Research AI Frontiers: <\/strong>Transformer models have brought us a revolution in language modeling with their capability to generate impressive language with many emergent properties. At the same time, LLMs have a number of weaknesses, one being that they are not very good at evaluating their own output. Let's hear how the new Belief State Transformer architecture unlocks new abilities by combining a standard GPT-style architecture of a forward encoder for token prediction with an additional backward encoder.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>JOHN LANGFORD<\/strong>: I'm John Langford. I'd like to tell you about <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/learning-to-achieve-goals-with-belief-state-transformers\/\">belief state transformers<\/a>, which is a new paper we have in archives, and which is also accepted at ICLR [International Conference on Learning Representations]. There are many coauthors on this paper. I'd like to thank them, particularly Edward, who did much of the work here.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>To start with, let's talk about standard GPT-style transformers. In standard GPT style transformers, you have a sequence of symbols which are going into a forward encoder, and then the forward encoder outputs some information to the output head, and then the output head predicts the final token. So, this is a straightforward approach and yet amazingly powerful. It's kind of the key backbone behind GPT-4 and other language models.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>For the purposes of research, though, we need to have something to think about, to complain about, and I'm going to complain about self-evaluation. Often these language models can't be used to evaluate their own output too well, because the generation of the next token is done by exactly the mechanism you would use to evaluate it in that output head. So, this is kind of like grading yourself, and like grading yourself you can miss things that an independent grader would actually see pretty well.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Right, so a belief state transformer changes the architecture. And so, it's taking two transformers and grafting them together. One of them is going to be the standard forward encoder on the prefix. And then we're also going to have another transformer, which is a backward encoder on the suffix. These are both going to put out some information, which goes to the output head. And the output head is going to predict the next token and the previous token. So, it's the next token of the prefix and the previous token of the suffix. Something to worry about with these transformers is the computation. So, these are transformers obviously doing more computation. But it turns out that this \u201cmore computation\u201d is only in a constant factor of more computation.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And the key observation here is that in the forward encoder, just doing the attention, what you're going to use in the GPT-style transformer, is already order N-squared [N<sup>2<\/sup>]. Every token looks at every previous token in order to figure out what information is necessary to predict the next token. In the belief state transformer, that happens twice. You have two different transformers, each with their own attention, and so you pay a factor of two.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And then, in addition, you're going to pay because the number of times you evaluate the head, the output head, is order n squared because there are order N-squared prefix\/suffix pairs. So, there's a constant factor increasing computation, which is problematic, but it's not like the end of the world. You can subsample or things like that. And what you get in return is order N-squared gradients rather than order N gradients.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In a standard GPT-style transformer, you only have order N gradients because you only have order N symbols, and you get one gradient per symbol. Here you get order N-squared gradients because you have order N-squared prefix\/suffix pairs. That means there's many more ways to get information out of a sequence. And that unlocks the possibility of learning new things that were previously unlearnable.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Okay, so now let's go on to the belief state. Why are we talking about a belief state when we say belief state transformer. Well, it turns out you can prove a theorem. And this theorem says that the output of the forward encoder is a belief state for the prefix. So what that means is that the output of the forward encoder will converge to all the information necessary to predict the future. So that\u2019s all symbols after the prefix. So, that ability to create a compact belief state is new with belief state transformers, something that previously we only really knew how to do with state space machines.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Okay, so let's try this out. Looking at Tiny Stories. Tiny Stories is dataset where you have a bunch of children stories, which are generated by GPT-4.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We're going to feed a prefix and a suffix into our system, and it's going to fill in the middle, which is what happens in blue. And then for a baseline, we're going to compare the fill-in-the-middle approach to using GPT-style transformers. So the way the fill-in-the-middle approach works with GPT-style transformers is you take the prefix, and then you add the suffix, and then you just predict the tokens after that.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So that works reasonably well. This is very commonly used. And now if we have these two different approaches the question is how do we actually value these different approaches? Which one is better? So, the way we're going to judge this is we're going to ask GPT-4 which is better in various ways: syntax, style, and so forth. And then we'll ask it for a summary judgment, which is a standard technique.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We looked at what it was doing, and it seemed very reasonable. And in doing this, we end up with the belief state transformer winning about a factor of three more often than the GPT-style transformer. So that's huge. It's so huge that you really want to understand why. And it seems like the key here is self-evaluation. So, under the hood, we're actually running each of these, say 120 times, using a beam search. The code for that is on the right. So, given the beam search, you have several different possible completions. And now how do you choose which completion to actually use? Because you have to pick one of these. You're trying to pick a completion. And for the GPT-style transformer, there's only one way to really do this. The way is you take the next head, and you use it as a probability function, and you look at the probability of the sequence of tokens which is produced.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>That works reasonably well. It actually does improve picking out a high-probability sequence of tokens versus a lower probability sequence of tokens. But it's not as much as you get with the belief state transformer. And the reason why is the self-grading issue that I was talking about earlier. There's many ways that a system could be blind to its own mistakes. With the belief state transformer, though, you have another option, because the next head can instead condition on the generated data and run over the suffix in order to value the generated data.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, that ability to condition on generation, rather than evaluate the generation, ends up being amazingly useful in terms of giving you a more honest valuation of the generated text. All right, so just to summarize, we have this belief state transformer. This learns a compact belief state, which is a new thing in transformers. It gives us a way to have a simple set of values, which summarize all information we need to predict the future.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And this seems to provide a very strong form of self-evaluation, which is potentially very useful in many situations where you're trying to use test-time compute, or even using test-time compute to further create training data. So, this is more in the paper. There's some other things that you can do with transformer that are kind of new.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>I think the biggest question in my mind is what happens when you scale this up? And, of course, we're working on that. That's one of the great things about being in MSR [Microsoft Research]. They have some GPUs to scale this up to much larger datasets. So, stay tuned. And, thank you.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"What advantages do belief state transformers offer over traditional GPT-style models in planning and decision-making tasks?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=What%20advantages%20do%20belief%20state%20transformers%20offer%20over%20traditional%20GPT-style%20models%20in%20planning%20and%20decision-making%20tasks?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Belief state transformers","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"belief-state-transformers-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-23 11:27:57","post_modified_gmt":"2025-06-23 18:27:57","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/belief-state-transformers-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269929,"slug":"driving-model-innovation","name":"Driving Model Innovation","parent":0,"term_taxonomy_id":269974,"term_order":0,"facet":"{\"term_id\":269929,\"slug\":\"driving-model-innovation\",\"name\":\"Driving Model Innovation\",\"parent\":0,\"term_taxonomy_id\":269974,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/aqhbRtB2Fyg-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"a man sitting at a table\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t09:05\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/aqhbRtB2Fyg-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/belief-state-transformers-microsoft-research-forum\/\" data-bi-cN=\"Belief state transformers\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Belief state transformers\" icon_class=\"c-heading__icon\"><span>Belief state transformers<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/jcl\/\">John Langford<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1132209,"post_author":38004,"post_date":"2025-02-25 12:34:50","post_date_gmt":"2025-02-25 20:34:50","post_content":"<!-- wp:paragraph -->\n<p><em><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/jianwyan\/\">Jianwei Yang<\/a>&nbsp;at<\/em>&nbsp;<strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Jianwei Yang, Principal Researcher, Microsoft Research Redmond, introduces Magma, a new multimodal agentic foundation model designed for UI navigation in digital environments and robotics manipulation in physical settings. It covers two new techniques, Set-of-Mark and Trace-of-Mark, for action grounding and planning, and details the unified pretraining pipeline that learns agentic capabilities.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/ai.azure.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Azure AI Foundry<\/a><br>Code repository<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/github.com\/microsoft\/Magma\" target=\"_blank\" rel=\"noreferrer noopener\">Magma<\/a><br>Code on GitHub<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Magma: A foundation model for multimodal AI agents<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>FRIEDERIKE NIEDTNER, Principal Technical Research Program Manager, Microsoft Research AI Frontiers: <\/strong>The following talk introduces <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/magma-a-foundation-model-for-multimodal-ai-agents\/\">Magma<\/a>, an agentic foundation model, meaning a generalist model that has agentic abilities like perceiving its environment, reasoning, and taking actions to achieve goals.<strong> <\/strong>Magma can understand multimodal inputs and predict actions for real-world goals in both the digital and physical world.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>JIANWEI YANG<\/strong>: Welcome everyone. My name is Jianwei Yang. I'm a researcher from MSR [Microsoft Research] <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/group\/deep-learning-group\/\">Deep Learning Group<\/a> and very excited to talk about Magma, the most recent work to build the foundation for multimodal AI agents.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>When talking about multimodal agents, I would like to walk us through the multimodal models people have built in the past five years. Five years ago, vision-language models or multimodal models were mostly built on top of the BERT architecture. Typically, these models contain less than 1 billion parameters, and the training data is usually a small amount of images. Later on, the CLIP model came out from OpenAI. It scaled up their multimodal training to billions of images. Back then, we built our own multimodal foundation called Florence. Although the modal size is still relatively small, it shows strong open vocabulary and zero-shot recognition capability across a range of visual domains.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Most recently, we entered the era of large multimodal models. Connecting multimodal vision models, such as CLIP, with large language models, such as GPT, incurs many advanced and multimodal capabilities. Now we can have a multimodal chatbot such as GPT-4o or small 53cv, which can see, talk, and reason.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Nowadays, most of the existing multimodal models are built to make a good sense of the world. They still lack the ability to interact with the world, either virtually or physically. They cannot directly interact with the world as their inputs are captured by different sensors and then detached between the environment and the large foundation models. We believe that a multimodal AI model should not only understand the inputs but also interact with the environment as an agent in a human-like manner.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, nowadays, we are still facing a big gap between AI and human in performing tasks as simple as web navigation and manipulation. With this in mind, we developed Magma, a foundation model for multimodal agents. We are striving for a single foundation model, which is a large multimodal model that can understand the visual and textual inputs, and also predict actions for a real-world goal.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The whole model is pretty simple and straightforward. As you can see, it follows common design and takes image, video and a task prompt as inputs and then generates textual, spatial, and action as outputs for different tasks. The goal is to create a generalizable system capable of performing a varied range of agentic tasks in both digital and physical environments.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>As we well know, pretraining larger foundation models requires large-scale data. In this project, we explore a new way of leveraging a valid range of human instructional videos for our model pretraining. Consider that temporal motions in this video data are used for supervision for action grounding and pretraining. Below are four sample videos and the corresponding object motions. As you can see, the motion represented by the object trajectory can clearly indicate the action taken by humans and the robot.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, the raw vision in the video cannot be directly used, as they are usually very noisy and do not necessarily capture the meaningful object in the scenarios. We need a way to convert the motions to meaningful action for agentic models to learn. To achieve this goal, we introduce two techniques: Set-of-Mark for images and Trace-of-Mark for videos and robot data. Set-of-Mark is our earlier proposed method,&nbsp; which has been widely used by the community for UI and robotics tasks as it helps to ground the agent action spatially into the images.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Trace-of-Mark, on the other hand, is our newly developed method to capture the motions of foreground objects. The resulting traces, which with the actions, are shown at the bottom. In the end, we compared roughly 20 million training samples, which contains images, video data, and also robotics data. Each of them serve slightly different goals. Given the pretraining data, we use a unified pretraining objective, which is similar to pretraining a large language model.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>More specifically, our model takes text data as input, and then predicts verbal, spatial, and action outputs. During the pretraining, we prompted a model for action planning. At the top, we compare different numbers of pre-training data. As we can see, the more data we use for the pre-training, the better our model is for action grounding and planning. At the bottom, we prompt the model with different task prompts. It shows good generalization ability across tasks given the same image input.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>After the whole pretraining, we evaluated our model in zero-shot manner on different tasks. From left to right, we evaluated on spatial grounding, digital UI navigation, and physical robot manipulation. Our Magma model shows advantages over the counterpart methods, including GPT-4v. Note that our model is the first and only model that can perform all three agentic tasks simultaneously.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Given the pretrained Magma model, we can configure it for robotics manipulation. Using the same amount of robot data as OpenVLA, the Magma model, almost doubles the performance in different simulated environments. This indicates the effectiveness of our pretraining techniques and the potential of leveraging unlabeled image and video data for agentic pretraining. and lab of the video data for pre-training. Afterwards, we further fine-tune our model for real-world robot manipulation and UI navigation.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>At the top, we tested both seen and unseen tasks, and Magma showed much better performance compared with OpenVLA, though both methods are fine-tuned in exactly the same way. In the bottom table, we compare Magma with other methods in a more realistic UI navigation benchmark called Manage-to-Work. Using only image data as input, our Magma model achieved state-of-the-art performance in terms of the success rate.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>To summarize, in this project we developed the first agentic foundation model, Magma, that can understand multimodal input and also take action in both digital and physical environments. Considering the limited amount of pretraining data, we proposed two techniques, Set-of-Mark and Trace-of-Mark, to leverage large amounts of images and videos without human labels for model pretraining.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In the end, we get a very compatible foundation model for a wide range of multimodal tasks, including both understanding and action prediction. We have released our code and model. Feel free to try it out by yourself. At last, I want to highlight that this is a joint work by many teammates in the Deep Learning group and also MSR [Microsoft Research] as well as many external collaborators.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thank you all for your attention.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How does Magma, as a multimodal agentic foundation model, enhance interaction in both digital and physical environments?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20does%20Magma,%20as%20a%20multimodal%20agentic%20foundation%20model,%20enhance%20interaction%20in%20both%20digital%20and%20physical%20environments?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Magma: A foundation model for multimodal AI Agents","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"magma-a-foundation-model-for-multimodal-ai-agents-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-06 15:07:48","post_modified_gmt":"2025-06-06 22:07:48","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/magma-a-foundation-model-for-multimodal-ai-agents-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269929,"slug":"driving-model-innovation","name":"Driving Model Innovation","parent":0,"term_taxonomy_id":269974,"term_order":0,"facet":"{\"term_id\":269929,\"slug\":\"driving-model-innovation\",\"name\":\"Driving Model Innovation\",\"parent\":0,\"term_taxonomy_id\":269974,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/SbfzvUU5yM8-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t08:34\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/SbfzvUU5yM8-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/magma-a-foundation-model-for-multimodal-ai-agents-microsoft-research-forum\/\" data-bi-cN=\"Magma: A foundation model for multimodal AI Agents\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Magma: A foundation model for multimodal AI Agents\" icon_class=\"c-heading__icon\"><span>Magma: A foundation model for multimodal AI Agents<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\tJianwei Yang\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1132200,"post_author":38004,"post_date":"2025-02-25 12:26:36","post_date_gmt":"2025-02-25 20:26:36","post_content":"<!-- wp:paragraph -->\n<p><em>Presented <em>by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/marwinsegler\/\">Marwin Segler<\/a>&nbsp;a<\/em>t&nbsp;<strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Marwin Segler, Principal Researcher Manager, Microsoft Research AI for Science, discusses chemical synthesis in drug discovery with a learning-to-rank framework that integrates AI-based models, significantly boosting prediction accuracy and preferred by chemists.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/chimera-accurate-retrosynthesis-prediction-by-ensembling-models-with-diverse-inductive-biases\/\">Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases<\/a><br>December 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Chimera: Accurate synthesis prediction by ensembling models with diverse induction biases<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>WILL GUYMAN,<\/strong> <strong>Group Product Manager, Healthcare AI Models: <\/strong>To design a new medication to defeat an illness, scientists need to predict which blend of molecules can be transformed into medicines, a tedious process that traditionally takes decades and can cost billions. Researchers at Microsoft Research and Novartis have been developing a novel approach to addressing a major bottleneck in this process called retrosynthesis, figuring out how to start from a target molecule and plan the chemical steps needed to make it. In practical terms, that means cutting down on trial-and-error experiments, speeding up how quickly researchers can create new molecules, and ultimately lowering the time and cost needed to develop new treatments. I'll now hand it over to Marwin, who will explain how this technology works in detail and discuss its potential impact on future drug discovery.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>MARWIN SEGLER<\/strong>: Hi, I'm Marwin, principal researcher at Microsoft Research AI for Science. And on behalf of the team, especially Chris and Guoqing, I'm going to tell you a story about life and death. Small organic molecules are central to human well-being. As agrochemicals, they have to feed the planet; as drugs, they keep us healthy and help us, hopefully, to prevent from dying too early; and as materials, they help to improve the quality of our lives. To get access to small molecules, one needs to synthesize them in the lab via the synthesis route. And the synthesis route, you can think about it like a cooking recipe, where we start from the ingredients and then run several steps until we reach the final product. And to plan a synthesis, chemists often start with the targets that they want to make and then work their way recursively backward to the starting materials.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, synthesis can be super challenging as reactions can fail, and also in this multi-step synthesis the errors can compound. And this is one of the reasons why small molecule drug discovery, for example, is so much slower and more expensive than protein design, where we have had so many recent breakthroughs. And AI models that could help chemists to find better synthesis routes will really have a profound impact on how small molecules are discovered and produced, with the potential to really accelerate the discovery of much-needed new functional organic molecules. So how can we address this major bottleneck? First, we need the synthesis prediction model. And this model takes in a molecule, a target molecule, and predicts a list of feasible reverse chemical reactions, basically.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And this is similar to learning how to predict the moves in a chess game. But in chess it's relatively simple because we actually don't really need a model, because we can just implement the rules of the game perfectly as a very simple program. But chemistry is much, much more complicated. So, we need to learn this model from actual experimental data.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We can thus think about this model that we're learning as a chemical generative world model that predicts which reactions are feasible for a given molecule in a given situation. And once we have such a model, we can plug it into a search algorithm and recursively apply it to get a full multi-step synthesis route.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>How can we model chemical reactions? We can represent molecules either as graph structures or using SMILES [Simplified Molecular Input Line Entry System]. SMILES is basically the token sequence representation of the graph and carries the same information. Now, given the target product that we want to make, we could either use an auto-regressive model to generate the SMILES sequence of the reactants de novo.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So in whole, new, token by token. If one knows about language models, it\u2019s very similar to that. This is very appealing, because it leaves it to stochastic gradient descent to figure out this process end to end. However, it has a disadvantage, because in chemical reactions usually only a small part of the molecule changes, and with this de novo model we need to copy the whole, also unchanged parts.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So here, in this reaction, only the marked parts change. So what we could do as well is just predict these edits that we have to apply to the molecule. And these edits can be very well represented using simple rules or so-called templates, which we can just derive from the training data. We could just predict those edits.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now how do we implement these models? The de novo prediction model, we can implement as a sequence-to-sequence model using modern transformers, using grouped multi-query attention and modern activations.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>An edit-based model, we can implement via a dual GNN that includes both the product and these edit templates. And then we perform classification of which is the most appropriate templates in our database, or a collection of templates that we can apply to the molecule.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now there is an additional complication, which is where do we apply this template in the molecules? Because there can be multiple matches. And for this we have an additional localization model that gives us calls to where the template optimally matches in the molecule. And this second one we can also train with stochastic gradient descent. Now we have the best of both worlds.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>But how do we combine the outputs of these two models together? And again, we need something which is learned. And we came up with a new learning-to-rank strategy, where we have an additional model that scores the outputs that the different models provide. And then provides a rescoring, which we can then use to rerank the outputs of the model to build an extremely powerful ensemble of models. And by combining these two models of complementary inductive bias, you will see we get extremely exciting results.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>But first, we need to make sure that we're really able to check what's going on. And the issue with chemical data is that it often has temporal bias, so it's somewhat clustered over time. So, if we randomly split the data, we get this weird time-machine effect. So, what we did instead was to make a clean type-split of the data. So we train our model only based on reaction data from patents that was published up to 2023. And then test the models on data published from 2024 onwards.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And then as a metric, we asked the model to make 50 predictions for a test set product, and&nbsp; then measure how many times the model was able to recover the ground truth reactants on this data. Now, we can measure how the models are doing in different regimes&nbsp; and what we're seeing with all the models that have been published for the baselines is that they tend to work super well when there's a lot of data, as in the typical deep learning regime. However, reactions where we don't have lots of examples in the training data are very often super important for synthesis strategy. So, you can see this here where we saw that the performance of models by the frequency of how often different reaction classes occur in the training data. And so far, this has been a major limitation of deep learning models in this domain.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thankfully, with our model, we can basically not just outperform all the baselines that are typically used in the, in the literature, for the very frequent cases, but we can also really make progress on the classes where we don't have that many training data and data points in our data sets. And we can even maintain very, very high performance in the cases where we just have two examples in the training set, which is usually super rare to achieve with deep learning models.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And even if we just have one example in the training data, even for the zero-shot case, we can still achieve reasonable performance whereas the baselines drop off. Yeah, completely, basically. And that's super important for synthesis strategy.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now, another question is how robust is the model where we move further away from the training data? And it's very important in discovery because, by definition, we need to make predictions on new things, on new molecules that have never been made before. And we can measure that by chemical similarity. So how far the molecules in the test set are away from the training data. And existing baselines, they drop off quite a bit. But with our new ensemble, we can basically achieve a step change in how we can predict the further we go away from the data, and we can completely maintain high performance even when we move very far away from the training data, giving us a sense of the out of distribution prediction capabilities of our model.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And why is it important? Again, in drug discovery, one needs to make new molecules that have never been made before. Structurally, very new, very different. And with these improvements, we can now apply synthesis prediction with much, much more confidence to new molecules. And to give you an example of how that would look in practice, here's a synthesis route predicted by our model for a molecule you could typically expect in a drug discovery project, which is non-trivial, so it\u2019s quite a long sequence of steps.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And, just to give you an example of rare reaction classes, the model is able to predict these specific Hemetsberger-Knittel Indole Synthesis step, which maybe as a chemist you would not immediately think about. But the model is able to retrieve it and propose it. And in this context, it actually makes sense. So, to give you one example of how these rare reaction classes can be highly strategic.&nbsp;&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And we think, in the future, predictive synthesis will really help chemists to accelerate the discovery of new essential molecules. And if that excites you, check out the extensive results in our paper, including validation with our great collaborators at Novartis. And up next, you're going to hear from Jianwei Yang from the Microsoft Research AI Frontiers team to introduce Magma.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thank you for listening.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How might the use of AI models in synthesis prediction impact the future of drug discovery?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20might%20the%20use%20of%20AI%20models%20in%20synthesis%20prediction%20impact%20the%20future%20of%20drug%20discovery?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Chimera: Accurate synthesis prediction by ensembling models with diverse induction biases","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"chimera-accurate-synthesis-prediction-by-ensembling-models-with-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-23 11:34:23","post_modified_gmt":"2025-06-23 18:34:23","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/chimera-accurate-synthesis-prediction-by-ensembling-models-with-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269932,"slug":"transforming-scientific-discovery","name":"Transforming Scientific Discovery\u200b","parent":0,"term_taxonomy_id":269977,"term_order":0,"facet":"{\"term_id\":269932,\"slug\":\"transforming-scientific-discovery\",\"name\":\"Transforming Scientific Discovery\\u200b\",\"parent\":0,\"term_taxonomy_id\":269977,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/FvziVbhHVSE-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t12:06\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/FvziVbhHVSE-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/chimera-accurate-synthesis-prediction-by-ensembling-models-with-microsoft-research-forum\/\" data-bi-cN=\"Chimera: Accurate synthesis prediction by ensembling models with diverse induction biases\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Chimera: Accurate synthesis prediction by ensembling models with diverse induction biases\" icon_class=\"c-heading__icon\"><span>Chimera: Accurate synthesis prediction by ensembling models with diverse induction biases<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/marwinsegler\/\">Marwin Segler<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1132188,"post_author":38004,"post_date":"2025-02-25 12:20:00","post_date_gmt":"2025-02-25 20:20:00","post_content":"<!-- wp:paragraph -->\n<p><em><em>Hosted by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/hoifung\/\">Hoifung Poon<\/a>, with&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/liliqiu\/\">Lili Qiu<\/a>,&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/avasoleimany\/\">Ava Amini<\/a>, <a href=\"https:\/\/www.linkedin.com\/in\/carlo-bifulco-8b123124\/\" target=\"_blank\" rel=\"noreferrer noopener\">Carlo Bifulco<\/a>, and&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/mlungren\/\">Matthew Lungren<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum<\/strong><\/em><strong>, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>This panel discussion with Microsoft researchers and external guests explores the transformative potential of generative AI in learning the language of nature and patients for precision health, from proteins to medical imaging, from electronic medical records to home health monitoring. Emphasis is placed on the end-to-end innovation cycle from foundational research to deep partnership to productization.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/blog.providence.org\/national-news\/comprehensive-genomic-profiling-leads-to-better-patient-outcomes-new-joint-study-says\" target=\"_blank\" rel=\"noreferrer noopener\">Comprehensive Genomic Profiling leads to better patient outcomes, new joint study says<\/a><br>Providence Blog | November 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/industry\/blog\/healthcare\/2024\/10\/10\/unlocking-next-generation-ai-capabilities-with-healthcare-ai-models\/?msockid=2cf9e53ba73e6362243bf1caa6ba6226\" target=\"_blank\" rel=\"noreferrer noopener\">Unlocking next-generation AI capabilities with healthcare AI models<\/a><br>Microsoft Industry Blog | October 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Panel: AI for Precision Health: Learning the language of nature and patients<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>WILL GUYMAN,<\/strong> <strong>Group Product Manager, Healthcare AI Models: <\/strong>To talk about generative AI models and the impact they are beginning to have in the real world, Hoifung Poon will host a panel discussion with a distinguished group of experts. Representing our Microsoft Research is Ava Amini and Lili Qiu. They are joined by Microsoft\u2019s Chief Scientific Officer in Health and Life Sciences Dr. Matthew Lungren, who is also a practicing physician and maintains research and teaching roles at Stanford University in AI and medicine. To round out a stellar panel, Providence\u2019s Chief Medical Officer Carlo Bifulco joins to provide another voice on the real-world implementation of generative AI in clinical settings. Back to you, Hoifung.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>HOIFUNG POON<\/strong>: Hi, everyone. Welcome to Microsoft Research Forum. Today we will have a very exciting panel discussing AI for Precision Health. As we all know, there are two fundamental challenges in today's health care, right? So first, medicine can be very imprecise and doesn't work for the patient, right? So for example, immunotherapy is the cutting edge cancer treatment today. And indeed, you will have some of the blockbuster drug like Keytruda? that can, you know, work miracles for some of the late-stage cancer patients. But overall, the survival is still hovering around 20, 30%, right. And then second challenge is like high-quality healthcare is just too expensive and very hard to scale. Right. So, for example, even in the U.S., 85% of cancer patients, actually are treated in this, rural or community hospital that simply doesn't have the kind of resources and care quality like some of those more comprehensive cancer center like Mayo or Memorial Sloan, right. So and, sometime disparities in you know, simple information access, can be life or death. So what's really exciting, these days, is that the GenAI revolution really brings us unprecedented capability. To start, \u2026 you can think about it as learning the language of nature to patients, right? And that starts to give us some very powerful tools to start accelerating biomedical discovery so we can drastically improve the healthcare quality and also, career opportunity for us to drastically reduce our healthcare costs. So now we can democratize that high-quality healthcare for everyone.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So now, of course, this undertaking is a really, kind of moonshot aspiration and really takes way more than a village. Right? So at Microsoft Research, we are super blessed with the privilege to actually have fostered deep collaboration across amazing researchers all around the globe and also with our, kind of, beloved health and life sciences product division.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And also we have key external stakeholders, such as large healthcare systems. So, you will see that, this panel really is a perfect reflection of that deep collaboration across the board. So, we will start with a quick intro by every panelist about who they are and what's the chatter and what gets them excited these days. And also we'll dive deep into the key opportunities and challenges. So, maybe Ava, can we start with you?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Ava Amini<\/strong>: Absolutely. Yeah. My name is Ava Amini, I'm a senior researcher at Microsoft Research, based in the New England Lab, and also working closely with Health Futures. My passion is really in building new AI methods to accelerate our ability to understand biology and also to design biology. And this is rooted in kind of a fundamental curiosity about bringing the power of computation and quantitative science and engineering to the biological world so that we can learn the language at which biology operates. And for me personally, I'm most interested in how behavior at the cellular level arises from the interactions and activity of individual biomolecules, how these processes become dysregulated in disease, and how we can understand those regulations and dysregulations to now develop more effective and more personalized treatments. So really thinking about the vision of bringing the power of AI to unlock new biological insight so that we can move towards our ability to create new therapies and better interventions that hopefully could be implemented in the clinic and at the patient level.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Well, that's fascinating. Like you are learning the language of biomolecules and so far, and really the fundamental kind of biology, So Lili, do you want to go next?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Lili Qiu<\/strong>: Sure. I\u2019mLili Qiu, Assistant Managing Director, Microsoft Research Asia Microsoft Research Asia, mainly responsible for leading the Shanghai Lab. Our mission is to develop a sensing and machine learning for healthcare. Complementary to Ava, our focus is to learn the language our patients outside hospitals. With the rise of chronic diseases, unpredictable health crisis and the demand for personalized treatment, traditional hospital-based monitoring is no longer sufficient.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Consider a patient with a cardiovascular killer disease who visits hospital just a few times a year. On the surface, everything seems fine; stable blood pressure, a steady heart rate, and normal respiration pattern. Yet, between these breaks, subtle flucuations can occur. Warning signs that remain invisible, until they escalate into life-threatening emergencies. For me, this scenario isn't an abstract concept, but a painful reality. I lost both my mom and my grandmom to cardiovascular disease while they were at home. Their passing revealed how critical it is to have better monitoring tools that extend beyond hospital wards. Their memory was what motivated me to explore and develop in-home continuous monitoring tools to prevent similar heartbreaking loss and protect patients even when they are not at hospital.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Advancements in sensing and I could make it possible to track individuals\u2019 health in real time by continuously monitoring vital signs and body movement. Health care providers can gain a deep and more comprehensive and accurate understanding of a patient's condition. This could yield many benefits. Here I just will highlight three of them: First, we could do early detection and prevention. With continuous monitoring deviation from normal health parameters can be detected early, allowing for timely intervention before a condition gets worse.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Second, personalized and adaptive treatment plans is possible. No two patients at the same. Precision medicine requires individualized treatment plans based on real-time data. Continuous monitoring allows doctor to tailor their medication and lifestyle recommendation and therapy strategies based on actual patient behavior and physiological response over time. Moreover, we could enhance the patient engagement and quality of life while reducing healthcare costs.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>When patients are equipped with real time insight into their own health, they become more engaged in their well-being. Wearable devices and mobile apps to empower individuals to make informed lifestyle choices, adhere to treatment plans, and actively participate in managing their health. This could not only improve patient outcome, but also significantly cut down healthcare costs.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Awesome. Well, that's, I really appreciate you sharing some of those, kind of really powerful personal stories, right. So, that actually remind me so many years ago, one of my colleagues, share also a very kind of, like, inspiring story. She had, brother, right, who was diagnosed with cancer, in actually Eastern Washington, Spokane, specifically.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And they found a mutation that actually renders standard healthcare doesn't work. And so normally the prognosis is like six months, right. So and, and my colleague persuaded him to literally drive two hours west to for a hutch. And there they found a matching trial that actually put the cancer in remission, right. So that that kind of, sort of really powerful story is like, how can we actually democratize that kind of, right, to everyone so that it, it doesn't just, so on that. On that note, actually, Carlo, do you want to go next? Right. Because you are so really deep in the trenches.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Carlo Bifulco<\/strong>: Yeah. Thank you, Hoifung, indeed in the trenches. Yeah. So my background is, physician scientist, currently serving as CMO of Providence Genomics. For people unfamiliar with Providence, big healthcare network on the West Coast. And our program\u2019s focus is really to bring precision medicine and personalized medicine to cancer patients in the context of that, kind of, very diverse network. On the research side, my work is really focused on genomics, but also spatial biology and AI. And the approach is really translational. I think we try to bring all these modalities to impact patient care in the future. And current patient care whenever we can. Specifically, for this, I think we I had the fortune of working with you all from the Microsoft research team now, I think for six years. And I think we have so much convergence. Right. I think we had a very interesting applications of NLP and AI in the real-world evidence kind of space, clinical trial matching. And we have built an ecosystem which extends to precision medicine to solutions like mobile network tumor boards and other things that really, hopefully, impact patient care.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>I think most of what I'm most excited currently is really, you know, an opportunity we had recently which is focused on making a paradigm shift in pathology. We brought generative AI and large foundation models to that field. I think we were one of the first groups to do so, with a very large, open-weight model called Prov-GigaPath.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>I think it's approximately, you know, more than 1 billion parameters, 1.3 billion, if I remember correctly. You know, very impressive, we had 500,000 downloads on Hugging Face. So, super surprised by the impact. And, you know, very pleased by the impact that this is having. And for the future, you know, working on integrating all these modalities, multimodalities hopefully, with things like genomics, spatial biology and so forth.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Yeah. Thanks so much, Carlo. Obviously a disclaimer is that we have this, super privilege to be able to work with you, right. Exactly. Like when I do the math, yes years. Sorry. And oftentimes like, the challenge is like, yes, so we are all machine learning and modeling folks, right? And then we often think of our machine learning and modeling, but also there is lots of groundwork, right? How do we actually get the data, get the compute set up. Also, adhere to privacy compliance, make sure everything is responsible. And then having this super privilege to be able to really deeply collaborate with you. And also I think that also leads to a very exciting prospect, is that how can we kind of take the learning from, like, this, some of this, kind of, deep partnership, right, and really try to start to impact? Can we start to impact millions of, if not billions of patient, rights? And for that we need scaling.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, Matt, no pressure, but really want to, get your perspective here.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Matt Lungren<\/strong>: It's all about scale, Hoifung. So, I'm Matt Lungren, I'm the chief scientific officer at Microsoft Health and Life Sciences. And I've kind of got an interesting role. So my background as an academic physician, and, you know, spent a lot of time sort of in both the clinical world, but, you know, also in the core research world, right. And sort of bridging those gaps, kind of starting to become a pattern, I guess, in my career. But now, I kind of do the same thing. But to your point, Hoifung, it's definitely a scaled effort. And so, we are a group of data scientists, PMs, and obviously some engineers that really are focused on working bidirectionally across both the organization and externally with partners. And what we're looking to do is we're saying, okay, what are the core problems in health care? Where are the gaps in some of the technology that we see today? And then what kind of innovations are happening that might, you know, fill those gaps? But the bidirectional aspect is also kind of translating some of those gaps or opportunities in the healthcare space over to some of the core innovation areas to say, hey, I think if you know, if you had if you had a technique that could actually address this, we can actually make a huge difference. And I think, I think what's really wonderful about working in sort of this collaborative group as a great example is you've heard sort of from the biologic discovery, the sort of clinical translational, you're hearing about how genomics and images kind of come into play.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>There's sort of a beautiful story here about all of these modalities kind of coming together, to your point, Hoifung, to learn the language of life or learn language biology. And I think we're in a really interesting moment where, you know, we recognize that these powerful language models are, you know, they're very competent across a lot of different concepts, and particularly in the tech space. And where we see the opportunity is really to translate that ability to, you know, easily access the information, process the information, potentially even enrich the information. But also leverage the data that we know has a lot more information about our patients. And that's obviously clinically, in the imaging space. And so, I'm just delighted about the opportunities to come. And again, I think this effort that we've talked about, the model that the Carlo referenced is currently on the Azure catalog across many other modalities as well. And really unlocks the opportunities for the healthcare developer ecosystem to say, hey, you've actually got me pretty close to my goal line here with some of the things you developed, let me take it to the finish line and start to translate that at scale. And that's exactly what we're seeing.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Yeah, thanks. Thanks a lot, Matt. And really, amazing to see your leaderships and, and try to actually get a lot of this kind of, you know, models, right, to start being able to democratize them in AI foundries and so far to really start to put the put them in the hands, right, of folks who can start playing with those model and explore applications. So super, super exciting. So, so one theme I\u2019m &nbsp;really kind of hearing and seeing is like, there is, sort of like a lot of this kind of challenges, as Matt, you just mentioned. Like in the text modality, we kind of learn relatively, quite deeply. Right. But, on the other hand, there are many biomedical modality that are non-text modality that seem to have a lot of unique challenges. So Ava, I want to kind of get back to you is like you, you and the team have done some really amazing work, right? As you mentioned, on biomolecule proteins and so forth. So, what's your top of mind in terms of some of the key challenges that you see? And what are some of the learning you have found?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Amini<\/strong>: Yeah. I think for me, the what's really top of mind connects back to this theme of bidirectionality that Matt and Carlo and Lili and yourself, Hoifung, have raised. And that's really core for how we think about, you know, AI in this space of biology and how we actually operationalize that. So, it's not sufficient to just develop competent models that can learn over protein sequences or protein structures or other biological modalities. What we really care about in this next phase is how do we bring those models to translation to unlock real biological discovery. And so as a step toward doing this, we're really excited about a long-term partnership that we have with the Broad Institute of MIT and Harvard, specifically focusing on cancer cell biology and this notion of, how do we think about cell states in cancer beyond just the genomic measurements of point mutations and alterations that are in DNA? But how to actually use AI to learn representations of cells as a whole and how they interact with other local influences in their microenvironment. And so, we've launched a a research collaboration with the Broad Institute called Project Ex Vivo that really kind of exemplifies this theme of bidirectionality. And in fact, we have a dedicated lab group and wet lab space at the Broad Institute where we can actually, as computationalists and AI scientists, go in and inform the design of experiments that are generating data and also validating the predictions of our models that we're developing. And I think that speaks to this core challenge for this next phase of AI for biology, of how do we actually build synergistic relationships that are truly bidirectional, and use that as a catalyst to actually bring these modeling efforts to the biological lab. So that's something that's at a high level really exciting and really top of mind for me.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Awesome. That's really fascinating because you're basically, you know, bridging the dry and the wet lab, right. So you\u2019re basically having the infinity loop start kicking in, having a discovery cycle kind of like really going on steroids. That's really fascinating. So along that same line, Lili, you mentioned earlier, the aspect that you've been focusing on is a lot of this kind of remote sensing opportunity, right, and often to some extent addressing some of the gap that conventional clinical data collection may or may not have at high density. So, kind of like similar question to you is like, what do you see as some of the major bottlenecks and what does what do you see as some of the key learning?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Qiu<\/strong>: Sure, Hoifung. Yeah, continuous health monitoring has lots of advantages, but it does introduce significant challenges. Here, I will quickly go over five main challenges that we've been looking at. First is achieving ease of use. Hospital-grade monitoring devices often require professional medical staff to operate, but in-home devices need to be very intuitive and user friendly so that elderly people such as grandma and grandpa can operate them independently. To address that, we are developing very simple wearable sensing, such as earphone sensing that requires minimal user intervention. Second, we need to achieve high precision and robustness. In-home health monitoring devices are typically designed with cost-efficiency in mind, and ideally, they need to support noninvasive sensing. This makes it very challenging to achieve with high accuracy and robustness. To enhance reliability, we are exploring hardware and software co-design. On the hardware side, we are developing advanced metasurface to dramatically enhance the sensing resolution. Metasurface, consist of many sub-wavelength cells like shown here. And these elements are designed to manipulate waves in ways that conventional material cannot. By carefully designing the geometry and material properties and spatial arrangement, we can enable metasurface to have very high flexible control over wavefront shaping and achieve high-resolution sensing. On the software side, we are developing advanced machine learning algorithms to support multimodality data. Third is to increase the sensing range and support mobility. Users expect a continuous monitoring regardless of their location, so sensing should continue to work even when users are moving around throughout their environment. So we developed a metasurface-based approach to enhance the sensing range so that a user can be sensed even when they are far away, or even when they are covered with blankets. Fourth is the mental state sensing and training. Continuous sensing does not just track vital signs, but also provides real time insights into a person's cognitive and emotional well-being. We are developing an approach to track a user's mental state. Meanwhile, we are also developing a large language model-based cognitive training tool that draws on each user's daily experience to reinforce episodic memory. This ensures these exercises not only feel relevant but also engaging. We demoed our cognitive training tool on last year's World Alzheimer\u2019s Day and receive great feedback. And we think continuous at-home monitoring and tailored intervention can potentially improve cognitive care. Last but not least, achieving timely processing and energy efficiency. Because this continuous monitoring can generate a large volume of data that must be processed in real time on a user's device. So our team is actively working on edge computing and lightweight modeling to achieve low latency and enhance energy efficiency.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Wow. That's fascinating really. Thanks so much for sharing. When I personally think about continual monitoring, the first thing that comes to mind is like the continual is the glucose monitoring, right? For diabetes patients. But what you touch on, some of the cool sci-fi stuff, like this metasurface. Like people maybe eventually can wear a shirt, right, to keep monitoring and also go beyond just metabolic but also some of the mental and other, that that's really fascinating. So, I want to continue toward more and more clinical application. So Carlo, you earlier mentioned about sort of like really two themes, right. So one is when we think about precision health, one of the marquee poster child? is cancer. So you mentioned some of the application side like tumor board trial matchings and so forth. You also mentioned another part which is on the technological front, right. Like how do we go about some of this kind of like, emerging modality, like pathology, but also even spatial omics? And also you seem to also touch on some of what Ava and Matt alluded to also eventually how do you pull those multilingual right, multi-model together. And so&nbsp; again, similar question is like what do you see in both fronts, application and technology? What are some of the key challenges that you see that really keep you up at night?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And what is some of your learning over the years?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Bifulco<\/strong>: Yeah. So super exciting to hear from Ava and from Lili on the progress that you can make in basic science and, and also, on the, not on the patient, but at a personal level in in collection of large data sets and so forth. On the clinical side, things are a little bit more challenging because we have a lot of overhead coming from the complexity of patient care, regulatory frameworks and so forth. So the progress is, you know, is great, but not always as great as I think as it could be. There are some sweet spots still that I feel are, you know, where we can move rapidly. And I think those have to do with the areas that are really of translation. So thinking of clinical trials is a setting where we can move very rapidly and really make an impact. Biomarkers is another area where we can do to same, real-world evidence is another area where things can move super rapidly. Having said that, you know, I'm super optimistic about the impact of AI. Even in routine patient care. I mean, I don't want to sound too worried about this. I think there's a very bright future ahead of us, and almost inevitable. But I just wanted to acknowledge that there are some complexities and some challenges in bringing this technologies to fruition in a conventional setting. And all of those can be, you know, overcome. But they will require a big effort at multiple levels.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Awesome. And and so now back to you, Matt.&nbsp; So as you, mentioned. You have this really amazing, almost like panorama kind of wheel, from academic to industries. And now really leading our scientific effort on our product health and life sciences product division. So, what do you see? Kind of like coming to see from all these angles, from foundational research, to a partnership to productization. What do you see ultimately, how do we address some of this last mile? Some of like what Carlo mentions. How do we really make the I count for patient care.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Lungren<\/strong>: Yeah. I was just kind of just reflecting on some of the comments around the, the incredible innovations that have that have been going on. This is just obviously, as you know, a small sample of some of the tremendous work that we see. And then I do my clinical time and I walk by a fax machine in my office, right. So there is a gap. There's no question about it. Carlo knows very well. And, you know, on a macro scale you can see it in sort of the conferences. You can go to NeurIPS and see some incredible things, and then you can go to the American Medical Association conferences. There is a divide, but I think that's closing. And I'm extremely optimistic. And part of it is, you know, you look at successful applications of AI to solve a clinical problem. And I'll just use one example that much of the audience may be familiar with, which, you know, when you think about what are the immediate needs, like before we can get to the future state, the things we want to see happen, we have to solve the problem. We have to put out the initial fire. And the fire, of course, is really burnout, right? We have a crisis obviously, in the U.S., but certainly, this is this is an issue, I think, across the world. And clinicians have too much to do, too much complexity to sort of handle. And they're looking for some time back, if I'm being honest. And so, you know, when I look at some of these technologies, I sort of say, we're going to save time before we save lives. And the DAX Copilot solution, if you if you've heard of it, it sounds very simple on its face. Maybe you wouldn't, you know, present this as the keynote at a computer science conference, but yet it's solving an incredible problem. And what's interesting about it is by saving that doctor some time, you're also generating kind of a comfort level with, hey, this AI solution is actually making my life better. But it's also to the to the point about the last mile. It's also in the last mile. And from that place can we build out there? So, you know, just to use an example, Lili's talking about some biometrics. Well, there's voice data that comes from that interaction that then gets transcribed into a note. Well, there's voice biometrics that we all are starting to become very familiar with. Well, now I can start to add that in. And now there's almost a foothold right into the real clinical world. And you're building from a place that physicians are kind of congregating around or at least familiar with. And so, I'm extremely bullish. And that's outside of just the fact that maybe more so than ever, you see seen the New England Journal has a new journal about AI. That is a huge sign to me that there is an absolute, you know, Cambrian explosion of interest from the clinical side, not just sort of in the technology, but just how do we use this and how do we learn about applications for this? So, maybe more so than ever, I feel like that that divide is starting to really close.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Yeah, that that's a really amazing insight. You know, you mentioned about, DAX Copilot. Right. And but also this whole feel about kind of ambient intelligence, right? That it feels like, you know, even just a couple of years ago. This feels super kind of sci-fi novel concept that you could have patient and doctor talking. And then actually the computer actually take care of the notetaking, right? And maybe even start to alert, you know, some of the things that maybe the doctor may have forgotten and so forth. Even, again, even a couple of years ago, felt so sci-fi. But now actually, DAX has, right, like, as you mentioned, has already taken so much, kind of, [INAUDIBLE]. But also there is a lot of other kind of similar undertaking that really testify to how this notion that like the genAI revolution can really move things much faster, right? So that that is so, so exciting. And also, I really love what you bring up about like, save time before saving life. So by starting from sort of like productivity again, then eventually we could really get to the even the creativity gain. So that that's super, super exciting. So, I think we can talk, you know, for hours and hours, but I think we, we have, some final chance to start to kind of elicit some of the other insights from you guys. And I think this will be a very fun run. So we'll basically ask each of you to make a prediction for the future? Like what might happen in five years, right? And so, Ava, can we start from you?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Amini<\/strong>: I have the hard job of going first for this question (laughing)<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Or the easy one (laughing)<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Ava<\/strong>: I think, you know, honestly, we're at this incredible moment of a true inflection point in our capabilities with technologies like AI and it's really impossible to predict exactly what's going to happen next. But I have my vision and ideas about what that landscape could look like. And so right now, we've seen breakthroughs in our ability to use the power of generative AI and foundational models to learn over these individual biological modalities. So, for example, protein sequences like our work with EvoDiff or pathology data like GigaPath and Virchow and other biological modalities that are coming to the forefront. As an immediate step, I think we're going to see a shift in bringing this information together, right? To be able to reason across the scales and the hierarchy of biology, from the level of individual molecules to cells to tissues to patients, and try to, you know, put this information together from a modeling perspective and also from an application perspective. And then I think looking forward to a few years down the line hopefully that leads to this vision that you raised Hoifung of how do we actually bridge that iterative loop between the experimental world and the computational world, such that we have AIs that can help us propose new hypotheses and go test them in the lab. And I think that's something that I'm optimistic to see in five years. And hopefully that leads to drugs, therapies that are discovered or designed from scratch by AI and are put into pre-clinical or clinical testing. And I think that's a very real possibility to think about. And then finally, to close, you know, I think this panel is really awesome because we have these different perspectives of, you know, someone thinking about fundamental research at the biological scale, like myself and Lili, with the perspectives on, you know, how do we interact with humans in their real lives and in kind of a cultural sense and the clinical partnership with Providence and, you know, the scaling perspective that Matt brings. And my ultimate vision is that five years from now, we have a way as Microsoft to come together and put these pieces, like bring these pieces together to life, to really create solutions at scale and that's pretty high level. But I think that we are empowered to do that. And that's what I'm really excited about.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: That's amazing. Just to echo some of your points about this kind of multi-scale learning, right, to bridge between different scales, by biological mechanisms and so far, but also really to, actually closing this discovery and translation loop. So that that's super exciting. So, Lili, you highlight did this really important part to how can we fill in some of this CAB modality that conventionally may not be collected. So I'm curious, if you\u2019ve thought about in five years. What do you see could actually happen. Will we all have metasurface vests? (Laughing)<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Qiu<\/strong>: Yeah. That's our hope. First of all, I'd like to express my deep appreciation for the opportunity to learn from Hoifung, Ava, Carlo and Matt, your perspective. For continuous health monitoring, what I see is, it's more than just a technology advancement. It's a paradigm shift in healthcare. So it means that healthcare is no longer constrained inside a hospital. It's everywhere. No matter where we are, every step we move, every eye movement we make, every breath we take, every heartbeat we strike, every brainwave signal we generate is being sensed and analyzed to understand our health condition. And what we envision for the future is there will be no more travel, no more waiting room, no more frequent needle pricks, just timely virtual interactions with doctors empowered by advanced sensing and AI. And this shift is not only meaning convenience, but also hope. So with the aid of continuous monitoring, even minor physiological frustration, such as a slight rise in blood pressure or subtle changes in heart rhythm or blood glucose level, can be detected before they escalate into life threatening crises. By continuously tracking each patient\u2019s state, a doctor can tailor their treatments and adapt immediately, rather than waiting on tests only taken at occasional hospital visits.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So our vision is to put advanced diagnostic and treatment at people's fingertips so that they can use at home to make healthcare more proactive, personalized and powerful than ever before.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Oh, that's amazing. Thanks. Thanks so much, Lili. when I was posing this question about in five years, I was also thinking about how people constantly make this kind of joke about in five years from now. And then, obviously this day, one of the hot topics would be AGI. Right. So apparently probably we will get AGI before five years. But when we think about, let's say curing cancer, right? So like I joke with my team that let, let's try to solve cancer before we get one. And so Carlo, I'm curious about what's your take in five years? Like how close are we to start fundamentally, understanding, you know, cracking some of the cancer mechanisms? Will we be there in five years?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Bifulco<\/strong>: Yeah. Great question. And also hard act to follow, Ava and Lili's, vision. But I don't know how close we are going to be in fully understanding cancer, but I feel very confident that we will look back to our current stage as a dark age. Because I do think the impact of AI is going to be transformational. That applies to both biology as we heard before from Ava, you know, I do think we are currently generating so much data, and the capability of generating is so large that we need AI to actually manage that. But it also goes, you know, back to what Lili said. I do think in the future, AI will interact with people before they go to see a doctor. From a medical perspective, actually ideally not just medically, it\u2019s health. It will really drive their health and their behaviors from a health point of view. In terms of medicine itself, I do think that we will reach a state where physicians will not be allowed to see patients without a companion, an AI companion of some point. I don't know if that's going to happen in five years, but I do think is going to be inevitable at some point. And lastly, you know, vis a vis Matt, you know, radiologists, pathologists. I think pathology and radiology are going to fuse and merge. I'm not sure is going to be great news for the radiology. But I think all the imaging modalities are going to be one single thing. And AI is going to mediate that interaction with the physicians and that kind of landscape.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Yeah. Fascinating. And, and I think also, as Ava mentioned earlier, aside from this existing conventional imaging modality, there are also a lot of these emerging, like measuring cell states and everything, and then coupling all of them together. It's kind of like incredible, like a microscope to some extent. A virtual microscope. But also incredibly challenging because like you said, the high dimensionality, the noise and everything and, and, and really sort of tailor make for AI to hopefully help. And so, the should we say billion dollar question, the trillion dollar question, how can we really make this kind of viable, to put this technology to eventually democratizing this, high-quality healthcare to everyone? Matt, we really want to lean on you with all your diverse perspective. What do you see would be happening in five years?<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Lungren<\/strong>: Well, I mean, I can at least predict that we won't have fax machines anymore.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: You sure? (laughing)<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Lungren<\/strong>: I'm willing to bet on that one. Five years is hard, right? In this current environment. We're seeing some pretty surprising acceleration in sort of the general purpose technologies, I think you've heard from some of the speakers. So I mean, we are clearly, I think advancing science at a pace that at least I haven't seen in my career in my career in the last 20 years. So, with that being said, you know, I think that there's a couple things I want to I really want to emphasize, what Lili said. I had a mentor once that said, you know, he was the chair of a very prestigious department and he always would go to these ribbon-cutting ceremonies when we're celebrating the opening of hospitals. And he always said, why are we doing that? Like we should be celebrating the closing of hospitals. Like we really should be advancing care to the point where a lot of these things are preventative. We're taking care of these things outside of the, you know, the four walls of the hospital where errors can occur. There's all kinds of potential risks that go beyond just the conditions you have and obviously the complexity of that. So I do celebrate that. And I think that, you know, some of the steps in terms of how we scale to that, to that point, I mean, one of them is, you know, it's not sexy to talk about, but it's data. And we've done a tremendous job, I think, for the most part, in starting to collect data and digitize data and to be able to manipulate in its individual modalities. But what we haven't done a great job of is really leveraging that data to, to drive insights even with what we have. This is beyond just sort of, you know, new data and new discovery. And I think, you know, in five years, I would be surprised if we don't look back and really facepalm at the idea that we were leaving all this data on the table sort in archives and then only using it in episodic, you know, taking care of a patient and, and not using for insights such as real world evidence. How can I find similar patients, from practice-based evidence. Right. And leveraging that decision-making from, from real-world data. I think that is, something that, you know, we're really close to at least at least seeing the possibility or pathway towards when it comes to some of the, I think the, the connection between the biological space and I think is Lili said, you know, the wearable space. I think there's some connections there that, you know, I would hazard to guess are really going to start to come into fruition. I'm thinking specifically about, you know, less invasive monitoring over time. But then also tying that to, you know, biomarkers that may predict early development of cancer and other chronic diseases. And then to Carlo's point, hey, I\u2019d be been great with partnering up with you, in the reading room. We both love dark rooms and, you know, we can work together to take care of patients in our dark rooms. I'm good with that.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Bifulco<\/strong>: I'm looking forward.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Poon<\/strong>: Well, that that's incredible. One thing that, Matt, you mentioned about that data, right? Like, I kind of learned from John Halamka from Mayo. He mentioned that actually, by some estimates, even today, 3 billion people in the globe already have many of their medical records digitized. But when you think about it what are we using those data? Right now it's mostly like some immediate diagnosis, some billing. Right. Then they\u2019re locked in the attics gathering dust. So to your point, like, like actually that's a super exciting opportunity from all of you that is like, you know, genAI could potentially be able to understand the language of those data, multi-model longitudinal data. And then harnessing them to really for good use. So this is amazing and really thankful for all the panelists. Today I think we heard from like all the way from, you know, biomolecules and proteins and all the way to continuous sensing to, you know, patients and also from research and productization. So I personally learned quite a bit and, and I, I feel even more energized. So thank you very much. Thanks to everyone for listening.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So thank you.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Lungren<\/strong>: Thank you.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Qiu<\/strong>: Thank you.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Amini<\/strong>: Thank you.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>Bifulco<\/strong>: Thank you.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How is AI catalyzing a shift towards precision health care, and what are the key challenges and opportunities in this transformation?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20is%20AI%20catalyzing%20a%20shift%20towards%20precision%20health%20care,%20and%20what%20are%20the%20key%20challenges%20and%20opportunities%20in%20this%20transformation?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"AI for Precision Health: Learning the language of nature and patients","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"ai-for-precision-health-learning-the-language-of-nature-and-patients-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-23 11:01:22","post_modified_gmt":"2025-06-23 18:01:22","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/ai-for-precision-health-learning-the-language-of-nature-and-patients-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"},{"term_id":13553,"slug":"medical-health-genomics","name":"Medical, health and genomics","parent":0,"term_taxonomy_id":13553,"term_order":0,"facet":"{\"term_id\":13553,\"slug\":\"medical-health-genomics\",\"name\":\"Medical, health and genomics\",\"parent\":0,\"term_taxonomy_id\":13553,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":264136,"slug":"panel","name":"Panel","parent":0,"term_taxonomy_id":264181,"term_order":0,"facet":"{\"term_id\":264136,\"slug\":\"panel\",\"name\":\"Panel\",\"parent\":0,\"term_taxonomy_id\":264181,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269930,"slug":"ensuring-societal-benefit","name":"Ensuring Societal Benefit","parent":0,"term_taxonomy_id":269975,"term_order":0,"facet":"{\"term_id\":269930,\"slug\":\"ensuring-societal-benefit\",\"name\":\"Ensuring Societal Benefit\",\"parent\":0,\"term_taxonomy_id\":269975,\"term_order\":0}"},{"term_id":269931,"slug":"extending-human-capabilities","name":"Extending Human Capabilities","parent":0,"term_taxonomy_id":269976,"term_order":0,"facet":"{\"term_id\":269931,\"slug\":\"extending-human-capabilities\",\"name\":\"Extending Human Capabilities\",\"parent\":0,\"term_taxonomy_id\":269976,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/5K0YemTKu-w-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t44:59\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/5K0YemTKu-w-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/ai-for-precision-health-learning-the-language-of-nature-and-patients-microsoft-research-forum\/\" data-bi-cN=\"AI for Precision Health: Learning the language of nature and patients\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled AI for Precision Health: Learning the language of nature and patients\" icon_class=\"c-heading__icon\"><span>AI for Precision Health: Learning the language of nature and patients<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/hoifung\/\">Hoifung Poon<\/a>, <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/avasoleimany\/\">Ava Amini<\/a>, <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/liliqiu\/\">Lili Qiu<\/a>, <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/mlungren\/\">Matthew Lungren<\/a>, <a href=\"https:\/\/www.linkedin.com\/in\/carlo-bifulco-8b123124\/\">Carlo Bifulco<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1131591,"post_author":38004,"post_date":"2025-02-25 12:15:59","post_date_gmt":"2025-02-25 20:15:59","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/hoifung\/\">Hoifung Poon<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 5<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Hoifung Poon, General Manager of Microsoft Health Futures, introduces an agenda in precision health, utilizing generative AI to pretrain high-fidelity patient embeddings from multimodal, longitudinal patient journeys. This approach unlocks population-scale real-world evidence, optimizing clinical care and accelerating biomedical discovery.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/articles\/multimodal-generative-ai-the-next-frontier-in-precision-health\/\">Multimodal Generative AI: the Next Frontier in Precision Health<\/a><br>Article | February 2025<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.nature.com\/articles\/s41586-024-07441-w\" target=\"_blank\" rel=\"noreferrer noopener\">A whole-slide foundation model for digital pathology from real-world data<\/a><br>Article | May 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/www.nature.com\/articles\/s41592-024-02499-w\" target=\"_blank\" rel=\"noreferrer noopener\">A foundation model for joint segmentation, detection and recognition of biomedical objects across nine modalities<\/a><br>Article | November 2024<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Keynote: Multimodal generative AI for precision health<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>WILL GUYMAN, Group Product Manager, Healthcare AI Models<\/strong>: It is my pleasure to introduce my colleague Hoifung Poon, an expert in healthcare AI and general manager of Microsoft Health Futures, to talk about utilizing generative AI to enable precision healthcare. In addition to advancing the frontier of medical AI, Hoifung and Microsoft Research have deeply invested in bridging the gap between research and our clinical partners across the ecosystem. I always leave inspired after hearing Hoifung talk, and I'm sure you'll feel the same. Over to you, Hoifung.&nbsp;<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p><strong>HOIFUNG POON<\/strong>: Hi, everyone. My name is Hoifung Poon. I am general manager at Microsoft Health Futures. I lead Biomedical AI Research and Incubation for precision health, with a particular focus on advancing multimodal gen-AI [generative AI], to unlock the population-scale real-world evidence. So, in the ideal world, we want every patient to be able to respond to the treatment they have been prescribed, as signified by the blue person here on the graph on the left.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In the real world, unfortunately, many patients do not respond to the treatment, as signified by the red person here. So this is obviously the fundamental challenge in biomedicine, and cancer is really the poster child of this problem. For example, immunotherapy is the cutting edge of cancer treatment. And, indeed, blockbuster drugs such as Keytruda can work miracles on some of the late-stage cancer patients.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, the overall response rates still hover around 20 to 30%. Now when the standard of care fails, which is often the case for cancer, clinical trials become the last hope. Here's Martin Tenenbaum, a successful AI researcher and e-commerce entrepreneur. At the peak of his career, Marty was diagnosed with late-stage melanoma. But fortunately for Marty, he was able to mobilize his network to find a matching trial that cured his cancer.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, most patients are not as lucky or resourceful as Marty. Even in the US, only a small portion of patients were able to find matching trials, whereas a lot of cancer trials fail simply because they couldn't find enough patients. Developing a new drug is notoriously hard, taking billions of dollars and over a decade. And this will become increasingly unsustainable in precision health as we actually have to develop more drugs, each applicable to smaller subpopulations.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>When we think about drug development, oftentimes the first thing that comes to mind is early discovery. Now, this is indeed super exciting and foundational, but in the grand scheme of things it's only 10 to 20% of the total costs. Most of the astronomical costs in drug development actually stem from later stages of clinical trials and post-market. Interestingly, this also happens to be the most low-hanging area, with immediate opportunity for major disruptions.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>For example, a single phase-three cancer trial can cost hundreds of millions of dollars, and we only get back a few thousand data points. And the whole process is so inefficient. But there is a lot of potential in actually changing this by harnessing AI to unlock population-scale real evidence. In the past couple of decades, there has been rapid digitization of patient records.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>And every day there are literally billions and billions of data points collected in routine clinical care about a patient journey from diagnosis to treatment to outcome. At the beginning of a patient journey, even the best doctor doesn't have a perfect crystal ball on what might happen next. So, each journey is essentially a mini-trial, and each encounter brings forth new information.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>If we can crack the code and unlock the insight underneath, this is essentially a population-scale free lunch. So, for example, here is the de-identify journey of a cancer patient, where each bar is clinical notes. So, you can see there are many, many note types, and also each note contains a lot of detailed information about the patient journey.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Additionally, there are a lot of information-rich modalities, from medical imaging to multi-omics. So, each of these modalities is trying to tell us something about the patient, but each is inherently limited. Only by assimilating all these kinds of modalities can we recapitulate a holistic kind of patient representation. So, from a machine learning point of view, precision health amounts to learning a function that inputs a multimodal patient journey and then outputs key medical events, such as disease progression and counterfactual tumor response.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>If we can predict them well, we have essentially solved precision health. Now, of course, as you can guess, this is not so easy, right? So, a patient journey is not just a snapshot, but actually a longitudinal time series. More annoyingly, most of the information that we want to have is actually missing, and even the observable information can be very noisy and also contain a lot of biases.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>But this is exactly why gen-AI can be so promising for precision health. The underpinning of gen-AI is a generative model, overall the joint distribution of all those chemical variables. So this enables us to compress all the observable information into a patient embedding, which can then help predict the missing information. And then predicting the next medical event is essentially a special case.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, our overarching agenda essentially lies in how can we harness those population-scale, real-world data to portray a high-fidelity patient embedding that can serve as a digital twin for the patient. And, given the patient embedding, we can then conduct patient reasoning at the population scale. For example, after the cancer diagnosis, instead of spending months and tons of resources to seek a second opinion, we can essentially snap a finger to get millions of opinions from the most similar patients.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We can interrogate the patient journey, such as a treatment pathway and longitudinal outcome. And this can immediately help improve patient care. We can also compare non-responder versus exceptional responder and start probing mysteries, such as why those 80% of patients do not respond to Keytruda. And in this way we can essentially unlock all those emerging capabilities from the population-scale real-world evidence that actually allow us to shatter the glass ceiling of today's healthcare common sense.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So this is very, very exciting, but the forward path is incredibly challenging. Even the best frontier models have a major competency gap for an ever-growing, long list of non-text modalities in biomedicine. So, over the past decade or so, we have blazed a new trail by essentially conducting curriculum learning over three giant free lunches.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The first free lunch stems from unimodal data, such as nanotech images. So, here a general recipe for self-supervision lies in pre-training modality-specific encoders and decoders. And then that can compress the input into an embedding, and then decompress it back to reproduce the original input. So for text, we can also simply piggyback on existing frontier models that are already very, very good at understanding and reasoning with biomedical texts.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now, this general recipe is universally applicable and very powerful biomedicine, and there are also a whole slew of, kind of like, modality-specific challenges that require major research innovations. For example, digital pathology is well known to contain a lot of key information about tumor microenvironments, such as how immune cells interact with cancer cells, which is crucial for deciphering resistance to, immunotherapy.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So here, transformer is the workhorse of the gen-AI and in theory is actually perfect for modeling such a complex global presence. However, pathology slides are actually among the largest in the world. A single whole-slide image can be hundreds of thousands of times larger than standard web images, which means that it will require billions of times more computation due to the quadratic growth in transformer. So, to address this problem, a promising direction is to incorporate this idea called dilated attention, which originated from speech recognition that also has a big problem in modeling long contexts. So, for images, transformer essentially works by having pixels passing messages with each other, which is why it leads to the quadratic growth in compute.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So in dilated attention, for smaller blocks and in local neighborhoods, we will still keep using the full self-attention with the pairwise message passing. But when we pass messages in larger blocks, we will instead try to essentially elect representatives for the local neighborhoods and then only pass messages among those two representatives. So for larger and larger blocks, we will elect sparser and sparser representatives. And in this way, we can perfectly cancel out the quadratic growth.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, by adapting dilated attention to digital pathology and in collaboration with Providence Health System and University of Washington, we have created <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/articles\/gigapath-foundation-model-for-digital-pathology\/\">GigaPath<\/a>, the world's first digital pathology foundation model that can truly scale transformer to the whole-size image. And this paper was published by Nature last year, and we are very excited to see that in the few months since its publication, GigaPath has already been downloaded well over half a million times across the globe.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We are super psyched to see the community's interest. And we have also made a ton of progress in other modalities, such as CT and spatial multi-omics. So, the unimodal pre-training is a very good first step, but there are even bigger challenges. So, for example, a pathology foundation model may learn to map a tumor lesion somewhere in the embedding space, whereas a CT foundation model may map it elsewhere.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Each modality is trying to tell us something about a patient, but each is speaking its own distinct language. So, this is essentially analogous to the translation problem for human languages. And in the translation space, right, to deal with the multilingual explosion, machine translation systems will usually introduce a resource-rich language, such as English, as an interlingua to bridge among those low-resource languages.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>For example, there may not be any parallel data between a language in Africa and a sub-language in India, but we can translate from the African language to English and then from English to the sub-language in India. And this is, indeed, how commercial machine translation systems scale to hundreds of languages in the world. So, here we propose to follow the same recipe in dealing with the multimodal complexity in biomedicine by introducing interlingual modality, and text is an ideal candidate to serve as this interlingua.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We already have very powerful frontier models for the biomedical text modality and, moreover, for any non-text modality under the sun. The study of the modality involves natural languages, which means that there are a lot of readily available modality text pairs such as a pathology slide and the corresponding pathology report. We can piggyback on the unimodal pre-training in the first stage by reusing those encoders and decoders, and then focus on using the modality text pairs to pre-train a lightweight adapter layer. And the adapter layer essentially translates from the modality embedding to the text-semantic space. So, this enables all the modalities to start to speak in the same language, and also helps propagate a lot of the rich prior knowledge that has already been captured in the text-semantic space back to individual modalities to help with their interpretation.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, for more detail about this general recipe, you can check out our <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/llava-med-training-a-large-language-and-vision-assistant-for-biomedicine-in-one-day\/\">LLaVA-Med<\/a> paper, which was spotlighted in NeurIPS. So, here I also want to add that the LLaVA paradigm also represents a trailblazing innovation at MSR [Microsoft Research] by harnessing the text-processing capability of frontier models to synthesize multimodal instruction following data. So, this has since become a standard practice, including training multimodal Phi and other popular vision-language models.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now, we can extend this recipe to include a pixel-level decoder for holistic image analysis. So, this enables us to develop <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/blog\/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis\/\">BiomedParse<\/a>, which can conduct object recognition, detection, and segmentation in one fell swoop through a unified natural-language interface. So, you can essentially talk to the image to conduct an analysis. So, BiomedParse is a single foundation model that can attain state-of-the-art performance across nine modalities and six major object types.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>It was just published by Nature Methods and, in the same issue, Nature Methods also published an external review that <a href=\"https:\/\/www.nature.com\/articles\/s41592-024-02519-9\" target=\"_blank\" rel=\"noreferrer noopener\">called BiomedParse a groundbreaking biomed AI foundation model<\/a> and said that the implications of BiomedParse are profound. So these are all very, very exciting, but we still have one last giant free lunch that lies in the very patient journeys themselves.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So, recall that GPT essentially learns by predicting next token, next token, next token. Right? And in the same way, our patient embedding can actually learn by predicting the next medical event and next medical event. So, in this way, we can essentially turn every single patient journey into a self-supervision training instance. So we have conducted some initial explorations on the structure of medical events using a public data set.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Interestingly, scaling laws established for text actually are not very far away from the structure of medical events. And we are now extending the study to much larger datasets. So, ultimately, we can imagine the embedding not just for patients, but also for interventions, for clinical trials, etc. And in this way, we can potentially develop a universal embedding calculus for precision health.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>As we mentioned earlier, clinical trial is the perfect beachhead. Providence is the third-largest health system in the US, and they have been using our research system daily now in their tumor board to screen thousands of patients a year, including this high-profile trial featured by The New York Times. Using Microsoft AI, Providence researchers were able to find actionable biomarkers for a majority of patients and, consequently, many patients were prescribed with precision therapy, which substantially increased overall survival.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So this is super, super exciting. So, ultimately, the dream is to drastically scale high-quality health care and drastically reduce healthcare costs. And, thereby, we can democratize such high-quality health care to, essentially, really for everyone. So, with the clinical trial matching capability, we can also essentially snap a finger and control our virtual case arm and control arm, and then conduct clinical research, hypothesis generation, and test using real-world, data.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>A lot of those marquee lung cancer trials that can cost hundreds of millions of dollars to run can be simulated using real-world data as we have been shown with Providence collaborators, including the original key to the trial.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now, obviously, with exciting moonshots such as precision health, it takes way more than a village. At Microsoft Research, we are super blessed by being able to collaborate in depth with talented researchers across Microsoft Research itself as well as with academia and with a lot of key health stakeholders, such as large health systems and life-sciences companies. Many of the frontier biomedical models we have highlighted in this talk are already publicly available in <a href=\"https:\/\/ai.azure.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Azure AI Foundry<\/a>.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Now, obviously, much more remains to be done. But even with what we have today, there is already a lot that we can bring forth in positive disruption to scale drug development and improve patient care. <\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Thank you.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How does the integration of patient data using generative AI transform the future of cancer treatment?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20does%20the%20integration%20of%20patient%20data%20using%20generative%20AI%20transform%20the%20future%20of%20cancer%20treatment?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Keynote: Multimodal Generative AI for Precision Health","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"keynote-multimodal-generative-ai-for-precision-health-microsoft-research-forum","to_ping":"","pinged":"","post_modified":"2025-06-23 10:57:31","post_modified_gmt":"2025-06-23 17:57:31","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/keynote-multimodal-generative-ai-for-precision-health-microsoft-research-forum\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"},{"term_id":13553,"slug":"medical-health-genomics","name":"Medical, health and genomics","parent":0,"term_taxonomy_id":13553,"term_order":0,"facet":"{\"term_id\":13553,\"slug\":\"medical-health-genomics\",\"name\":\"Medical, health and genomics\",\"parent\":0,\"term_taxonomy_id\":13553,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-post-option":[{"term_id":269148,"slug":"approved-for-river","name":"Approved for River","parent":0,"term_taxonomy_id":269193,"term_order":0,"facet":"{\"term_id\":269148,\"slug\":\"approved-for-river\",\"name\":\"Approved for River\",\"parent\":0,\"term_taxonomy_id\":269193,\"term_order\":0}"},{"term_id":269142,"slug":"include-in-river","name":"Include in River","parent":0,"term_taxonomy_id":269187,"term_order":0,"facet":"{\"term_id\":269142,\"slug\":\"include-in-river\",\"name\":\"Include in River\",\"parent\":0,\"term_taxonomy_id\":269187,\"term_order\":0}"}],"msr-session-type":[{"term_id":256156,"slug":"keynote","name":"Keynote","parent":0,"term_taxonomy_id":256183,"term_order":0,"facet":"{\"term_id\":256156,\"slug\":\"keynote\",\"name\":\"Keynote\",\"parent\":0,\"term_taxonomy_id\":256183,\"term_order\":0}"}],"msr-episode":[{"term_id":269928,"slug":"s1-ep5","name":"Season 1, Episode 5","parent":0,"term_taxonomy_id":269973,"term_order":0,"facet":"{\"term_id\":269928,\"slug\":\"s1-ep5\",\"name\":\"Season 1, Episode 5\",\"parent\":0,\"term_taxonomy_id\":269973,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269930,"slug":"ensuring-societal-benefit","name":"Ensuring Societal Benefit","parent":0,"term_taxonomy_id":269975,"term_order":0,"facet":"{\"term_id\":269930,\"slug\":\"ensuring-societal-benefit\",\"name\":\"Ensuring Societal Benefit\",\"parent\":0,\"term_taxonomy_id\":269975,\"term_order\":0}"},{"term_id":269931,"slug":"extending-human-capabilities","name":"Extending Human Capabilities","parent":0,"term_taxonomy_id":269976,"term_order":0,"facet":"{\"term_id\":269931,\"slug\":\"extending-human-capabilities\",\"name\":\"Extending Human Capabilities\",\"parent\":0,\"term_taxonomy_id\":269976,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/T4Xu7WMYUcc-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t17:14\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2025\/02\/T4Xu7WMYUcc-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/keynote-multimodal-generative-ai-for-precision-health-microsoft-research-forum\/\" data-bi-cN=\"Keynote: Multimodal Generative AI for Precision Health\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Keynote: Multimodal Generative AI for Precision Health\" icon_class=\"c-heading__icon\"><span>Keynote: Multimodal Generative AI for Precision Health<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tFebruary 25, 2025\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/hoifung\/\">Hoifung Poon<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 5\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1080732,"post_author":42735,"post_date":"2024-09-03 10:50:00","post_date_gmt":"2024-09-03 17:50:00","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/mivorvor\/\">Mihaela Vorvoreanu<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 4<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Mihaela Vorvoreanu, Director UX Research and Responsible AI Education, Microsoft Aether, discusses reliance on AI. Because of their probabilistic nature, all AI systems will make mistakes. One of the main challenges in human-AI interaction is to foster appropriate reliance on AI, and empower users of AI systems to determine when to accept or not accept an AI system's recommendation. Hear about the work being done at Microsoft to foster appropriate reliance and help people accept AI outputs when they are correct, and reject them when they are wrong.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Fostering appropriate reliance on AI<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p><strong>MIHAELA VORVOREANU:<\/strong> Hi, everyone. My name is Mihaela, or Mickey, Vorvoreano. I lead UX Research and Responsible AI Education in Aether, Microsoft's research and advisory body on AI ethics and effects in engineering and research. And in a previous life, I was a professor of UX design and research.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>During the past few months, I've had the privilege of leading a cross-company team of researchers and product builders focused on fostering appropriate reliance on AI, specifically generative AI and our <a href=\"https:\/\/www.microsoft.com\/en-us\/ai\/principles-and-approach\" target=\"_blank\" rel=\"noreferrer noopener\">Copilot<\/a> product. In this working group, we think of fostering appropriate reliance on AI as striking a balance between people not overrelying too much on AI and accepting its outputs when they are incorrect or incomplete, and not under-relying and not using or trusting AI outputs even when they could be useful. And so across all of us, we have started looking into how we can foster research that leads to improvement in our own products.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>My team started looking into the problem of overreliance on AI quite a while back. About two years ago, we released this first <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/overreliance-on-ai-literature-review\/\">review of research literature<\/a> about overreliance on AI. In that paper, we isolated antecedents, mechanisms, and consequences of overreliance on AI and the series of mitigations that showed promise in the research literature. However, as we know, many such mitigations can backfire, actually increasing overreliance rather than mitigating it.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>More recently, we released a second <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/appropriate-reliance-on-generative-ai-research-synthesis\/\">synthesis of research literature<\/a>. This one focused specifically on generative AI. We find that generative AI makes this tricky problem of overreliance even more difficult for several reasons, one of them being that it is so much more difficult to spot incorrect or incomplete AI outputs, especially when they are formulated so fluently and with such impressive grammar. In this paper, we also looked at some overreliance mitigations. Some of them have been mentioned in the literature before, such as cognitive forcing functions, and others [are] quite new that involved using generative AI to critique existing answers or to stimulate critical thinking in generative AI users.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>As <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/horvitz\">Eric Horvitz<\/a> and <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/asellen\/\">Abby Sellen<\/a> point out in the recent <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/the-rise-of-the-ai-co-pilot-lessons-for-design-from-aviation-and-beyond\">opinion piece<\/a> [that] using generative AI places a high cognitive burden on regular people during everyday life. Such levels of attention and vigilance were only previously expected of highly trained professionals, such as airline pilots. And so in our group, we wonder how might we make use of generative AI products a little bit easier so people can maximize the benefits [and] minimize the risks while not spending as much mental energy as an airplane pilot would.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In our internal research\u2014and here I want to acknowledge my wonderful team members who have done all of this research\u2014we have identified three possible directions. Each one of these is a problem\/an opportunity. The first one is that most people, even advanced users of generative AI, don't have useful mental models of how these technologies work. They mostly think of them as traditional web search, and that doesn't always come in handy. This points to the opportunity of helping people form useful mental models through AI literacy. We can create AI literacy, not only through formal or informal education, but also through responsible communication in journalism and in marketing, and also during interaction with a product.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We could do a better job of teaching people about generative AI while they interact with generative AI products. Here, the <a href=\"https:\/\/www.microsoft.com\/en-us\/haxtoolkit\/ai-guidelines\/\" target=\"_blank\" rel=\"noreferrer noopener\">guidelines<\/a> for human AI interaction from the <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/project\/hax-toolkit\/\">HAX Toolkit<\/a>\u2014particularly guidelines 1, 2, and 11\u2014which really emphasize how important it is to make clear to users the system\u2019s not only capabilities, but also limitations, and [it] provide some explanations of how it works so that they can form mental models. This is where these guidelines can really come into play.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>I also invite you to keep an eye out on the HAX Toolkit because we have been adding new examples and content related to appropriate reliance specifically. This is one idea of how we could intervene at the user interaction layer to actually foster AI literacy and more useful mental models.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The second direction and the second research finding is that overall, people are not inclined to verify AI outputs. Also, if you think about one of the most popular strategies that's used in most products to date, is what I like to call the warning sticker strategy, where we might show something like, \u201cAI-generated content might be incorrect.\u201d This is partially useful. People seem to have learned that.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>However, this type of notice doesn't mention that AI-generated content might also be incomplete. And so people might miss out altogether on the fact that important or useful information is not in the answer in the first place. That also raises the opportunity of how might we get people's attention, arouse that attention and vigilance just a little bit, so they know when it is time to check answers versus not in more important or high-risk situations.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In the research that we highlight on the working team\u2019s <a href=\"http:\/\/aka.ms\/appropriate-reliance\" target=\"_blank\" rel=\"noreferrer noopener\">webpage<\/a>, we show some papers that talk about communicating uncertainty verbally, via text output, or via highlights that might help users spot when it might be time to increase their alertness level and verify outputs more carefully.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Finally, the third direction is that the user experience of verifying generative AI outputs is rather difficult for many people. The primary UI paradigm that we use for this is to cite sources like we do in a research or a school paper. Now, this format in itself suggests a level of rigor and trustworthiness that AI-generated outputs might not be equal with research papers. Because of this signal, people might not be inclined to verify because what's really more trustworthy than a research or a school paper.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>This raises the opportunity of how might we make the relationship between AI-generated outputs and the information that they work with\u2014their grounding data\u2014more transparent. How might we make it easier to verify, to spot discrepancies, to spot incompleteness? But also looking even further into how we might use LLMs to propose critiques of their own responses, or as we see in some research that we highlight on the webpage, to actually not just give people a response, but stimulate people to engage in critical thinking, which could be a very different paradigm of interacting with generative AI and large language models in particular.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Throughout all this, what I would really like to highlight, and I do this with my co-authors in this <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3665504\" target=\"_blank\" rel=\"noreferrer noopener\">piece<\/a> that appeared as an opening article in ACM interactions not very long ago, is really that this is a moment for UX disciplines to shine. As you can see, a lot of these mitigations, a lot of these techniques for fostering appropriate reliance, are UX interventions.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p>This is where I think it is our responsibility as people working in UX disciplines\u2014as people researching UX and human computer interaction\u2014to really, really step up to the front and see how it is our moment to shine and to address this problem. That being said, I hope you stay in touch. I hope you follow our research, which we publish on the team's <a href=\"http:\/\/aka.ms\/appropriate-reliance\" target=\"_blank\" rel=\"noreferrer noopener\">webpage<\/a>, and I hope you help us follow your research. So maybe together, we can work towards making progress on this very tricky but important problem. With that, I want to thank you so much for following this presentation. I look forward to working with you.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"What approaches are being developed to foster appropriate reliance on AI, ensuring users can discern when to accept or reject AI recommendations?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=What%20approaches%20are%20being%20developed%20to%20foster%20appropriate%20reliance%20on%20AI%2C%20ensuring%20users%20can%20discern%20when%20to%20accept%20or%20reject%20AI%20recommendations?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Fostering appropriate reliance on AI","post_excerpt":"Mihaela Vorvoreanu, Director UX Research and Responsible AI Education, Microsoft Aether, discusses reliance on AI. Because of their probabilistic nature, all AI systems will make mistakes. One of the main challenges in human-AI interaction is to foster appropriate reliance on AI, and empower users of AI systems to determine when to accept or not accept an AI system's recommendation. Hear about the work being done at Microsoft to foster appropriate reliance and help people accept AI outputs when they are correct, and reject them when they are wrong.","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"fostering-appropriate-reliance-on-ai","to_ping":"","pinged":"","post_modified":"2025-05-27 13:10:16","post_modified_gmt":"2025-05-27 20:10:16","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/fostering-appropriate-reliance-on-ai\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"},{"term_id":13554,"slug":"human-computer-interaction","name":"Human-computer interaction","parent":0,"term_taxonomy_id":13554,"term_order":0,"facet":"{\"term_id\":13554,\"slug\":\"human-computer-interaction\",\"name\":\"Human-computer interaction\",\"parent\":0,\"term_taxonomy_id\":13554,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269927,"slug":"s1-ep4","name":"Season 1, Episode 4","parent":0,"term_taxonomy_id":269972,"term_order":0,"facet":"{\"term_id\":269927,\"slug\":\"s1-ep4\",\"name\":\"Season 1, Episode 4\",\"parent\":0,\"term_taxonomy_id\":269972,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269930,"slug":"ensuring-societal-benefit","name":"Ensuring Societal Benefit","parent":0,"term_taxonomy_id":269975,"term_order":0,"facet":"{\"term_id\":269930,\"slug\":\"ensuring-societal-benefit\",\"name\":\"Ensuring Societal Benefit\",\"parent\":0,\"term_taxonomy_id\":269975,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/na4AAsKblsA-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t09:39\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/na4AAsKblsA-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/fostering-appropriate-reliance-on-ai\/\" data-bi-cN=\"Fostering appropriate reliance on AI\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Fostering appropriate reliance on AI\" icon_class=\"c-heading__icon\"><span>Fostering appropriate reliance on AI<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tSeptember 3, 2024\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/mivorvor\/\">Mihaela Vorvoreanu<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 4\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1080717,"post_author":42735,"post_date":"2024-09-03 10:43:00","post_date_gmt":"2024-09-03 17:43:00","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/kevyan\/\">Kevin Yang<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 4<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Kevin Yang, Senior Researcher, Microsoft Research New England, shares how deep learning is enabling us to generate novel and useful biomolecules, allowing researchers and practitioners to better understand biology.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>A generative model of biology for in-silico experimentation and discovery<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p><strong>KEVIN YANG:<\/strong> Hi. I'm Kevin K. Yang, senior researcher at Microsoft Research, and I'll be presenting on generative models of biology for in-silico experimentation and discovery.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>Our mission in the <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/theme\/biomedical-ml\/\">Biomedical ML Group<\/a> at MSR [Microsoft Research] is to develop AI systems that contribute to biomedical knowledge via generative design and interactive discovery across length scales from molecules to patients.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>At the smallest scale, we model biomolecules such as nucleic acids and proteins. These molecules function within cells, which we model specifically in the context of understanding and treating cancer. Cells form tissues. We build generative models of histopathology images in order to improve diagnostics. Finally, we study genetics and biomarkers at the whole patient level to better understand health and disease.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Today, we'll focus on the molecular level with our protein engineering work.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Proteins are the actuators of biology. Each of our cells contains 1 to 3 billion protein molecules at any given time. Proteins catalyze metabolic reactions, replicate DNA, respond to stimuli such as light and scent, provide structure to cells and organisms, and transport molecules within and between cells.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>All of this functional diversity is encoded in just 20 chemical building blocks called amino acids. Proteins are sequences of dozens to thousands of amino acid residues. In nature, these sequences often fold into a three-dimensional structure, which then performs a cellular function.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>A protein's structure and function are completely determined by its amino acid sequence. Protein design seeks to generate the amino acid sequences of new proteins that perform useful and novel functions. For example, engineered proteins in laundry detergent help remove stains while other proteins are of great interest as gene editors.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>My research focuses on training neural networks and the natural diversity of proteins in order to generate new protein sequences that hopefully encode new functions. Today, I'll focus on the model called EvoDiff. This work was done in collaboration with Sarah Alamdari, Nitya Thakkar, Rianne van den Berg, Alex Lu, Nicolo Fusi, and Ava Amini.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>EvoDiff is a discrete diffusion model trained on evolutionary-scale protein sequence data. By evolutionary scale, we mean that we train on sequences taken from across many different organisms and that perform many different functions.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Diffusion models were first popularized for generating images. During training, a diffusion model learns to remove noise added to a data point. In this case, we randomly mask some amino acid residues from a protein and train the model to predict the identities of the masked residues. After training, EvoDiff can generate new protein sequences, beginning with a sequence of all masks by decoding one position at a time.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Here, we show an example and also show the predicted structure of the generated protein after each decoding step. We see that EvoDiff generates plausible and diverse proteins across a variety of lengths. We visualize the predictions using their predicted 3D structures. The structural prediction model also outputs a confidence metric called pLDDT [predicted local distance difference test], which ranges from 0-100. EvoDiff is able to generate sequences that are likely to fold into stable structures by this metric.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>These sequences are also distinct from anything seen in nature.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Often, protein engineers want proteins that perform a similar function to a natural protein, or they want to produce a protein that performs the same function but has other desirable properties, such as stability. By conditioning EvoDiff with a family of related sequences, we can generate new proteins that are very different in sequence space to the natural proteins but are predicted to fold into similar three-dimensional structures. These may be good starting points for finding new functions or for discovering versions of a protein with desirable properties. Finally, EvoDiff can also generate a complete protein sequence conditioned on a desired functional motif.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Biological functions, including binding and catalysis, are often mediated by a small structural motif held in the correct orientation by a scaffold. One way to design new functional proteins is to hand design these functional motifs, and then to generate a scaffold that will position the residues of the motif in the desired orientation. Traditionally, this is done by designing the protein structure and then finding a protein sequence that will fold to the desired structure. Here, we specified a desired functional motif from a natural protein in green, then resampled the rest of the protein around it using EvoDiff.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The new protein sequence is predicted to maintain the functional orientation of the motif with high resolution, demonstrating that we can perform motif scaffolding entirely in sequence space. By training on an evolutionary-scale dataset of 40 million proteins with many different natural functions from many different organisms, EvoDiff is able to generate plausible and diverse sequences. In addition, we have demonstrated the ability to condition on evolutionarily related sequences or undesired function motifs within a sequence.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Looking ahead, our next goal is to train generative models that allow finer grain control of the desired function in the form of text or a chemical reaction. This sort of conditional protein design will expand the scope of applications for designed proteins in chemistry, biology, and medicine. Finally, generative models of proteins can be a building block for models of cells, tissues, and patients, as we seek to design and understand biology.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p>If you enjoyed this talk, please go read our preprint, or you can <a href=\"https:\/\/github.com\/microsoft\/evodiff\" target=\"_blank\" rel=\"noreferrer noopener\">use the code in our GitHub<\/a> to generate your own proteins. Thank you.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"What are the capabilities of generative models in biology, and how are they enabling in-silico experimentation and discovery?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=What%20are%20the%20capabilities%20of%20generative%20models%20in%20biology%2C%20and%20how%20are%20they%20enabling%20in-silico%20experimentation%20and%20discovery?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"A generative model of biology for in-silico experimentation and discovery","post_excerpt":"Kevin Yang, Senior Researcher, Microsoft Research New England, shares how deep learning is enabling us to generate novel and useful biomolecules, allowing researchers and practitioners to better understand biology.","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"a-generative-model-of-biology-for-in-silico-experimentation-and-discovery","to_ping":"","pinged":"","post_modified":"2025-05-27 13:10:07","post_modified_gmt":"2025-05-27 20:10:07","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/a-generative-model-of-biology-for-in-silico-experimentation-and-discovery\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269927,"slug":"s1-ep4","name":"Season 1, Episode 4","parent":0,"term_taxonomy_id":269972,"term_order":0,"facet":"{\"term_id\":269927,\"slug\":\"s1-ep4\",\"name\":\"Season 1, Episode 4\",\"parent\":0,\"term_taxonomy_id\":269972,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269932,"slug":"transforming-scientific-discovery","name":"Transforming Scientific Discovery\u200b","parent":0,"term_taxonomy_id":269977,"term_order":0,"facet":"{\"term_id\":269932,\"slug\":\"transforming-scientific-discovery\",\"name\":\"Transforming Scientific Discovery\\u200b\",\"parent\":0,\"term_taxonomy_id\":269977,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/Jk4iEisnKRo-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"a man standing in front of a door\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t06:16\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/Jk4iEisnKRo-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/a-generative-model-of-biology-for-in-silico-experimentation-and-discovery\/\" data-bi-cN=\"A generative model of biology for in-silico experimentation and discovery\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled A generative model of biology for in-silico experimentation and discovery\" icon_class=\"c-heading__icon\"><span>A generative model of biology for in-silico experimentation and discovery<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tSeptember 3, 2024\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/kevyan\/\">Kevin Kaichuang Yang<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 4\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1080684,"post_author":42735,"post_date":"2024-09-03 10:30:00","post_date_gmt":"2024-09-03 17:30:00","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/corbyrosset\/\">Corby Rosset<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 4<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Corby Rosset, Senior Researcher, Microsoft Research AI Frontiers, discusses teaching language models to self-improve using a preference oracle like GPT-4, framing it as a two-player game to find an optimal policy at a Nash equilibrium, and achieving state-of-the-art win rates against GPT-4 Turbo on benchmarks such as Alpaca-Eval and MT-Bench.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Direct Nash Optimization: Teaching language models to self-improve with general preferences<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p><strong>CORBY ROSSET:<\/strong> Hi, I'm Corby. I'm a scientist in Microsoft Research. Today, we're going to be talking about Direct Nash Optimization, which is a technique to help language models self-improve.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>We all know that there are two main ways to improve language models. One is to scale up the number of parameters or to scale up the amount of training data. Both of these approaches are costly even for the post-training techniques. The traditional way to fine-tune an LLM for post-training is using SFT. SFT basically tells the model to emulate good behaviors, but it does not target or correct any mistakes or bad behaviors that it makes explicitly. More advanced post-training techniques such as RLHF use a fixed reward model, which can be easily hacked or go stale during training and involves much more complex reinforcement learning, which can be unstable. Self-improving post-training explicitly identifies and tries to correct bad behaviors or mistakes that the model makes.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Before we move on, we want to give a concrete example of what we mean by self-improving behavior. Here's a simple geometry problem where a base model that was already SFTed makes a simple arithmetic error on the left-hand side. After our self-improving technique, the model is able to correct this mistake.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Here we give a simple overview of how Direct Nash Optimization works. One of the properties of generative LLMs is that you can sample multiple outputs from them. This is advantageous because what we can do is, given an input, we can take our language model and sample, in this case, two outputs\u2014answer A and answer B\u2014and we can have them scored or rated by a preference function oracle, which tells us which response is better. Then we can use a contrastive training mechanism, such as DPO or IPO or others to update the parameters of the language model to hopefully improve it. In the next iteration, timestep t+1, we repeat the process over again. The key insight of this technique is how we define reward. Typically, in the RLHF framework, we want to maximize the reward of a language model policy against some given external reward model. Here, we redefine \u201creward\u201d as the expected win rate against your own behavior as judged by a preference function P. What this means is that for a given response <em>y<\/em> to an input <em>x<\/em>, the reward of that response is defined as the expected win rate against <em>y<\/em> primes sampled from the policy itself. Hence, rewards are maximized by responses that are preferred over other responses.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>When you start comparing the <em>y<\/em> primes, or the model's own outputs to each other, this incentivizes a self-improving behavior because you're basically competing against yourself. You can formulate this in a game theoretic manner where, in this game, you have a single player which is competing against itself, and the payoffs are given by the preference function. In this game, a Nash equilibrium is achieved by the best possible \u03c0* whose responses are preferred over any other competing policy in its class.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>At a high level, Direct Nash Optimization has many advantages. Firstly, it optimizes towards a more general preference function directly rather than a point-wise reward model, which is limited in its expressibility since it can't model transitive preferences. Secondly, it is an iterative algorithm, meaning it is much simpler to implement. We use a contrastive update as the loss, which does not involve any policy gradients or heavy reinforcement learning machinery. We also sample on policy outputs from the model and compare them to each other in a self-play framework. We use a powerful preference annotator\u2014in this case, GPT-4\u2014to rank or judge the best response among them. This approach is also flexible since we can compare the responses to each other but also to outputs from a more powerful teacher such as GPT-4, which provides even bigger improvements. Most importantly, this algorithm is theoretically guaranteed to monotonically approach the Nash equilibrium, hence the name Direct Nash Optimization.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>If you implement this algorithm correctly, you will find state-of-the-art results on several benchmarks, including this one, which is AlpacaEval2. This benchmark basically measures how well language models follow instructions and align with human expectations. This benchmark computes a win rate of the language model\u2019s outputs versus a powerful reference\u2014in this case, GPT-4\u2014in a side-by-side comparison. The y-axis is the win rate, and the x-axis is the amount of iterations of training. We see that the dark blue line, which is DNO, the vanilla implementation, outperforms two important baselines. The red line is SFT, and the orange and yellow lines are offline contrastive algorithms, such as DPO and KTO. Hence, we see that self-improving post-training is better than offline contrastive training and SFT. Notably, DNO is also able to outperform similar training techniques from other models, which were 10 times as large, namely the gray line, which was a 70 billion parameter Llama model. We are also encouraged to see that these results do not saturate, and with more training in the purple line over more iterations, we see even better results.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p>We hope this work inspires other researchers to continue to investigate self-improving post-training as an effective method for aligning language models with human expectations. Thank you for watching.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"What is Direct Nash Optimization, and how does it enable language models to self-improve using general preferences?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=What%20is%20Direct%20Nash%20Optimization%2C%20and%20how%20does%20it%20enable%20language%20models%20to%20self-improve%20using%20general%20preferences\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Direct Nash Optimization: Teaching language models to self-improve with general preferences","post_excerpt":"Corby Rosset, Senior Researcher, Microsoft Research AI Frontiers, discusses teaching language models to self-improve using a preference oracle like GPT-4, framing it as a two-player game to find an optimal policy at a Nash equilibrium, and achieving state-of-the-art win rates against GPT-4 Turbo on benchmarks such as Alpaca-Eval and MT-Bench.","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"direct-nash-optimization-teaching-language-models-to-self-improve-with-general-preferences","to_ping":"","pinged":"","post_modified":"2025-05-27 13:09:56","post_modified_gmt":"2025-05-27 20:09:56","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/direct-nash-optimization-teaching-language-models-to-self-improve-with-general-preferences\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269927,"slug":"s1-ep4","name":"Season 1, Episode 4","parent":0,"term_taxonomy_id":269972,"term_order":0,"facet":"{\"term_id\":269927,\"slug\":\"s1-ep4\",\"name\":\"Season 1, Episode 4\",\"parent\":0,\"term_taxonomy_id\":269972,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269929,"slug":"driving-model-innovation","name":"Driving Model Innovation","parent":0,"term_taxonomy_id":269974,"term_order":0,"facet":"{\"term_id\":269929,\"slug\":\"driving-model-innovation\",\"name\":\"Driving Model Innovation\",\"parent\":0,\"term_taxonomy_id\":269974,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/V04Q7YhEUzw-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t06:09\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/V04Q7YhEUzw-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/direct-nash-optimization-teaching-language-models-to-self-improve-with-general-preferences\/\" data-bi-cN=\"Direct Nash Optimization: Teaching language models to self-improve with general preferences\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Direct Nash Optimization: Teaching language models to self-improve with general preferences\" icon_class=\"c-heading__icon\"><span>Direct Nash Optimization: Teaching language models to self-improve with general preferences<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tSeptember 3, 2024\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/corbyrosset\/\">Corby Rosset<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 4\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1080705,"post_author":42735,"post_date":"2024-09-03 10:27:00","post_date_gmt":"2024-09-03 17:27:00","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/meganstanley\/\">Megan Stanley<\/a> at&nbsp;<strong>Microsoft Research Forum, Episode 4<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Megan Stanley, Senior Researcher, Microsoft Research AI for Science, talks about Aurora, a cutting-edge foundation model that offers a new approach to weather forecasting that could transform our ability to predict and mitigate the impacts of extreme events, air pollution, and the changing climate.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:heading {\"className\":\"h5\"} -->\n<h2 class=\"wp-block-heading h5\" id=\"explore-more\">Explore more<\/h2>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><a href=\"https:\/\/ai.azure.com\/labs\/projects\/aurora\" target=\"_blank\" rel=\"noreferrer noopener\">Aurora on Azure AI Foundry<\/a><br>Project page<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Project Aurora: The first large-scale foundation model of the atmosphere<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p><strong>MEGAN STANLEY:<\/strong> Hi. My name is Megan Stanley, and I'm a senior researcher in Microsoft AI for Science, and I'd like to tell you all about Aurora, our foundation model of the atmosphere.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>Now, weather forecasting is critical in our societies. Whether that's for disaster management, planning supply chains and logistics, forecasting crop yields, or even just knowing whether we should take a jacket out when we leave the house in the morning, it has day-to-day significance for all of us and is very important to the functioning of our civilization. In addition, in the face of a changing climate, we need more than ever to predict how the patterns of our weather will change on an everyday basis as the earth system we all inhabit undergoes a shift.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Traditionally, the atmosphere and its interactions with the Earth's surface and oceans, as well as the incoming energy from the sun, are modeled using very large systems of coupled differential equations. In practice, to make a forecast or simulate the atmosphere, these equations are numerically integrated on very large supercomputers. They also have to assimilate observations from the current state of the weather in order to have correct initial conditions. Putting all of this together means that making a single weather forecast is computationally extremely expensive and slow, and the simulation must be rerun for every new forecast. At the same time, the set of equations used cannot completely capture all of the atmospheric dynamics, and this ultimately limits the accuracy that can be obtained.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>With Aurora, we aim to demonstrate state-of-the-art medium-range weather forecasting\u2014that is, for time periods out to a couple of weeks\u2014and to do so with a model that learns a good general representation of the atmosphere that can be tuned to many downstream tasks. It is our bet that, similar to the breakthroughs in natural language processing and image generation, we can make significant advances by training a large deep learning model on the vast quantity of Earth system data available to us.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Aurora represents huge progress. We demonstrate that it can be fine-tuned to state-of-the-art performance on operational weather forecasting, as well as previously unexplored areas in deep learning of atmospheric pollution prediction. It's able to do all of this roughly 5,000 times faster than current traditional weather forecasting techniques. In addition, if we compare to the current state of the art in AI weather forecasting, the GraphCast model, we're able to outperform it on 94 percent of targets, and we do so at a higher spatial resolution in line with the current traditional state of the art.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Aurora achieves this by training on more data and more data that is more diverse, training a larger model at the same time. We also demonstrate that, as a foundation model, it has the possibility of being fine-tuned on a wide range of very important downstream tasks. As a foundation model, Aurora operates using the pretrain\u2013fine-tune paradigm. It's initially trained on a large quantity of traditional weather forecasting and climate simulation data. This pretraining phase is designed to result in a model that should carry within it a useful representation of the general behavior of the atmosphere so that then we can fine-tune it to operate in scenarios where there is much less data or data of less high quality.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>So examples of the scarce data scenario? Well, weather forecasting at the resolution of the current gold standard of traditional methods, that is the IFS system, operating at 0.1 degrees resolution, or approximately 10 kilometers. Another good example is prediction of atmospheric pollution, including gases and particulates, where the current gold standard is an additional, very computationally expensive model applied to the IFS from the Copernicus atmospheric modeling service, or CAMS. This problem is generally very challenging to traditional forecasting systems, but it's of critical importance.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>We're able to show that Aurora outperforms IFS on 92 percent of the operational targets, and it does this particularly well in comparison at forecasting times longer than 12 hours while being approximately 5,000 times faster. When we look at the ability of Aurora to predict weather station observations, including wind speed and temperature, it\u2019s better in general than traditional forecasting systems. It really is able to make accurate predictions of the weather as we experience it on Earth.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>On the atmospheric pollution task, Aurora is able to match or outperform CAMS in 74 percent of cases, and it does so without needing any emissions data as an input. This task has never before been approached with an AI model. If we look at Aurora's ability to predict pollutants such as nitrogen dioxide that are strongly related to emissions for human activity, we can see that the model has learned to make these predictions with no emissions data provided. It's learned the implicit patterns that cause the gas concentrations, which is very impressive. It's also, very impressively, managed to learn atmospheric chemistry behavior. You can see this here, where as the gas is exposed to sunlight, this causes the changes between night and day concentrations of nitrogen dioxide.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Aurora is also capable of forecasting extreme events as well as the state-of-the-art traditional techniques. Here it is seen correctly predicting the path of storm Ciar\u00e1n, which hit Northwestern Europe in early November 2023, causing record-breaking damage and destruction. In particular, Aurora was the only AI model that could correctly predict the maximum wind speed during the storm as it picked up when it made landfall.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>In conclusion, Aurora is a foundation model that really is the state of the art in AI and in general weather forecasting in terms of its ability to produce correct operational forecasts. It does so 5,000 times faster than traditional weather forecasting techniques. Moreover, because it's a foundation model, it unlocks new capabilities. It can be fine-tuned on downstream tasks where there\u2019s scarce data or that haven't been approached before. We believe that Aurora represents an incredibly exciting new paradigm in weather forecasting. This is much like the progress we've seen across the sciences, where the ability to train AI models at massive scale with vast quantities of accurate data, has unlocked completely unforeseen capabilities.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p>If you want to learn more about how my colleagues and I at AI for Science achieve this, please refer to our <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/publication\/aurora-a-foundation-model-of-the-atmosphere\/\">publication<\/a>. Thank you.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How does Project Aurora, the first large-scale foundation model of the atmosphere, aim to transform weather forecasting and climate impact prediction?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20does%20Project%20Aurora%2C%20the%20first%20large-scale%20foundation%20model%20of%20the%20atmosphere%2C%20aim%20to%20transform%20weather%20forecasting%20and%20climate%20impact%20prediction?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Project Aurora: The first large-scale foundation model of the atmosphere","post_excerpt":"Megan Stanley, Senior Researcher, Microsoft Research AI for Science, talks about Aurora, a cutting-edge foundation model that offers a new approach to weather forecasting that could transform our ability to predict and mitigate the impacts of extreme events, air pollution, and the changing climate.","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"project-aurora-the-first-large-scale-foundation-model-of-the-atmosphere","to_ping":"","pinged":"","post_modified":"2025-07-17 07:59:50","post_modified_gmt":"2025-07-17 14:59:50","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/project-aurora-the-first-large-scale-foundation-model-of-the-atmosphere\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"},{"term_id":198583,"slug":"ecology-environment","name":"Ecology and environment","parent":0,"term_taxonomy_id":198583,"term_order":0,"facet":"{\"term_id\":198583,\"slug\":\"ecology-environment\",\"name\":\"Ecology and environment\",\"parent\":0,\"term_taxonomy_id\":198583,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269927,"slug":"s1-ep4","name":"Season 1, Episode 4","parent":0,"term_taxonomy_id":269972,"term_order":0,"facet":"{\"term_id\":269927,\"slug\":\"s1-ep4\",\"name\":\"Season 1, Episode 4\",\"parent\":0,\"term_taxonomy_id\":269972,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269932,"slug":"transforming-scientific-discovery","name":"Transforming Scientific Discovery\u200b","parent":0,"term_taxonomy_id":269977,"term_order":0,"facet":"{\"term_id\":269932,\"slug\":\"transforming-scientific-discovery\",\"name\":\"Transforming Scientific Discovery\\u200b\",\"parent\":0,\"term_taxonomy_id\":269977,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/Zi4u-JWpY5w-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"a woman standing in front of a laptop\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t06:36\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/08\/Zi4u-JWpY5w-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/project-aurora-the-first-large-scale-foundation-model-of-the-atmosphere\/\" data-bi-cN=\"Project Aurora: The first large-scale foundation model of the atmosphere\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Project Aurora: The first large-scale foundation model of the atmosphere\" icon_class=\"c-heading__icon\"><span>Project Aurora: The first large-scale foundation model of the atmosphere<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tSeptember 3, 2024\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/meganstanley\/\">Megan Stanley<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 4\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"},{"data":{"ID":1080693,"post_author":42735,"post_date":"2024-09-03 10:15:00","post_date_gmt":"2024-09-03 17:15:00","post_content":"<!-- wp:paragraph -->\n<p><em>Presented by&nbsp;<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/frparmig\/\">Francesca Parmigiani<\/a> and <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/jiaqchu\/\">Jiaqi Chu<\/a>&nbsp;at&nbsp;<strong>Microsoft Research Forum, Episode 4<\/strong><\/em><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Francesca Parmigiani and Jiaqi Chu, researchers at Microsoft Research Cambridge, discuss a new kind of computer \u2013 an analog optical computer \u2013 that has the potential to accelerate AI inference and hard optimization workloads by 100x, leveraging hardware-software co-design to improve the efficiency and sustainability of real-world applications.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:buttons -->\n<div class=\"wp-block-buttons\"><!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/aka.ms\/researchforum-sessions\">All Research Forum sessions<\/a><\/div>\n<!-- \/wp:button -->\n\n<!-- wp:button {\"className\":\"is-style-cta\"} -->\n<div class=\"wp-block-button is-style-cta\"><a class=\"wp-block-button__link wp-element-button\" href=\"https:\/\/register.researchforum.microsoft.com\/\" target=\"_blank\" rel=\"noreferrer noopener\">Register for the series<\/a><\/div>\n<!-- \/wp:button --><\/div>\n<!-- \/wp:buttons -->\n\n<!-- wp:msr\/show-more -->\n<!-- wp:heading {\"level\":3} -->\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript<\/h3>\n<!-- \/wp:heading -->\n\n<!-- wp:paragraph -->\n<p><strong>Analog optical computing for sustainable AI and beyond<\/strong><\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p><strong>JIAQI CHU<\/strong>: Hi, everyone. I'm Jiaqi, a researcher at Microsoft. Over the past three years, I have been working with a fantastic team to build a new kind of computer. It doesn't use logic case; it doesn't use bits. It uses physics and physical systems to do computation, which means it has a potential to be 100 times more efficient compared to state-of-the-art GPUs. [The] really neat thing is that we are building it using the technologies that are soon prevalent in consumer space.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:msr\/more -->\n<!--msr\/more-->\n<!-- \/wp:msr\/more -->\n\n<!-- wp:paragraph -->\n<p>There is a catch here. This is not a general-purpose computer. It is accelerating two different but very broad classes of applications: machine learning inference and hard optimization problems. For the machine learning inference part, we have been able to show the potential of accelerating diffusion models that can generate images and other content using this computer. Actually, there are emerging forms of machine learning that can really take advantage of the amazing amount of computing offered and achieve high-level properties, like better [generalization] to out-of-distribution data. Second, the same computer can solve hard or combinatorial optimization problems. We have identified real-world problems from many industry verticals, from healthcare, finance, chemical engineering, to robotics, that could be accelerated using this computer. Exactly the same computer supporting a wide range of applications.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>But before we talk about these applications and the computer, I want to go after the \u201cwhy\u201d question. I'm sure all of you have had firsthand experience of the amazing capabilities of the latest machine learning models. We are just at the start of this inflection [point]. We expect that the capabilities of those models will grow tremendously, as long as we can keep pouring exponentially increasing amount of [compute]. But this is a big problem, not just because we are spending billions and billions of dollars on AI infrastructure to train and service models, there are also serious environmental concerns about the energy and other resources that are being consumed here. I genuinely believe sustainability of AI is one of the most important questions. Unfortunately, this couldn't be happening at a worse time. Right when these computer demands are taking off, the future trends for digital computing do not look good, with Moore\u2019s law slowing down. This is not just our observation; it is a broader industry concern.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Over the past five\/six years, this has led to a fantastic amount of research and development. Many companies, many startups, have built nontraditional computers from the broad family of analog technologies. In this context, our journey started a few years ago. Last year, we had the first generation of our computer. It was built using bulky technology, but it was already solving a scaled-down version of a real-world finance problem from Barclays. We are actually outperforming the same problem being solved on a quantum computer, which gave [us] a lot of confidence. It led to our research collaboration with Barclays, a partnership with the Microsoft Health Futures team. I'm really excited to share that we have just completed the second generation of [this] computer. It is much smaller in physical size, and this is a world first in that exactly the same computer is simultaneously solving hard optimization problems and accelerating machine learning inference.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Looking ahead, we estimate that at scale, this computer can achieve around 450 tera operations per second per watt, which is a 100-times improvement as compared to state-of-the-art GPUs. Let me now move on to give you an [introduction] to how we can compute using physical technologies. Let's start with the basic mathematical operations: multiplication and addition. If I take a light source, and if I shine it on a filter, like the one that you have in your camera, and I can't have any shade of gray on my filter when light passes through. This is a multiplication by weight between zero and one. This is happening simultaneously for tens of thousands of light beams that are going through this filter in a completely passive power-free fashion\u2014massively parallel multiplication using light-matter interaction.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Similarly, when I have multiple beams of light that fall on a pixel on my smartphone camera, they add up to the photons to produce current\u2014massively parallel addition using light-matter interaction. Once I have addition and multiplication, I can implement a vector matrix multiplier. Benefit from the inherent parallelism of optics, we can implement a massively parallel systolic vector-matrix multiplier. We are building these using consumer technologies. Our input vector is an array of micro-LEDs, the next big thing in the display space. The matrix in the middle is a chip that we use in digital projectors, and I have a sample here\u2014a standard projector with four million pixels on it. In theory, it can simultaneously do four-million multiplications when light bounces off this. Our output vector is exactly the same chip [as] in our smartphone cameras, the standard CMOS sensor\u2014technologies with an existing manufacturing ecosystem that we can dovetail behind.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>For the most interesting applications, we also need nonlinearities, normalization, 10-edge sigmoidal. We implement this using chief-scale analog electronics by CMOS chips. Our choice to combine optics and analog electronics is unique in the industry. Hence, the name of \u201cAnalog Optical Computing\u201d or for short, AOC. These are not just cartoons in slides. We have just completed the second generation of our computer, and my colleague, Francesca, will tell you about what this computer is solving.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p><strong>FRANCESCA PARMIGIANI:<\/strong> The AOC computer has the potential to speed up two broad classes of applications, machine learning inference and hard optimization problems. The first example we run on our computer is the MNIST classification. We've trained the model <em>a priori<\/em> on GPUs, and we have encoded it on our projectors. As you can see, the digits are being successfully classified by our computer live and at a very high accuracy. But what's more important here is that the computer is exactly doing what our emulator platform, our digital twin, is predicting, which really gives us the confidence that the computer is working correctly.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Exactly the same computer can also successfully solve hard optimization problems. As a second example, we have encoded onto the very same projectors an optimization problem. A 100% rate in these graphs means that I solve the problem correctly all the time. When I put now my hand in front of one of the projectors, I block the optical path, and so the computer loses track of what the problem is trying to solve. As a result, it attempted to solve it randomly, and the success rate dropped to zero. Once I remove my hand, the computer regains its understanding of the problem that's solving, and then the success rate returns to 100%.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Looking ahead as we build a future large-scale generation of our computer, it is really critical to co-design the computer with the application to really take advantage of what the computer is good at and really to compensate for its deficiencies. Noise, for example, has always been the main historical challenge with analog computers. Fortunately, machine learning models are relatively amenable to noisy computers. For some models, like diffusion models, noise can actually be your friend rather than your enemy. Used in Bing and Copilot, just to name a few, such diffusion models work as follows: You have your training image, and then over time, you are adding noise to them until you end up with just complete noise. At inference, you run the reverse denoising process, starting from complete noise, and then you end up generating a clean-looking image, a dog in this instance. Importantly, this reverse process is iterative in nature. It is computationally expensive, and it requires a denoise. All requirements that perfectly fit our computer. We have implemented a very small version of such a model to generate MNIST digits using our digital twin, and we aim to run it on our computer very soon. As we then increase the size of the model, we can run advanced images, such as fashion MNIST, cipher images, and many more.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Diffusion, though, is only one example of broader classes of analog-amenable machine learning models that have this feedback nature. Others include deep equilibrium model, neural ODEs, and actually, even some of the latest models like flow matching and state space model, seem to be amenable to our computer, which is really fantastic news for us.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>The same notion of co-design is also key for optimization. Let me give you a real-world example from the healthcare sector. Most likely, you or your loved ones have been inside an MRI scan, not really a great place to be in. Imagine if you can reduce that amount of time from 20\u201340 minutes to less than five minutes. The implication [is] for the patient's experience and the treatment's modalities. Actually, the math here is 15 years old, something called <em>compressed sensing<\/em>. The idea is that when your patient is inside the scanner, you are under-sampling this image\u2014or more precisely, the scan in the freer space\u2014and then you are solving a hard optimization problem to recover ideally the image with full fidelity. Because the problem was computationally hard, it never took off, but we have been able to map this optimization problem to our formulation in our computer. You can see the corresponding results here and how we can iteratively converge to the ground-truth scan using the AOC algorithm. Based on our earlier investigation, we think we could be able to accelerate MRI scan by a factor of 4\u20138x while achieving reconstruction with high fidelity, potentially reducing the scanning time down to five minutes only.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>Certainly, this is an extremely high-risk but high-ambitious project, and it's super exciting that Microsoft Research supports and, in fact, encourages such work. Of course, none of this would be possible without a fantastic interdisciplinary team behind [us] to really rethink across the whole computer stack. All these people here, world leaders in their own discipline, instead of carrying out their own research in silos, they've chosen to work together and operate at the boundary of their disciplines, which is where I believe key breakthroughs can happen. But this is not enough. We also need to build a community. Towards this, we are calling out for people to submit and participate to our <a href=\"https:\/\/aka.ms\/mlncp\" target=\"_blank\" rel=\"noreferrer noopener\">workshop<\/a> at NeurIPS 2024, where we aim to bring together ML and hardware experts. We are also looking to expand our collaboration to gain more experience in solving industry-specific optimization problems.<\/p>\n<!-- \/wp:paragraph -->\n\n<!-- wp:paragraph {\"placeholder\":\"More content...\"} -->\n<p>Towards this, we have launched an online service to allow partners to map and run their problems to our computer. To wrap up, we have been building a new kind of analog optical computer, which has the potential to offer a step change in computer performance using consumer technology. The most important thing I want to leave you with is how we can co-design our application with the underlying computer as the only way for this technology to have a chance in the future of computing. Thank you for listening.<\/p>\n<!-- \/wp:paragraph -->\n<!-- \/wp:msr\/show-more -->\n\n<!-- wp:spacer {\"height\":\"30px\"} -->\n<div style=\"height:30px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n<!-- \/wp:spacer -->\n\n<!-- wp:msr\/annotated-link {\"kicker\":\"Microsoft research copilot experience\",\"kickerEdited\":true,\"title\":\"How does analog optical computing promise to enhance the efficiency and sustainability of AI and other applications?\",\"titleEdited\":true,\"link\":\"https:\/\/msrchat.azurewebsites.net\/?askmsr=How%20does%20analog%20optical%20computing%20promise%20to%20enhance%20the%20efficiency%20and%20sustainability%20of%20AI%20and%20other%20applications?\",\"linkNewTab\":true,\"mediaId\":1002648,\"mediaUrl\":\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/01\/MSR-Chat-Promo.png\",\"className\":\"is-style-default\"} \/-->","post_title":"Analog optical computing for sustainable AI and beyond","post_excerpt":"","post_status":"publish","comment_status":"closed","ping_status":"closed","post_password":"","post_name":"analog-optical-computing-for-sustainable-ai-and-beyond","to_ping":"","pinged":"","post_modified":"2025-05-27 13:09:27","post_modified_gmt":"2025-05-27 20:09:27","post_content_filtered":"","post_parent":0,"guid":"","menu_order":0,"post_type":"msr-video","post_mime_type":"","comment_count":0,"filter":"raw","site_id":1,"permalink":"https:\/\/www.microsoft.com\/en-us\/research\/video\/analog-optical-computing-for-sustainable-ai-and-beyond\/","terms":{"msr-research-area":[{"term_id":13556,"slug":"artificial-intelligence","name":"Artificial intelligence","parent":0,"term_taxonomy_id":13556,"term_order":0,"facet":"{\"term_id\":13556,\"slug\":\"artificial-intelligence\",\"name\":\"Artificial intelligence\",\"parent\":0,\"term_taxonomy_id\":13556,\"term_order\":0}"}],"msr-video-type":[{"term_id":268311,"slug":"microsoft-research-forum","name":"Microsoft Research Forum","parent":0,"term_taxonomy_id":268356,"term_order":0,"facet":"{\"term_id\":268311,\"slug\":\"microsoft-research-forum\",\"name\":\"Microsoft Research Forum\",\"parent\":0,\"term_taxonomy_id\":268356,\"term_order\":0}"}],"msr-locale":[{"term_id":268875,"slug":"en_us","name":"English","parent":0,"term_taxonomy_id":268920,"term_order":0,"facet":"{\"term_id\":268875,\"slug\":\"en_us\",\"name\":\"English\",\"parent\":0,\"term_taxonomy_id\":268920,\"term_order\":0}"}],"msr-session-type":[{"term_id":256174,"slug":"talk","name":"Talk","parent":0,"term_taxonomy_id":256201,"term_order":0,"facet":"{\"term_id\":256174,\"slug\":\"talk\",\"name\":\"Talk\",\"parent\":0,\"term_taxonomy_id\":256201,\"term_order\":0}"}],"msr-episode":[{"term_id":269927,"slug":"s1-ep4","name":"Season 1, Episode 4","parent":0,"term_taxonomy_id":269972,"term_order":0,"facet":"{\"term_id\":269927,\"slug\":\"s1-ep4\",\"name\":\"Season 1, Episode 4\",\"parent\":0,\"term_taxonomy_id\":269972,\"term_order\":0}"}],"msr-research-theme":[{"term_id":269931,"slug":"extending-human-capabilities","name":"Extending Human Capabilities","parent":0,"term_taxonomy_id":269976,"term_order":0,"facet":"{\"term_id\":269931,\"slug\":\"extending-human-capabilities\",\"name\":\"Extending Human Capabilities\",\"parent\":0,\"term_taxonomy_id\":269976,\"term_order\":0}"},{"term_id":269933,"slug":"understanding-general-ai","name":"Understanding General AI","parent":0,"term_taxonomy_id":269978,"term_order":0,"facet":"{\"term_id\":269933,\"slug\":\"understanding-general-ai\",\"name\":\"Understanding General AI\",\"parent\":0,\"term_taxonomy_id\":269978,\"term_order\":0}"}]},"meta":[],"elasticsearch":true},"markup":"\n<!-- Card column wrapper -->\n<div class=\"col mb-4\" itemprop=\"subjectOf\" itemscope itemtype=\"https:\/\/schema.org\/VideoObject\">\n\n\t<!-- Card -->\n\t<div class=\"card h-100 material-card has-spectrum-border-top__hover\" data-mount=\"click-group\">\n\t\t<!-- Image -->\n\t\t\t\t\t<div class=\"position-relative\">\n\t\t\t\t<img width=\"390\" height=\"228\" src=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/09\/RF4_LT1_FrancescaP-JiaqiC-split_1280x720-480x280.jpg\" class=\"card-img wp-post-image\" alt=\"Research Forum | Episode 4 Talk 1 | Francesca Parmigiani and Jiaqi Chu\" \/>\t\t\t\t<!-- Duration -->\n\t\t\t\t<span class=\"duration--overlay badge font-weight-normal position-absolute bg-black text-white px-2 right-2 bottom-2 text-decoration-none\">\n\t\t\t\t\t<span class=\"glyph-prepend glyph-prepend-video position-relative\" style=\"top: 2px\"><\/span>\n\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"sr-only\">Duration<\/span>\n\t\t\t\t\t\t&nbsp;\n\t\t\t\t\t\t15:12\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t<\/div>\n\t\t\t\t\t\t\t<meta itemprop=\"thumbnail\" content=\"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2024\/09\/RF4_LT1_FrancescaP-JiaqiC-split_1280x720-480x280.jpg\">\n\t\t\t\t\t\n\t\t<!-- Card header -->\n\t\t<div class=\"card-header mt-4 px-4\">\n\t\t\t<h3 itemprop=\"name\" class=\"mb-0 h4\">\n\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/video\/analog-optical-computing-for-sustainable-ai-and-beyond\/\" data-bi-cN=\"Analog optical computing for sustainable AI and beyond\" class=\"js-card-link icon-link icon-link--card-title\" itemprop=\"url\" data-bi-type=\"video\" data-bi-tN=\"related-content-tabs\" aria-label=\"Play video entitled Analog optical computing for sustainable AI and beyond\" icon_class=\"c-heading__icon\"><span>Analog optical computing for sustainable AI and beyond<\/span>&nbsp;<span class=\"glyph-in-link glyph-append glyph-append-chevron-right\" aria-hidden=\"true\"><\/span><\/a>\t\t\t<\/h3>\n\t\t<\/div>\n\n\t\t<!-- Card body -->\n\t\t<div class=\"card-body p-4\">\n\t\t\t<p class=\"mb-1\" aria-label=\"Video date\">\n\t\t\t\tSeptember 3, 2024\t\t\t<\/p>\n\n\t\t\t\t\t\t\t<div aria-label=\"Video speakers\">\n\t\t\t\t\t\n\t\t\t\t\t\t<p class=\"mb-1\">\n\t\t\t\t\t\t\t<a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/frparmig\/\">Francesca Parmigiani<\/a>, <a href=\"https:\/\/www.microsoft.com\/en-us\/research\/people\/jiaqchu\/\">Jiaqi Chu<\/a>\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\n\t\t\t\t\t\t\t<p class=\"mb-1\" aria-label=\"Related event\">\n\t\t\t\t\tResearch Forum |\n\t\t\t\t\tSeason 1, Episode 4\t\t\t\t<\/p>\n\t\t\t\t\t<\/div>\n\t<\/div>\n<\/div>\n"}],"found_posts":35,"posts_per_page":12,"max_num_pages":3,"page":1,"current_selections":[{"id":"sort-by","name":"sort_by","count":0,"value":"most-recent","parent":{"id":"sort-by","label":"Sort by"},"slug":"sort_by","type":"sort-by","label":"Most recent","children":[],"selected":true,"default":true}],"facets":[{"id":"sort-by","label":"Sort by","slug":"sort-by","kind":"multiitemlist","items":[{"id":"sort-by","name":"sort_by","count":0,"value":"most-relevant","parent":{"id":"sort-by","label":"Sort by"},"slug":"sort_by","type":"sort-by","label":"Most relevant","children":[],"selected":false,"default":false},{"id":"sort-by","name":"sort_by","count":0,"value":"most-recent","parent":{"id":"sort-by","label":"Sort by"},"slug":"sort_by","type":"sort-by","label":"Most recent","children":[],"selected":true,"default":true},{"id":"sort-by","name":"sort_by","count":0,"value":"a-to-z","parent":{"id":"sort-by","label":"Sort by"},"slug":"sort_by","type":"sort-by","label":"Alphabetical: a to z","children":[],"selected":false,"default":false},{"id":"sort-by","name":"sort_by","count":0,"value":"z-to-a","parent":{"id":"sort-by","label":"Sort by"},"slug":"sort_by","type":"sort-by","label":"Alphabetical: z to a","children":[],"selected":false,"default":false}]},{"id":"msr-session-type","label":"Session Types","slug":"msr-session-type","kind":"multiitemlist","items":[{"id":"tax-256174","name":"facet[tax][msr-session-type]","count":25,"value":"256174","parent":{"id":"msr-session-type","label":"Session Types"},"slug":"msr-session-type","type":"tax","label":"Talk","children":[],"default":false,"selected":false},{"id":"tax-256156","name":"facet[tax][msr-session-type]","count":5,"value":"256156","parent":{"id":"msr-session-type","label":"Session Types"},"slug":"msr-session-type","type":"tax","label":"Keynote","children":[],"default":false,"selected":false},{"id":"tax-264136","name":"facet[tax][msr-session-type]","count":5,"value":"264136","parent":{"id":"msr-session-type","label":"Session Types"},"slug":"msr-session-type","type":"tax","label":"Panel","children":[],"default":false,"selected":false}]},{"id":"msr-episode","label":"Episodes","slug":"msr-episode","kind":"multiitemlist","items":[{"id":"tax-269924","name":"facet[tax][msr-episode]","count":8,"value":"269924","parent":{"id":"msr-episode","label":"Episodes"},"slug":"msr-episode","type":"tax","label":"Season 1, Episode 1","children":[],"default":false,"selected":false},{"id":"tax-269925","name":"facet[tax][msr-episode]","count":7,"value":"269925","parent":{"id":"msr-episode","label":"Episodes"},"slug":"msr-episode","type":"tax","label":"Season 1, Episode 2","children":[],"default":false,"selected":false},{"id":"tax-269927","name":"facet[tax][msr-episode]","count":7,"value":"269927","parent":{"id":"msr-episode","label":"Episodes"},"slug":"msr-episode","type":"tax","label":"Season 1, Episode 4","children":[],"default":false,"selected":false},{"id":"tax-269928","name":"facet[tax][msr-episode]","count":7,"value":"269928","parent":{"id":"msr-episode","label":"Episodes"},"slug":"msr-episode","type":"tax","label":"Season 1, Episode 5","children":[],"default":false,"selected":false},{"id":"tax-269926","name":"facet[tax][msr-episode]","count":6,"value":"269926","parent":{"id":"msr-episode","label":"Episodes"},"slug":"msr-episode","type":"tax","label":"Season 1, Episode 3","children":[],"default":false,"selected":false}]},{"id":"msr-research-theme","label":"Research Themes","slug":"msr-research-theme","kind":"multiitemlist","items":[{"id":"tax-269929","name":"facet[tax][msr-research-theme]","count":15,"value":"269929","parent":{"id":"msr-research-theme","label":"Research Themes"},"slug":"msr-research-theme","type":"tax","label":"Driving Model Innovation","children":[],"default":false,"selected":false},{"id":"tax-269930","name":"facet[tax][msr-research-theme]","count":9,"value":"269930","parent":{"id":"msr-research-theme","label":"Research Themes"},"slug":"msr-research-theme","type":"tax","label":"Ensuring Societal Benefit","children":[],"default":false,"selected":false},{"id":"tax-269931","name":"facet[tax][msr-research-theme]","count":8,"value":"269931","parent":{"id":"msr-research-theme","label":"Research Themes"},"slug":"msr-research-theme","type":"tax","label":"Extending Human Capabilities","children":[],"default":false,"selected":false},{"id":"tax-269932","name":"facet[tax][msr-research-theme]","count":7,"value":"269932","parent":{"id":"msr-research-theme","label":"Research Themes"},"slug":"msr-research-theme","type":"tax","label":"Transforming Scientific Discovery\u200b","children":[],"default":false,"selected":false},{"id":"tax-269933","name":"facet[tax][msr-research-theme]","count":6,"value":"269933","parent":{"id":"msr-research-theme","label":"Research Themes"},"slug":"msr-research-theme","type":"tax","label":"Understanding General AI","children":[],"default":false,"selected":false}]},{"id":"msr-post-author","label":"Speakers","slug":"msr-post-author","kind":"multiitemlist","items":[{"id":"user-32016","name":"facet[tax][msr-post-author]","count":3,"value":32016,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Hoifung Poon","children":[],"default":false,"selected":false},{"id":"user-40408","name":"facet[tax][msr-post-author]","count":3,"value":40408,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Daniela Massiceti","children":[],"default":false,"selected":false},{"id":"user-32172","name":"facet[tax][msr-post-author]","count":2,"value":32172,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Jacki O'Neill","children":[],"default":false,"selected":false},{"id":"user-32204","name":"facet[tax][msr-post-author]","count":2,"value":32204,"parent":{"id":"msr-post-author","label":"Personne"},"slug":"msr-post-author","type":"user","label":"John Langford","children":[],"default":false,"selected":false},{"id":"user-39964","name":"facet[tax][msr-post-author]","count":2,"value":39964,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Ashley J. Llorens","children":[],"default":false,"selected":false},{"id":"user-41413","name":"facet[tax][msr-post-author]","count":2,"value":41413,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Tian Xie","children":[],"default":false,"selected":false},{"id":"user-30820","name":"facet[tax][msr-post-author]","count":1,"value":30820,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Adam Fourney","children":[],"default":false,"selected":false},{"id":"user-31452","name":"facet[tax][msr-post-author]","count":1,"value":31452,"parent":{"id":"msr-post-author","label":"Personne"},"slug":"msr-post-author","type":"user","label":"Christopher Bishop","children":[],"default":false,"selected":false},{"id":"user-31710","name":"facet[tax][msr-post-author]","count":1,"value":31710,"parent":{"id":"msr-post-author","label":"Personne"},"slug":"msr-post-author","type":"user","label":"Ece Kamar","children":[],"default":false,"selected":false},{"id":"user-32246","name":"facet[tax][msr-post-author]","count":1,"value":32246,"parent":{"id":"msr-post-author","label":"Personne"},"slug":"msr-post-author","type":"user","label":"Jianfeng Gao","children":[],"default":false,"selected":false},{"id":"user-32340","name":"facet[tax][msr-post-author]","count":1,"value":32340,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Jake Hofman","children":[],"default":false,"selected":false},{"id":"user-32468","name":"facet[tax][msr-post-author]","count":1,"value":32468,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Katja Hofmann","children":[],"default":false,"selected":false},{"id":"user-33238","name":"facet[tax][msr-post-author]","count":1,"value":33238,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Peter Lee","children":[],"default":false,"selected":false},{"id":"user-34779","name":"facet[tax][msr-post-author]","count":1,"value":34779,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Hanna Wallach","children":[],"default":false,"selected":false},{"id":"user-36021","name":"facet[tax][msr-post-author]","count":1,"value":36021,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Aseem Rastogi","children":[],"default":false,"selected":false},{"id":"user-36200","name":"facet[tax][msr-post-author]","count":1,"value":36200,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Pantazis Deligiannis","children":[],"default":false,"selected":false},{"id":"user-36804","name":"facet[tax][msr-post-author]","count":1,"value":36804,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Mihaela Vorvoreanu","children":[],"default":false,"selected":false},{"id":"user-37230","name":"facet[tax][msr-post-author]","count":1,"value":37230,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Alessandro Sordoni","children":[],"default":false,"selected":false},{"id":"user-37287","name":"facet[tax][msr-post-author]","count":1,"value":37287,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Sunayana Sitaram","children":[],"default":false,"selected":false},{"id":"user-37727","name":"facet[tax][msr-post-author]","count":1,"value":37727,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Francesca Parmigiani","children":[],"default":false,"selected":false},{"id":"user-37929","name":"facet[tax][msr-post-author]","count":1,"value":37929,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Tristan Naumann","children":[],"default":false,"selected":false},{"id":"user-38481","name":"facet[tax][msr-post-author]","count":1,"value":38481,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Jiang Bian","children":[],"default":false,"selected":false},{"id":"user-38670","name":"facet[tax][msr-post-author]","count":1,"value":38670,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Naoto Usuyama","children":[],"default":false,"selected":false},{"id":"user-38883","name":"facet[tax][msr-post-author]","count":1,"value":38883,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Tanuja Ganu","children":[],"default":false,"selected":false},{"id":"user-39093","name":"facet[tax][msr-post-author]","count":1,"value":39093,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Kevin Kaichuang Yang","children":[],"default":false,"selected":false},{"id":"user-39147","name":"facet[tax][msr-post-author]","count":1,"value":39147,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Jiaqi Chu","children":[],"default":false,"selected":false},{"id":"user-39856","name":"facet[tax][msr-post-author]","count":1,"value":39856,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Madeleine Daepp","children":[],"default":false,"selected":false},{"id":"user-40300","name":"facet[tax][msr-post-author]","count":1,"value":40300,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Marwin Segler","children":[],"default":false,"selected":false},{"id":"user-40372","name":"facet[tax][msr-post-author]","count":1,"value":40372,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Kristen Severson","children":[],"default":false,"selected":false},{"id":"user-40432","name":"facet[tax][msr-post-author]","count":1,"value":40432,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Ava P. Amini","children":[],"default":false,"selected":false},{"id":"user-40852","name":"facet[tax][msr-post-author]","count":1,"value":40852,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Rianne van den Berg","children":[],"default":false,"selected":false},{"id":"user-40861","name":"facet[tax][msr-post-author]","count":1,"value":40861,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Sameer Segal","children":[],"default":false,"selected":false},{"id":"user-41036","name":"facet[tax][msr-post-author]","count":1,"value":41036,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Alex Lu","children":[],"default":false,"selected":false},{"id":"user-41320","name":"facet[tax][msr-post-author]","count":1,"value":41320,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Lili Qiu","children":[],"default":false,"selected":false},{"id":"user-41482","name":"facet[tax][msr-post-author]","count":1,"value":41482,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Megan Stanley","children":[],"default":false,"selected":false},{"id":"user-41919","name":"facet[tax][msr-post-author]","count":1,"value":41919,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Bonnie Kruft","children":[],"default":false,"selected":false},{"id":"user-41997","name":"facet[tax][msr-post-author]","count":1,"value":41997,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Corby Rosset","children":[],"default":false,"selected":false},{"id":"user-42792","name":"facet[tax][msr-post-author]","count":1,"value":42792,"parent":{"id":"msr-post-author","label":"\u4eba\u5458"},"slug":"msr-post-author","type":"user","label":"Matthew P Lungren","children":[],"default":false,"selected":false},{"id":"user-43209","name":"facet[tax][msr-post-author]","count":1,"value":43209,"parent":{"id":"msr-post-author","label":"People"},"slug":"msr-post-author","type":"user","label":"Lev Tankelevitch","children":[],"default":false,"selected":false}]}],"filter_queries":[]},"classes":"btn btn-primary faceted-search__load-more","i18n":{"loadingStart":"Loading additional posts. Please wait.","loadingEnd":"Loading additional posts complete.","duetDatePicker":{"buttonLabel":"Choose date","placeholder":"YYYY-MM-DD","selectedDateMessage":"Selected date is","prevMonthLabel":"Previous month","nextMonthLabel":"Next month","monthSelectLabel":"Month","yearSelectLabel":"Year","closeLabel":"Close window","calendarHeading":"Choose a date","dayNames":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"],"monthNames":["January","February","March","April","May","June","July","August","September","October","November","December"],"monthNamesShort":["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]},"validation":{"patternMismatch":"Please enter a date in YYYY-MM-DD format."}},"slot":"0","isSearch":"","defaultFacets":{"facet":[],"sort_by":"most-recent"},"theme_assets":"https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/themes\/microsoft-research-theme\/assets\/","postId":"1140163","postTab":""};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.microsoft.com/en-us/research/wp-content/themes/microsoft-research-theme/assets/js/search.min.js?ver=7009c675ffd3915a29f8dc09388f79dc02addde3" id="faceted-search-js"></script>

	</body>
</html>
<!--
Performance optimized by Redis Object Cache. Learn more: https://wprediscache.com

Retrieved 5353 objects (1 MB) from Redis using PhpRedis (v6.1.0).
-->
